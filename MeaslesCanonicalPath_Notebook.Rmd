---
title: "Measles and the Canonical Path to Elimination"
output:
  html_document:
    keep_md: yes
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn=-1)
require(ggplot2)
require(mgcv)
require(tmap)
require(magrittr)
require(tidyverse)
require(RColorBrewer)
require(tmap)
require(reshape2)
require(wpp2015)
require(wesanderson)
library(lattice)
require(SDMTools)
library(gridExtra)
##' if we want to reproduce the code in the output, then change the next line to include.code = T
include.code = F
source("Functions.R")
```

This notebook will construct the figures for the paper by Graham et al., titled "Measles and the Canonical Path to Elimination." First we weighted case data along with population data to construct a dataset which can be used to plot each country through time in 'incidence-space', which has the incidence on the y-axis, and the coefficient of variation of incidence over time on the x-axis.

```{r,  echo = include.code, include = F}
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")

##' this line assigns the constructed data to the data set canonical.path.data
canonical.path.data.reported = generate.data(window.length = 10, regions,
                                                      gaussian.st.dev = 3, cutoff = 50,
                                                      interp.resolution = 20, year.shift.inc = 2)


canonical.path.data.reported = add.mcv2.data.to.anim.data (canonical.path.data.reported, 
                                                                non.mcv2.alpha = 0.4, mcv2.alpha = 0.4)


canonical.path.data <- canonical.path.data.reported

```

Following the construction of this data set, we plot Figure 1A from the paper. This figure shows the position of
countries in the Americas and in Africa in two years, along with the mean path taken by these continents from 
the beginning of the data set to the end of it. These mean paths are shown by the green and purple lines in the
figure below, with the green line being for Africa and the purple one for the Americas.

```{r, echo = include.code, include=FALSE}


taxonomy.fig1 = incidence.space.fig.dashed.arrow(anim.data = canonical.path.data, years = c(1990, 2017), 
                                     regions = c("AFR",  "AMR"), shapes = c(1,2,16,17),
                                     countries.of.interest = c("Malawi", "United States", 
                                                               "Brazil", "Argentina",
                                                               "Congo, Democratic Republic of the",
                                                               "Zambia",
                                                               "Uruguay", "Tanzania"),
                                     colors = c( "#367526", "#7a40a0"), text.size = 4,xint=-1.07, yint = 0.25,
                                     line.color = 'grey1', arrow.size = 2,
                                     breaks = c(1,5,10,15,20,40,60))


```


```{r, fig.height = 10, fig.width = 10, echo = include.code} 
taxonomy.fig1
```

By combining the trajectories, we can create the canonical path towards elimination seen in Fig. 1B in the paper.
This figure was created in Adobe Illustrator, so cannot be reproduced here.

The canonical path is estimated by scaling the incidence and coefficent of variation and then calculating the mean trajectories of Africa and the Americas over time, and combining these at the point that they intersect, i.e. at the point that the green and purple lines cross in the plot above. The analysis performed in the paper relies on the fact that when we calculate the position of a country at a given time in the incidence-space, we can calculate which point on the canonical path this country's location is closest to. However, we can see that when we do this there are positions which are close to each other distance wise on this path, but far in terms of progression towards elimination, due to the fact that on the lower end of incidence, there is very little distance between the points. For example if, in a given year, a country lay at the point 1.4 on the x-axis, and has a fairly low incidence, then it could easily be assigned to a point very close to the end of the path to elimination or one which is about half way along the path. This is not a desirable property of the canonical path. To help distinguish the points more clearly, and help this assignment of nations, we do two things. Firstly, we take the log (natural base) of the incidence, and secondly, we transform both the incidence and the coefficient of variation data to be on the 0-1 scale. This is done in the chunk below.

```{r, echo = include.code, include = FALSE}

##' set up variables to use for making the canonical path and the
##' assignment of countries to the closest point on the path

d = canonical.path.data
use.reported.cases = TRUE
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")
make.inc.cv.scale.same = 1 
sqrt.inc = F 
sqrt.cv = F
connect.canonical.path.to.zero = 0
log.incidence = T 
number.of.additional.points = 4 #4 additional points between each of 38 points

##' d1 will contain the closest point on the canonical path over time.
list[d1, canonical.path] = closest.path.point(d = d, 
                                              use.rep.cases = use.reported.cases,
                                              regions = regions, 
                                              years = seq(1990, 2017),
                                              make.inc.cv.scale.same = make.inc.cv.scale.same,
                                              sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                              connect.canonical.path.to.zero,
                                              log.incidence = log.incidence)

##' d1b will contain the closest point on the granular canonical path over time.
list[d1b, granular.canonical.path] = closest.path.point.movement.comparison(d = d, 
                                              use.rep.cases = use.reported.cases,
                                              regions = regions, 
                                              years = seq(1990, 2017),
                                              make.inc.cv.scale.same = make.inc.cv.scale.same,
                                              sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                              connect.canonical.path.to.zero,
                                              log.incidence = log.incidence,
                                              number.of.additional.points = number.of.additional.points) 
```

When we plot the canonical path now, we see that there is a much greater distinction between points at the low incidence part of the path (Fig. S15 in the supplement).  

```{r, echo = include.code, fig.height = 6, fig.width = 6}
cols.1 <- colorRampPalette(c("red", "white", "blue"))(length(canonical.path$x))
plot(canonical.path$x, canonical.path$y, pch = 21, cex = 2,
         xlab = 'scaled coefficient of variation', ylab= 'scaled mean incidence', bty="n", 
     cex.axis=1.5, cex.lab = 1.5, col = 'black', bg = cols.1, ylim=c(0,1), xlim=c(0,1))
points(granular.canonical.path$x, granular.canonical.path$y, pch = 16, cex = 0.5)

```

Using the scaled canonical path, we assign countries to the closest point on this path each year for which there is reported incidence data. Once countries have been assigned to positions on the canonical path, the majority of the analyses completed in this work can be reproduced.  

Fig. 2A shows the 38 point path (unscaled version), in which the grey band represents where the global population lies on the path currently (i.e., furthest position on the path between 2012 and 2017). For comparison, we also displayed the global populatoin position on the path based on the earliest data available for each country, as seen in Fig. 2B of the paper.


```{r, echo = include.code, fig.height = 10, fig.width = 10}

canonical.path2 <- Unscaled.Canonical.Path(canonical.path.data = canonical.path.data, 
                                           canonical.path = canonical.path, 
                                           regions=regions, 
                                           years = seq(1990, 2017))

#Newest figure which combines ribbon (pop at point) and cumulative proportion of the global pop (color)
df.tmp <- d1
#Add population size to the data frame
df.tmp$pop <- as.numeric(rep(NA, nrow(df.tmp)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(df.tmp)){
  row <- which(pop.by.year$Country.Name==df.tmp$Country[a])
  col <- which((1961:2017)==df.tmp$Year[a])+2
  df.tmp$pop[a] <- pop.by.year[row,col]
  if (is.na(df.tmp$pop[a]) | df.tmp$pop[a]=="#N/A") {df.tmp$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(df.tmp$pop[a]) | df.tmp$pop[a]=="#N/A") {df.tmp$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(df.tmp$pop[a]) | df.tmp$pop[a]=="#N/A") {df.tmp$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(df.tmp$pop[a]) | df.tmp$pop[a]=="#N/A") {df.tmp$pop[a] <- pop.by.year[row,(col-4)]}
}
df.tmp$pop <- as.numeric(df.tmp$pop)

#Best position 2012-2017 for each country
dfbest.tmp <- df.tmp %>%
  filter(Year>2012) %>%
  group_by(Country) %>%
  summarise(closest = max(closest), pop = pop[Year==2017]) %>%
  group_by(closest) %>%
  summarise(pop = sum(pop))

#Scaling and smoothing the population over the canonical path
population <- log(dfbest.tmp$pop)+1
index <- match(1:38, dfbest.tmp$closest)
population <- population[index]
population[is.na(population)] <- 0 #filling in missing points on the path
smoothed.pop <- rep(NA, length(population))
for (i in 2:37){
  smoothed.pop[i] <- mean(population[(i-1):(i+1)])
}
smoothed.pop[1] <- population[1]
smoothed.pop[38] <- population[38]
smoothed.scaled.pop <-  1*(smoothed.pop/sum(smoothed.pop))#scale to be between 0 and 1
#Get unit vectors for line thickness
df.polygon1 <- GetLineOrthogonalToPath(canonical.path.line=data.frame(x=canonical.path2$x, y=sqrt(canonical.path2$y)), smoothed.scaled.pop)

#plotted in sqrt incidence to be able to better deferentiate the points towards the end of the path
par(bty="n")
cols.1 <- colorRampPalette(c("red", "white", "blue"))(length(canonical.path$x))
plot(canonical.path2$x, sqrt(canonical.path2$y), pch = 21, cex = 2,
     xlab = 'coefficient of variation', ylab= 'mean incidence per 1000', bty="n", 
     yaxt = "n", cex.axis=1.5, cex.lab = 1.5, col = 'black', bg = cols.1, type="n")
axis(2, at=sqrt(c(0, 0.025, 0.1,0.5,1,1.5)), labels=c(0, 0.025, 0.1,0.5, 1, 1.5), cex.axis = 1.5, cex.lab=1.5)
for (p in 2:nrow(df.polygon1)){
  polygon(c(df.polygon1$x0[(p-1):p], rev(df.polygon1$x1[(p-1):p])), (c(df.polygon1$y0[(p-1):p],rev(df.polygon1$y1[(p-1):p]))), col="grey", border=NA)
}
points(canonical.path2$x, sqrt(canonical.path2$y), pch = 21, cex = 1.5, col = 'black', bg = cols.1)

#Earliest position for each country
dfearliest.tmp <- df.tmp %>%
  group_by(Country) %>%
  filter(Year==min(Year)) %>%
  group_by(closest) %>%
  summarise(pop = sum(pop))

#Scaling and smoothing the population over the canonical path
population <- log(dfearliest.tmp$pop)+1
index <- match(1:38, dfearliest.tmp$closest)
population <- population[index]
population[is.na(population)] <- 0 #filling in missing points on the path
smoothed.pop <- rep(NA, length(population))
for (i in 2:37){
  smoothed.pop[i] <- mean(population[(i-1):(i+1)])
}
smoothed.pop[1] <- population[1]
smoothed.pop[38] <- population[38]
smoothed.scaled.pop <-  1*(smoothed.pop/sum(smoothed.pop))#scale to be between 0 and 1
#Get unit vectors for line thickness
df.polygon2 <- GetLineOrthogonalToPath(canonical.path.line=data.frame(x=canonical.path2$x, y=sqrt(canonical.path2$y)), smoothed.scaled.pop)

#plot it
par(bty="n")
cols.1 <- colorRampPalette(c("red", "white", "blue"))(length(canonical.path$x))
plot(canonical.path2$x, sqrt(canonical.path2$y), pch = 21, cex = 2,
     xlab = 'coefficient of variation', ylab= 'mean incidence per 1000', bty="n", 
     yaxt = "n", cex.axis=1.5, cex.lab = 1.5, col = 'black', bg = cols.1, type="n")
axis(2, at=sqrt(c(0, 0.025, 0.1,0.5,1,1.5)), labels=c(0, 0.025, 0.1,0.5, 1, 1.5), cex.axis = 1.5, cex.lab=1.5)
for (p in 2:nrow(df.polygon1)){
  polygon(c(df.polygon2$x0[(p-1):p], rev(df.polygon2$x1[(p-1):p])), (c(df.polygon2$y0[(p-1):p],rev(df.polygon2$y1[(p-1):p]))), col="grey", border=NA)
}
points(canonical.path2$x, sqrt(canonical.path2$y), pch = 21, cex = 1.5, col = 'black', bg = cols.1)

```

Fig. 3A in the paper plots all countries position on the path overtime.

```{r, echo = include.code, include = F}

##' First add population size to the data.frame because we need to weight the region estimates by population size of coutry
d1b$pop <- as.numeric(rep(NA, nrow(d1b)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(d1b)){
  row <- which(pop.by.year$Country.Name==d1b$Country[a])
  col <- which((1961:2017)==d1b$Year[a])+2
  d1b$pop[a] <- pop.by.year[row,col]
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-4)]}
}
d1b$pop <- as.numeric(d1b$pop)

##' Get country-specific population weight for each region and year
##' This will be used to weight the average position by region overtime
d1b <- d1b %>%
  group_by(WHO_REGION, Year) %>%
  mutate(weight = pop/sum(pop))
d1b$weight <- round(d1b$weight,5)

##' create data frame to store values in
deltas.by.continent = data.frame(matrix(NA, nrow(d1b), 6))
colnames(deltas.by.continent) = c("country", "region", "year", "delta", "pos","weight")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
  c1 = d1b$Country[i]
  y = d1b$Year[i]
  pos = d1b$closest[i]
  
  ##' for each country, each year, find the data for the same country the following year
  
  k = d1b %>% filter(Country == c1, Year == (y+1))
  if(nrow(k)>0){
    pos2 = k$closest
    deltas.by.continent[count, ] =  c(c1, k$WHO_REGION, y+1, pos2-pos, pos2, k$weight)
    count = count + 1
  }
}

##' remove data which is NA
j = which(is.na(deltas.by.continent$country))
if(length(j) >0 ){
  deltas.by.continent = deltas.by.continent[-(j),]
}

##' extract the unique years from the data set containing the changes for each year
all.years = as.numeric(unique(deltas.by.continent$year))
countries = unique(deltas.by.continent$country)

##' change the data to be characters and numbers
deltas.by.continent$country = deltas.by.continent$country %>% as.character
deltas.by.continent$region = deltas.by.continent$region %>% as.character
deltas.by.continent$year = deltas.by.continent$year %>% as.character %>% as.numeric
deltas.by.continent$delta = deltas.by.continent$delta %>% as.character %>% as.numeric
deltas.by.continent$pos = deltas.by.continent$pos %>% as.character %>% as.numeric
deltas.by.continent$weight = deltas.by.continent$weight %>% as.character %>% as.numeric

##'choose a period of time over which to smooth the average position of the WHO regions. 
##'A 2 this means that we smooth using the average of a given year along with two years before and two years after
moving.av.length = 2

##' set up a dataframe to hold the weighted data
deltas.summary.weighted = data.frame(matrix(NA, (length(all.years)-2)*length(countries), 6))
colnames(deltas.summary.weighted) = c("country","region", "year", "mean.delta", "mean.pos", "weight")

count = 1
for(i in (moving.av.length+1):length(all.years - moving.av.length)){
  ##' choose the years we wish to include in the averaging
  years = all.years[(i-moving.av.length):(i+moving.av.length)]
  for(j in 1 : length(countries)){
    ##' find the require data
    c = countries[j]
    d = deltas.by.continent %>% filter(year %in% years & country ==c) 
    r = d$region[1]
    
    ##' record the regions, the year in question, along with summaries of the change in movement, along
    ##' with the mean position of the region over the years in question
    deltas.summary.weighted[count, ] = c(c, 
                                         r,
                                         years[(moving.av.length + 1)],
                                         mean(d$delta),
                                         mean(d$pos),
                                         mean(d$weight)) #keep the weight for appropriate year
    count = count + 1
  }
}

##' remove data which is NA
j = which(deltas.summary.weighted$mean.delta=="NaN")
if(length(j) >0 ){
  deltas.summary.weighted = deltas.summary.weighted[-(j),]
}

##' change the data to be characters and numbers
deltas.summary.weighted$country = deltas.summary.weighted$country %>% as.character
deltas.summary.weighted$region = deltas.summary.weighted$region %>% as.character
deltas.summary.weighted$year = deltas.summary.weighted$year %>% as.character %>% as.numeric
deltas.summary.weighted$mean.delta = deltas.summary.weighted$mean.delta %>% as.character %>% as.numeric
deltas.summary.weighted$mean.pos = deltas.summary.weighted$mean.pos %>% as.character %>% as.numeric
deltas.summary.weighted$weight = deltas.summary.weighted$weight %>% as.character %>% as.numeric

dd <- deltas.summary.weighted

##' summarise with average position for each region, by year
dd2 = dd %>% 
  group_by(region, year) %>%
  summarise(mean.pos = mean(mean.pos))
dd3 = dd %>% 
  group_by(region, year) %>%
  summarise(mean.delta = mean(mean.delta))
```

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1)

```

Countries do not necessarily progress smoothly along the path as if, for example, after years of low incidence is interrupted by a year of high incidence, then this will increase the x and y position of the country in incidence-space and hence the position on the canonical path will head backwards. We demonstrate these movements along the path by plotting the % change in path potion between 1990 and 2017 for each country in addition to region averages, as see in Fig. 3B in the paper.

```{r, fig.height = 6, fig.width = 6, echo = include.code} 

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1)

```

We can alternatively overlay population-weighted region averages by year, as seen in supplemental Fig. S29.

```{r, fig.height = 6, fig.width = 6, echo = include.code}
##' summarise the population weighted average position for each region, by year
dd2b = dd %>% 
  group_by(region, year) %>%
  summarise(mean.pos = sum(mean.pos*weight))
dd3b = dd %>% 
  group_by(region, year) %>%
  summarise(mean.delta = sum(mean.delta*weight))

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2b, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1)

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3b, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1)

```

We can easily pull out individual countries postion and speed of movement along the canonical path. Here we demonstrates movement along the canonical path for 10 countries of interest from the Americas, Africa, and European (supplemental Fig. S17).

```{r, fig.height=6, fig.width=12, echo=include.code}
##' filtering to the countries of interest
cc <- dd %>%
  filter(country=="Malawi" | country=="Brazil" | country=="Uruguay" | country=="Congo, Democratic Republic of the" |
           country=="Zambia" | country=="United States" | country=="France" | country=="Argentina" | country=="Tanzania") %>%
  mutate(country=ifelse(country=="Congo, Democratic Republic of the", "DRC", country))

ggplot(cc, aes(x=year, y=mean.pos/2, color=country)) + geom_line(alpha=0.6, lwd=1.5) +
  theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Paired")
ggplot(cc, aes(x=year, y=mean.delta/2, color=country)) + geom_line(alpha=0.6, lwd=1.5) +
  ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)")  + scale_colour_brewer(palette="Paired")
```


Given our assignment of all countries to the closest point on the path, for any given year a map can be produced which is colored according to each countries position along the path. This is seen below for 2017 (Fig. 2C of the paper).  We have also made available web application, developed with R package Shiny, to view all countries position on the canonical path between 1980 and 2017 (available at http://iddynamics.jhsph.edu/apps/shiny/measlescanonicalpath/).

```{r, fig.height = 6, fig.width = 10, echo = include.code}
plot.year = 2017

missing.countries = c("Bosnia and Herzegovina", "Central African Republic",
                       "Congo, Republic of The", "Czech Republic", "Korea, North",
                       "Congo, Democratic Republic of the", "Dominican Republic", "Gambia, The",   
                       "Burma", "Korea, South", "South Sudan")

replace.countries = c("Bosnia and Herz", "Central African Rep.", "Congo", "Czech Rep.",
                       "Dem. Rep. Korea", "Dem. Rep. Congo", "Dominican Rep.", "Gambia",
                       "Myanmar", "Korea", "S. Sudan")
 
 
list[w.plot, A, canonical.path] = plot.world.map (d = canonical.path.data, 
                                                  use.rep.cases = use.reported.cases,
                                                  regions,
                                                  year = plot.year,
                                                  make.inc.cv.scale.same = 1,
                                                  sqrt.inc = F,
                                                  missing.countries,
                                                  replace.countries,
                                                  connect.canonical.path.to.zero = 0 ,
                                                  log.incidence = T,
                                                  with.text = 1)
```

```{r, echo = include.code, fig.height = 5, fig.width = 10}
w.plot
```

We can also capture direction of movement of each country within the incidence space in order to assess "deviations" from the path or trajectories of countries in incidence space that were different than expected given the characterized canonical path.  Fig. 3C and 3D in the paper are reproduced here.  

```{r, echo=include.code}
position.and.movement.comparison = data.frame(matrix(NA, nrow(d1b), 15))
colnames(position.and.movement.comparison) = c("country", "region", "year", 
                                  "actual.x", "actual.y",
                                  "next.actual.x", "next.actual.y",
                                  "actual.x.change", "actual.y.change",
                                  "canonical.x","canonical.y", 
                                  "next.canonical.x", "next.canonical.y",
                                  "canonical.x.change", "canonical.y.change")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
    c1 = d1b$Country[i]
    y = d1b$Year[i]
    pos = d1b$closest[i]
    
    ##' for each country, each year, find the data for the same country the following year
    
    k = d1b %>% filter(Country == c1, Year == (y+1)) #looking one year ahead (i.e., 1 for observed, and 5 for expected)
    if(nrow(k)>0){
        if(pos < (nrow(granular.canonical.path)-5)){
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           granular.canonical.path$x[(pos+5)], granular.canonical.path$y[(pos+5)],
                                                           granular.canonical.path$x[(pos+5)]-d1b$canonical.x[i],
                                                           granular.canonical.path$y[(pos+5)]-d1b$canonical.y[i])
       } else if (pos < (nrow(granular.canonical.path)-1)) { #if within the last 5 granular points, then just use last position (186)
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           granular.canonical.path$x[186], granular.canonical.path$y[186],
                                                           granular.canonical.path$x[186]-d1b$canonical.x[i],
                                                           granular.canonical.path$y[186]-d1b$canonical.y[i])
       } else { #else means the country is at the end of the granular path, so force canonical path change to 0
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           0,0)
            
        }
               count = count + 1
    }
}

#remove non filled in rows
df <- position.and.movement.comparison %>% filter(!is.na(country))

#making numeric
df$actual.x.change = df$actual.x.change %>% as.character %>% as.numeric
df$actual.y.change = df$actual.y.change %>% as.character %>% as.numeric
df$canonical.x.change = df$canonical.x.change %>% as.character %>% as.numeric
df$canonical.y.change = df$canonical.y.change %>% as.character %>% as.numeric

#force observed movements at the end of the granular pathway to 0
end.x <- granular.canonical.path$x[length(granular.canonical.path$x)]
df$path.end <- ifelse(df$canonical.x==end.x & df$next.canonical.x==end.x, 1, 0)

#force actual movement of observations not moving from the end of the path to zero
df$actual.x.change.raw <- df$actual.x.change #save the raw estimates into this variable
df$actual.y.change.raw <- df$actual.y.change #save the raw estimates into this variable
df$actual.x.change[which(df$path.end==1)] <- 0
df$actual.y.change[which(df$path.end==1)] <- 0

#calculating the angle
df$actual.angle <- (atan2(df$actual.y.change,df$actual.x.change)*-180/pi) #-90 degrees at positive y-axis (top), 90 degrees a negative y-axis (bottom)
df$canonical.angle <- (atan2(df$canonical.y.change,df$canonical.x.change)*-180/pi) 

#Angle difference
df$angle.diff <- df$actual.angle-df$canonical.angle
#series of if statements: to get angle difference between 180 and -180, rather than -360 and 360.
dft <- df %>% filter(canonical.angle<= -90 & actual.angle>= 90)
df$angle.diff[(df$canonical.angle<= -90 & df$actual.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(actual.angle<= -90 & canonical.angle>= 90)
df$angle.diff[(df$actual.angle<= -90 & df$canonical.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(actual.angle<= -90 & canonical.angle<= 90 & canonical.angle>= 0 & angle.diff< -180)
df$angle.diff[(df$actual.angle<= -90 & df$canonical.angle<= 90 & df$canonical.angle>= 0 & df$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(canonical.angle>= 90 & actual.angle>= -90 & actual.angle<= 0 & angle.diff< -180)
df$angle.diff[(df$canonical.angle>= 90 & df$actual.angle>= -90 & df$actual.angle<= 0 & df$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)

#group angles in 10s
df$canonical.angle10 <- plyr::round_any(df$canonical.angle, 10)
df$actual.angle10 <- plyr::round_any(df$actual.angle, 10)

```

We plot the expected movement and observed movement for each region over 10 or 8 year increments. Below are some summary statisitics (i.e., median and IQR) for each region and year grouping. This analysis captures the frequency of countries movement in a direction grouped by 10 degree angle groups. 

```{r,echo = include.code}
#looping through regions
regs = c("AMR","AFR","EMR","EUR","SEAR","WPR")
year.groups <- list(1990:1999, 2000:2009, 2010:2017)
all.plots <- list()
for (c in 1:length(regs)){
  for (y in 1:3){
    
    #filtering and grouping data to set up dataframe for plotting
    dfo <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]]) %>%
      group_by(a = actual.angle10) %>%
      summarise(n=n()) %>%
      mutate(frequency=n/sum(n))
    dfe.tmp <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]]) %>%
      group_by(a = round(canonical.angle10)) %>%
      summarise(n=n()) %>%
      mutate(freq=n/sum(n))
    
    #smoothing expected path
    byn <- seq(-180,179,10)
    dfe <- as.data.frame(matrix(NA, nrow=length(byn), ncol=2))
    colnames(dfe) <- c("a", "freq")
    for (i in 1:length(byn)){
      dfe$freq[i] <- ifelse(is.na(dfe.tmp$freq[match(byn[i], dfe.tmp$a)]),0,
                            dfe.tmp$freq[match(byn[i], dfe.tmp$a)])
      dfe$a[i] <- byn[i]
    }
    dfe$frequency <- rep(NA, nrow(dfe))
    for (r in 1:nrow(dfe)){
      if (r==1) {dfe$frequency[r] <- mean(dfe$freq[(r):(r+2)], na.rm=T)}
      if (r==2) {dfe$frequency[r] <- mean(dfe$freq[(r-1):(r+2)], na.rm=T)}
      if (r>=3) {dfe$frequency[r] <- mean(dfe$freq[(r-2):(r+2)], na.rm=T)}
    }
    
    #merging the datasets together into one
    byn <- seq(-180,179,10)
    dfa <- data.frame(a=rep(byn,3), obs.exp=c(rep("O",length(byn)),rep("FF",length(byn)),rep("E",length(byn))), frequency=rep(NA, length(byn)*3))
    for (i in 1:length(byn)){
      dfa$frequency[which(dfa$obs.exp=="O")[i]] <- dfo$frequency[match(dfa$a[i], dfo$a)]
      dfa$frequency[which(dfa$obs.exp=="E")[i]] <- dfe$frequency[match(dfa$a[i], dfe$a)]
    }
    dfa$label <- c(rep("Observed",length(byn)), rep("blank",length(byn)), rep("Expected",length(byn)))
    dfa$frequency[is.na(dfa$frequency)] <- 0 #because no change is NA
    dfa$frequency[which(dfa$obs.exp=="FF")] <- NA
    dfa$a[dfa$a==seq(-180,-100,10)] <- 360+dfa$a[dfa$a==seq(-180,-100,10)] #hack so the top is -90 degrees
    
    #estimating median difference in angle
    dfd <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]]) %>%
      summarise(med=(median(angle.diff)*(-1))) #want positive 90 degrees at top and -90 degrees at bottom
    
    #IQR for region and year
    df.iqr <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]])
    iqr <- round(quantile((df.iqr$angle.diff*(-1)), c(0.25, 0.5,0.75)),2) #want positive 90 degrees top, and -90 degrees bottom
    if (c==1 & y==1) print(c("Region:Year Group ", "25%","50%","75%"))
    print(c(paste(regs[c], year.groups[y]), as.numeric(iqr)))
    
    #plot it
    dfa$obs.exp <- as.numeric(dfa$obs.exp)+2
    name <- paste("reg",c,".year",y, sep="")
    all.plots[[name]] <- 
      ggplot(dfa, aes(x=a, y=obs.exp, fill=(frequency))) +
      geom_tile(colour="white") +
      scale_fill_distiller(palette="YlGnBu", direction=1, limits=c(0,0.25), na.value="white") + 
      ylim(c(0, max(dfa$obs.exp) + 0.5)) +
      coord_polar(theta="x") + annotate("text", x = 0, y = 0, label = round(dfd[1,1])) +
      theme(panel.background=element_blank(),
            axis.title=element_blank(),
            panel.grid=element_blank(),
            axis.text.x=element_blank(),
            axis.ticks=element_blank(),
            axis.text.y=element_text(size=5)) + ggtitle(paste(regs[c],": ", year.groups[[y]][1], "-", year.groups[[y]][length(year.groups[[y]])], sep=""))
    
  }
}
```

We can plot all regions and years here as shown in Fig. 3D. This plot will look slightly different than the main text because the main text range is from 0 to >20%, where we grouped frequencies between 20 and 25% into one color dark blue color.  Below we show the range of frequencies between 0 and 25%. 

```{r, fig.height = 9, fig.width = 18}
do.call(grid.arrange, c(grobs=all.plots, nrow=3, as.table=F))
```

We also plot the expected and observed movements for all countries and years, as shown in Fig. 3C.

```{r, echo = include.code, fig.height = 4, fig.width = 4}
    dfo <- df %>%
      group_by(a = actual.angle10) %>%
      summarise(n=n()) %>%
      mutate(frequency=n/sum(n))
    dfe.tmp <- df %>%
      group_by(a = round(canonical.angle10)) %>%
      summarise(n=n()) %>%
      mutate(freq=n/sum(n))
    
    #smoothing expected path
    byn <- seq(-180,179,10)
    dfe <- as.data.frame(matrix(NA, nrow=length(byn), ncol=2))
    colnames(dfe) <- c("a", "freq")
    for (i in 1:length(byn)){
      dfe$freq[i] <- ifelse(is.na(dfe.tmp$freq[match(byn[i], dfe.tmp$a)]),0,
                            dfe.tmp$freq[match(byn[i], dfe.tmp$a)])
      dfe$a[i] <- byn[i]
    }
    dfe$frequency <- rep(NA, nrow(dfe))
    for (r in 1:nrow(dfe)){
      if (r==1) {dfe$frequency[r] <- mean(dfe$freq[(r):(r+2)], na.rm=T)}
      if (r==2) {dfe$frequency[r] <- mean(dfe$freq[(r-1):(r+2)], na.rm=T)}
      if (r>=3) {dfe$frequency[r] <- mean(dfe$freq[(r-2):(r+2)], na.rm=T)}
    }
    
    #merging the datasets together into one
    byn <- seq(-180,179,10)
    dfa <- data.frame(a=rep(byn,3), obs.exp=c(rep("O",length(byn)),rep("FF",length(byn)),rep("E",length(byn))), frequency=rep(NA, length(byn)*3))
    for (i in 1:length(byn)){
      dfa$frequency[which(dfa$obs.exp=="O")[i]] <- dfo$frequency[match(dfa$a[i], dfo$a)]
      dfa$frequency[which(dfa$obs.exp=="E")[i]] <- dfe$frequency[match(dfa$a[i], dfe$a)]
    }
    dfa$label <- c(rep("Observed",length(byn)), rep("blank",length(byn)), rep("Expected",length(byn)))
    dfa$frequency[is.na(dfa$frequency)] <- 0 #because no change is NA
    dfa$frequency[which(dfa$obs.exp=="FF")] <- NA
    dfa$a[dfa$a==seq(-180,-100,10)] <- 360+dfa$a[dfa$a==seq(-180,-100,10)] #hack so the top is -90 degrees
    
    #estimating median difference in angle
    dfd <- df %>%
      summarise(med=median(angle.diff)*(-1)) #want positive 90 top, and -90 bottom
    
    #plot it
    dfa$obs.exp <- as.numeric(dfa$obs.exp)+2
    all.together <-  ggplot(dfa, aes(x=a, y=obs.exp, fill=(frequency))) +
      geom_tile(colour="white") +
      scale_fill_distiller(palette="YlGnBu", direction=1, limits=c(0,0.2), na.value="white") + #Greys
      ylim(c(0, max(dfa$obs.exp) + 0.5)) +
      coord_polar(theta="x") + annotate("text", x = 0, y = 0, label = round(dfd[1,1])) +
      theme(panel.background=element_blank(),
            axis.title=element_blank(),
            panel.grid=element_blank(),
            axis.text.x=element_blank(),
            axis.ticks=element_blank(),
            axis.text.y=element_text(size=5)) +
      ggtitle("All countries and years")
    
    #estimating IQR for difference in angle
    iqr.all <- quantile(df$angle.diff*(-1), c(0.25, 0.5,0.75)) 
    print("Median and IQR observed minus expected angle for all movements")
    print(iqr.all)
    
    all.together
    
```

Along with this analysis, we used a method for estimating the susceptibility in each year of age which was developed by @tak2015. Each age cohort's susceptibility is estimated based on its opportunity for immunization (via routine and supplementary activities) and risk of natural infection. The probability of immunization was estimated per WHO reported administrative vaccination coverage estimates (@who). The probability of natural infection by age was estimated by assuming a constant hazard of infection over age that scaled each year relative to the proportional decline in estimated measles incidence corrected for under-reporting. Measles incidence, corrected for under-reporting, was estimated using a state space model per @statespace and @simons2012. The following chunks of code first uses the state-space model to estimate the number of measles cases (corrected for under-reporting) by year and country, then goes on to infer susceptibility by age for each country and each year.

```{r, eval=F, include=F, eval = FALSE}
##' this chunk of code runs the state space model that estimates measles incidence as "output-estimated_incidence.csv"
##' and then copied and renamed "State_space_cases_new.csv" 
source("state.space.model/run_state_space_model.R")
```

```{r, eval=F, include=F, eval = FALSE}
##' this chunk of code infers susceptiblity from the estimated measles incidence, birth rates, and vaccination rates
All.countries = as.character(unique(canonical.path.data$Country))
All.countries = All.countries[-(which(All.countries %in% c("")))]

All.countries= All.countries[order(All.countries)]
years = seq(1990,2017)

number.of.susceptibles = number.of.individuals = data.frame(matrix(0, length(years) * length(All.countries), 62))
colnames(number.of.susceptibles) = colnames(number.of.individuals) = c("Country", "Year", paste("X",0:59, sep = ""))
mean.age.sus = data.frame(matrix(0, length(All.countries), length(years) + 1))
colnames(mean.age.sus) = c("", paste(years))
mean.age.sus[,1] = All.countries

count = 1
for(i in 1 : length(All.countries)){
    for(j in 1 : length(years)){
        list[tot.susc,tot.susc.disrupted,
             pred,ages, rel.foi,
             prop.vacc, prop.vacc.disrupted,
             prop.nat.imm, coverage, years.sia,
             age.range, ages.vacc, coverage.sia,
             mat.protect] = getLexisVaccPopStructSpecifyYear(country = All.countries[i],
                                                             barchart.susc = T,
                                                             proportion.pop=F,
                                                             year = years[j], max.x = 3000000,
                                                             output.plot = F)
        tot.imm <- mat.protect+(pred-mat.protect)*prop.vacc + (pred-mat.protect)*(1-prop.vacc)*(prop.nat.imm)
        
        denom <- rep(1,length(pred))
        tot.susc <- pred-tot.imm
        
        k = which(mean.age.sus[,1] == All.countries[i])
        l = which(colnames(mean.age.sus) == years[j])
        mean.age.sus[k, l] = sum(tot.susc * 0:59)/sum(tot.susc)
        
        number.of.individuals[count, ] = c(All.countries[i], years[j], round(as.numeric(pred)))
        number.of.susceptibles[count, ] = c(All.countries[i], years[j], round(as.numeric(tot.susc)))
        count = count + 1
    }
    print(paste(All.countries[i], "done"))
}

for(i in 0:59){
    number.of.susceptibles[ , paste("X", i, sep = "")] = as.numeric(number.of.susceptibles[ , paste("X", i, sep = "")])
    number.of.individuals[ , paste("X", i, sep = "")] = as.numeric(number.of.individuals[ , paste("X", i, sep = "")])
}
write.csv(number.of.susceptibles, "data/est_sus_by_year.csv")
write.csv(number.of.individuals, "data/est_age_dist_by_year.csv")
write.csv(mean.age.sus, "data/mean_age_sus.csv", row.names=F)
```

For ease, we can simply read in the already estimated proportion susceptible by age, year, and country.

```{r, echo = include.code, include=F}
##' import the estimated susceptibles for each country and year.
estimated.susceptibles.by.year = read.csv("data/est_sus_by_year.csv", stringsAsFactors = F)
estimated.age.dist.by.year = read.csv("data/est_age_dist_by_year.csv", stringsAsFactors = F)
```

We can then use the dataset of the number of susceptibles by country, year, and age, to link each country and year to the canonical path and determine the estimated total proportion of susceptibles, and age-specific proportion susceptibles at each canonical path point. 

```{r, echo = include.code, include=F}
estimated.susceptibles.by.year = estimated.susceptibles.by.year[, -(1)]
estimated.age.dist.by.year = estimated.age.dist.by.year[, -(1)]
##' run code to generate the number of susceptibles by age by canonical path point
list[dist.by.age, canonical.path, prop.sus, d1, prop.sus.by.age] = 
    plots.for.sus.dist.by.canonical.path (d1 = canonical.path.data, 
                                          d2 = estimated.susceptibles.by.year, 
                                          d3 = estimated.age.dist.by.year,
                                          rep.cases = use.reported.cases,
                                          regions,
                                          make.inc.cv.scale.same = 1,
                                          sqrt.inc = F,
                                          connect.canonical.path.to.zero = 0,
                                          log.incidence = 1,
                                          make.figure.plot = F)
cols.1 <- colorRampPalette(c("red", "white", "blue"))(length(canonical.path$x))
```

Here we plot the proportion of susceptible individuals by canonical path point (Fig. 4C in the paper). The horizontal dashed lines display the critical level of immunity if the basic reproduction number of measles is 15 or 20 (critical level = 1-(1 / basic reproductive number)).

```{r, echo = include.code, fig.height = 6, fig.width =10}

    plot( prop.sus[, 2]*100, pch = 21, cex = 2,
          xlab = '', ylab= '% susceptible', bty="n",
          xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black')
    smoo <- with(prop.sus[!is.na(prop.sus$y),],smooth.spline(x,y*100, df=4))
    result <- with(prop.sus, predict(smoo,x[is.na(y)]))
    prop.sus[is.na(prop.sus$y),] <- result
    lines(smoo, col='black', lwd=2)
    abline(h = 5, lwd = 2, lty = 2)
    abline(h = ((1/15)*100), lwd = 2, lty = 2)
    
```

We also have data on the mean age of measles cases in multiple countries from 2000-2016. This data has increasing numbers of data as time goes on.

```{r, echo = include.code, fig.height = 5, fig.width = 10}

##' import the data on mean age of measles cases 
mean.measles.age <- read.csv("data/mean_age_meas.csv", stringsAsFactors = F)

##' melt the mean age of measles data 
melt.mean.measles.age = melt(mean.measles.age, id.vars = c("ISO3", "WHO_REGION", "Country")) %>%
    na.omit

##' remove the X from the year data
melt.mean.measles.age$variable = substr(melt.mean.measles.age$variable, 2, 5) %>% as.numeric

##' rename the columns 
colnames(melt.mean.measles.age) = c("ISO3", "WHO_REGION", "country", "year", "value")

##' remove data for countries which are not included in the canonical path data
k = which(melt.mean.measles.age$country %in% c("occupied Palestinian territory", "#N/A"))
melt.mean.measles.age = melt.mean.measles.age[-(k), ]

##' add a column which will contain the canonical path location of each country and year
melt.mean.measles.age$closest = NA

##' find the canonical path location for each country and year in the mean measles age data
for(i in 1 : nrow(melt.mean.measles.age)){
    k = which(d1$Country == melt.mean.measles.age$country[i] &
                                                     d1$Year == melt.mean.measles.age$year[i])
    if(length(k) > 0){
        melt.mean.measles.age$closest[i] = d1$closest[k]
    }
}

##' find all the locations on the canonical path that the data on the mean age of measles are on
all.closest = unique(melt.mean.measles.age$closest)

##' which locations on the canonical path are not included in this data
missing = setdiff(1:max(all.closest, na.rm = T), all.closest)

##' generate a data set called X, that has the same dimensions as the melted mean measles data
X = data.frame(matrix(NA, length(missing),6))

##' give this data set the same column names as the melted data
colnames(X) = colnames(melt.mean.measles.age)

##' assign the missing canonical path points to the data set X, along with a value outside of the range of the possible mean age of the measles cases
X$closest = missing
X$value = -100

##' combine the melted measles data and the missing data so that we can make a boxplot of the mean age of measles cases
melt.mean.measles.age = rbind(melt.mean.measles.age, X)
```

Again, these data can be linked to canonical path point. Here we make a boxplot of the estimated distribution of ages against the mean age of measles cases, to see how they compare (Fig. 4B). The estimates are hollow-wider boxes, and the case data is filled narrow purple boxes. 

```{r, echo = include.code, fig.height = 5, fig.width = 10}

boxplot(age ~ point, data = dist.by.age, outline = F, bty = "n",
        ylim = c(0, 60), xaxt = "n", frame.plot = F, xlab = "position on canonical path",
        cex.axis = 1.5, cex.lab = 1.5)

boxplot(value/12 ~ closest, 
        data = melt.mean.measles.age, boxlwd=0.01, whisklwd=2, staplelwd=2.5,
        ylim = c(0,700/12), border = rgb(red = 10/255, green = 10/255, blue = 100/255, alpha = 0.55),
        col = rgb(red = 1/255, green = 10/255, blue = 100/255, alpha = 0.4),
        ylab ="age", xaxt = "n", frame.plot = F,
        pars = list(boxwex = 0.38, staplewex = 0.5, outwex = 0),
        cex.axis = 1.5, cex.lab = 1.5, outline = F, add= T)

axis(1, at = c(1,length(unique(dist.by.age$point))),labels = c("",""))


```


The figures below show the estimated age-specific proportion seropositive (Fig. 4A), the age at which an SIA would have to go up to in order to cover 90% of all susceptibles (Fig. 4D), the proportion of susceptibles who are under 5 years old (Fig. 4E), and the proportino of susceptibles who are under 15 years old (Fig. 4F) for each position on the canonical path.

```{r, echo = include.code, include = F}

prop.sus.by.age <- prop.sus.by.age[,-1]
a = 1:59
n = 5
min = c(seq.int(from=1, to=length(a), by=n))
max = c((min-1)[2:length(min)], length(a))
prop.sus.by.age.group = apply(prop.sus.by.age, 1, function(x) sapply(1:length(min), function(i) mean(x[min[i]:max[i]])))
prop.sus.by.age.group <- rbind(prop.sus.by.age.group, prop.sus[, 2]) #add in prop.sus for ALL ages to the last row (same as Fig. 2A)

dist.by.age.rep = dist.by.age
points = unique(dist.by.age.rep$point)
perc.by.age.sia.rep = data.frame(matrix(NA, max(points), 5))
perc.by.age.sia.rep[,1] = 1:max(points)
colnames(perc.by.age.sia.rep) = c("pos", "perc.to.5", "perc.to.10", "perc.to.15", "age.for.90.perc")

for(i in 1 : length(points)){
    p = dist.by.age.rep[which(dist.by.age.rep$point == points[i]), ]
    if(nrow(p) > 1){ #xxamy this if statement was added
    p1 = p %>% filter(age <= 5)
    p2 = p %>% filter(age <= 10)
    p3 = p %>% filter(age <= 15)
    p4 = p[order(p$age), ]
    
    perc.by.age.sia.rep[points[i], ] = c(points[i], 
                             nrow(p1)*100/nrow(p),
                             nrow(p2)*100/nrow(p),
                             nrow(p3)*100/nrow(p),
                             p4[floor(nrow(p)*0.9), 2] )
    }
}


##'  adjust positions of the percentage age to sia age to go from 1 to
##' the number of points that have countries assigned to them
perc.by.age.sia.rep$pos = 1:nrow(perc.by.age.sia.rep)
#plot(perc.by.age.sia.rep$pos, perc.by.age.sia.rep$age.for.90.perc)
#k=unique(dist.by.age$point)
#k = k[order(k)]

```


```{r, echo = include.code, fig.height = 6, fig.width = 9.5}

levelplot(t(as.matrix(prop.sus.by.age.group)), ylab="age (years)", 
          xlab="position on canonical path", xaxt = "n",
          col.regions=colorRampPalette(brewer.pal(9,"Greys")),
          scales=list(y=list(at=1:13, labels=c("<5","5-9","10-14","15-19","20-24","25-29","30-34","35-39","40-44","45-49",
                                                                                            "50-54","55-59", "all"))))

plot( perc.by.age.sia.rep$pos, perc.by.age.sia.rep$perc.to.5, pch = 21, cex = 2,
      xlab = '', ylab= '% of susceptibles 5 or under', bty="n",
      xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black',ylim = c(10,60))
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$perc.to.5),], smooth.spline(pos,perc.to.5))
result <- with(perc.by.age.sia.rep, predict(smoo,pos[is.na(perc.by.age.sia.rep$perc.to.5)]))
perc.by.age.sia.rep[is.na(perc.by.age.sia.rep$perc.to.5),2] <- result$y
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$perc.to.5),], smooth.spline(pos,perc.to.5), cv = T)
lines(smoo, col='black', lwd=2)
abline(h = 50, lwd = 2, lty = 2)
abline(h = 2/30, lwd = 2, lty = 2)

plot(perc.by.age.sia.rep$pos, perc.by.age.sia.rep$age.for.90.perc, pch = 21, cex = 2,
     xlab = '', ylab= 'oldest SIA age to reach 90% of susceptibles', bty="n",ylim = c(10,60),
     xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black')
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$age.for.90.perc),], smooth.spline(pos,age.for.90.perc, df=6))
result <- with(perc.by.age.sia.rep, predict(smoo,pos[is.na(perc.by.age.sia.rep$age.for.90.perc)]))
perc.by.age.sia.rep[is.na(perc.by.age.sia.rep$age.for.90.perc),5] <- result$y
lines(smoo, col='black', lwd=2)

plot( perc.by.age.sia.rep$pos, perc.by.age.sia.rep$perc.to.15, pch = 21, cex = 2,
      xlab = '', ylab= '% of susceptibles 15 or under', bty="n",
      xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black')
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$perc.to.15),], smooth.spline(pos,perc.to.15))
result <- predict(smoo,perc.by.age.sia.rep$pos)
perc.by.age.sia.rep[is.na(perc.by.age.sia.rep$perc.to.15),4] <- result$y
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$perc.to.15),], smooth.spline(pos,perc.to.15), cv = T)
lines(smoo, col='black', lwd=2)

```

The remainder of this notebook creates the supplemental figures we have not yet reproduced above.  The following codes reproduces Fig. S1.

```{r, echo = F}

list[subset.pop.by.year, subset.vaccination, subset.birth.rates, subset.data] = get.data.for.animation(regions)
nigeria.pop = subset.pop.by.year %>% filter(Country.Name== "Nigeria") %>% data.frame 
j = which(colnames(nigeria.pop) %in%paste("X", 1981:2017, sep = ""))
nigeria.pop = nigeria.pop[j] %>% t %>% data.frame
colnames(nigeria.pop) = "pop"
nigeria.pop$pop = nigeria.pop$pop %>% as.character %>% as.numeric

cases.by.country.by.year = read.csv("data/Measles_cases_by_year.csv", stringsAsFactors = FALSE)

nigeria.cases = cases.by.country.by.year %>%
    filter(Cname == "Nigeria") 

j = which(colnames(nigeria.cases) %in% paste("X", 1981:2017, sep = ""))

nigeria.cases = nigeria.cases[rev(j)] %>% as.character %>% as.numeric %>% data.frame 
nigeria.cases = cbind(seq(1981, 2017), nigeria.cases)
colnames(nigeria.cases) = c("year", "cases")
nigeria.inc = data.frame(cbind(1981:2017, 100000 * nigeria.cases$cases / nigeria.pop$pop))
colnames(nigeria.inc) = c("year", "inc")

ggplot(nigeria.inc, aes(x = year, y = inc)) + geom_point(cex = 3, col = 'grey') +
     geom_line() + theme_bw() + ylab("incidence per 100,000")

```

```{r, echo = F}

year.shift.inc = 2
cutoff = 50
w2 = matrix(0, nrow(nigeria.inc), nrow(nigeria.inc))
x2 = 1981:2017
for (i in 10 : length(x2)){
    ##' set up the gaussian weights for averaging
    
    w.input = x2 - x2[i] + year.shift.inc
    w2[i, ] = output.weights.gaussian.with.cutoff(w.input, st.dev=3, cutoff)
    
    ##' make sure that the weights add up to 1 for each of the specific weightings
    j = which(w.input == (year.shift.inc + 1))
    if(length(j) > 0){
        w2[i,j : length(w2[i,])] = 0
        w2[i, ] = w2[i, ] / sum(w2[i, ])
    }
    if(i == length(x2)){
        w2[i, ] = w2[i, ] / sum(w2[i, ])
    }
    
}

k = cbind(w2[10,], 1981:2017, "1990")
k = rbind(k, cbind(w2[30, ],1981:2017, "2010"))
k = data.frame(k)
colnames(k) = c("weight", "year", "w")
k$weight[which(k$weight == 0)] = NA
k$weight = as.numeric(as.character(k$weight))
k$year = as.numeric(as.character(k$year))


ggplot(k, aes(x = year, y = weight, col = factor(w))) + geom_point(cex = 3) +
    geom_line() +
    theme_bw() + theme(legend.position="none") +
    scale_colour_manual(values=wes_palette("Darjeeling1")[c(1,5)]) #potentially Darjeeling without the 1 pending R version


```


```{r, echo = F}
weighted.mean.inc = data.frame(cbind(1981:2017, NA, "A"))
colnames(weighted.mean.inc) = c("year", "mean.inc", "type")
weighted.mean.inc$mean.inc = as.numeric(as.character(weighted.mean.inc$mean.inc))
weighted.mean.inc$type = as.character(weighted.mean.inc$type)
weighted.mean.inc$year = as.numeric(as.character(weighted.mean.inc$year))
for(i in 1 : nrow(w2)){
    weighted.mean.inc$mean.inc[i] = sum(w2[i, ] * nigeria.inc$inc)
}
weighted.mean.inc$type[which(weighted.mean.inc$year == 1990)] = "B"
weighted.mean.inc$type[which(weighted.mean.inc$year == 2010)] = "C"
weighted.mean.inc$type = as.factor(weighted.mean.inc$type)
weighted.mean.inc = filter(weighted.mean.inc, mean.inc > 0)


p <- ggplot(weighted.mean.inc, aes(x = year, y = mean.inc))
p + geom_point(cex = 3, aes(col = factor(type))) +
    geom_line() +
    theme_bw() + theme(legend.position="none") +
        scale_color_manual(values = c("grey",wes_palette("Darjeeling1")[c(1,5)]) ) + 
        ylab("mean incidence per 100,000") + xlim(c(1990, 2017))


```

The following codes reproduces Fig. S2. 

```{r,echo = F}

wt.cv <- function(x, wt){
    return(wt.sd(x, wt)/ wt.mean(x, wt))
}
cases.by.country.by.year = subset.data
bolivia.cases = filter(cases.by.country.by.year, Country == "Bolivia")
bolivia.cases = bolivia.cases[paste("X", 1981:2017, sep = "")]


bolivia.cv = matrix(0, 37, 2)
for(i in 1 : 37){
    bolivia.cv[i, 1] = wt.cv(as.numeric(as.character(bolivia.cases)), w2[i, ])
    if(i > 9){
        if(mean(as.numeric(as.character(bolivia.cases[paste("X", (i+1980-9):(i+1989-9),sep = "")])), na.rm = T) >0){
            bolivia.cv[i, 2] = sd(bolivia.cases[paste("X", (i+1980-9):(i+1989-9), sep = "")], na.rm = T)/
                mean(as.numeric(as.character(bolivia.cases[paste("X", (i+1980-9):(i+1989-9),sep = "")])), na.rm = T)
        }
    }
}



weighted.cv = data.frame(cbind(1990:2017, bolivia.cv[10:37, 1]))
colnames(weighted.cv) = c("year", "cv")
unweighted.cv = data.frame(cbind(1990:2017, bolivia.cv[10:37, 2]))
colnames(unweighted.cv) = c("year", "cv")
bolivia.cases = data.frame(cbind(1981:2017, as.numeric(as.character(bolivia.cases))))
colnames(bolivia.cases)  = c("year", "cases")


##' plot cases, weighted cv and unweighted cv for bolivia

bol.cases = ggplot(bolivia.cases, aes(x = year, y = cases)) + geom_point(cex = 3, col = 'grey') +
    geom_line() + theme_classic() 

unweight.cv = ggplot(unweighted.cv, aes(x = year, y = cv)) + geom_point(cex = 3, col = 'grey') +
    geom_line() + theme_bw() 

weight.cv = ggplot(weighted.cv, aes(x = year, y = cv)) + geom_point(cex = 3, col = 'grey') +
    geom_line() + theme_bw() 

##' make plot
multiplot(bol.cases, weight.cv, unweight.cv, cols = 1)




```

```{r, echo = F}
   window.length = 10
   gaussian.st.dev = 3
   cutoff = 50
   year.shift.inc = 2
   list[subset.pop.by.year, subset.vaccination, subset.birth.rates, subset.data] = get.data.for.animation(regions)
  
  x = seq(1980, 2017) 
  
  ##' interpolate the datasets to have entries for all points in time once the interpolation is done.
  list[interp.subset.data, interp.subset.vacc, interp.subset.br, interp.subset.pop] = interp.datasets(subset.data, 
                                                                                                      subset.vaccination, 
                                                                                                      subset.birth.rates, 
                                                                                                      subset.pop.by.year,
                                                                                                      x,
                                                                                                      x)
  
  ##' output matrices the correct size for our animation
  list[mean.cases, coeff.var.cases, incidence.per.1000, mean.br, mean.vac] = 
    prepare.matrices.for.animation(interp.subset.data, subset.data)
  
  ##' number of unique years that we will have data for. The longer the window, the less unique years of data.
  num.windows = length(x) - window.length + 1
  
  ##' first year of data
  year = 1980
  
  ##' setting up the datasets
  coeff.var = matrix(0, length(subset.data[ , 1]), num.windows)
  incidence.per.1000 = matrix(0, length(subset.data[ , 1]), num.windows)
  mean.br = matrix(0, length(subset.data[ , 1]), num.windows)
  mean.vac = matrix(0, length(subset.data[ , 1]), num.windows)
  
  ##' do calculations that calculate the coefficient of variation, incidence per 100, mean birth rate and
  ##' mean vaccination rate over periods of length given by the window length.
  for ( j in 1 : num.windows){
    for ( i in 1 : length(subset.data[ , 1])){
      coeff.var[i, j]  =  sd(interp.subset.data[i, paste(seq(year, year + window.length - 1))], na.rm = TRUE) /  
        mean(as.numeric(interp.subset.data[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE)
      if(is.na( mean(as.numeric(interp.subset.data[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE)) == FALSE ){
        if( mean(as.numeric(interp.subset.data[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE) == 0) {
          coeff.var[i, j]  =  0
        } 
      }
      incidence.per.1000[i, j]  =  sum(as.numeric(interp.subset.data[i,  paste(seq(year, year + window.length - 1))]) / 
                                         as.numeric(interp.subset.pop[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE) * 1000
      if(length(which(is.na(as.numeric(interp.subset.br[i, paste(seq(year, year + window.length - 1))])))) < window.length){
        mean.br[i, j]  =  mean(as.numeric(interp.subset.br[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE)
      }
      if(length(which(is.na(as.numeric(interp.subset.vacc[i, paste(seq(year, year + window.length - 1))])))) < window.length){
        mean.vac[i, j]  =  mean(as.numeric(interp.subset.vacc[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE)
      }
    }
    year = year + 1
  }
  
  incidence.per.1000.each.year = matrix(0, nrow(subset.data), length(seq(1980, 2017)))
  for(i in 1 : nrow(subset.data)){
    incidence.per.1000.each.year[i, ] = 1000 * as.numeric(interp.subset.data[i,  paste(seq(1980, 2017))]) / 
      as.numeric(interp.subset.pop[i, paste(seq(1980, 2017))])
    
  }
  ##' for calculating the weighted coefficient of variation, we need to take the weighted
    ##' mean of locally calculated coefficient of variations. The following function will
    ##' generate the matrix of weights used to calculate this weighted average.
    ##' the weights are gaussian, centred on a specific year, with
    ##' specified number of years for the standard deviation

    w1 = generate.cv.weights(coeff.var,
                             gaussian.st.dev,
                             cutoff)

    ##' for incidence, birth rate and vaccination rate, we can weight slightly differently
    ##' as there is no issue with the weighting of yearly calculated values.
    ##' the following function produces the weights used for weighting these variables

    w2 = generate.other.weights(d = incidence.per.1000.each.year,
                                window.length,
                                gaussian.st.dev,
                                cutoff, year.shift.inc)

  
  ##' make a set of matrices that are the same size as the matrices containing the data.
  coeff.2 = coeff.var
  incidence.2 = incidence.per.1000
  mbr2 = mean.br
  mvacc2 = mean.vac
  for(i in 1 : length(coeff.var[1, ])){
    for(j in 1 : length(coeff.var[, 1])){
      ##' make the entries of these newly created matrices to be the weighted averages of the originally calculated datasets
      coeff.2[j, i] = sum(coeff.var[j, ] * w1[i, ], na.rm = T)
      incidence.2[j, i] = sum(incidence.per.1000.each.year[j, ] * w2[i, ], na.rm = T)
      mbr2[j, i] =  sum(mean.br[j, i] * w2[i, ], na.rm = T)
      mvacc2[j, i] = sum(mean.vac[j, i]* w2[i, ], na.rm = T)
      
      ##' Should we do weighted average of birth rate and vaccination rate?
      ##' If so uncomment the next two lines
      
       #mbr2[j, i] = sum(mean.br[j, ] * w1[i, ], na.rm = T)
       #mvacc2[j, i] = sum(mean.vac[j, i] * w1[i, ], na.rm = T)
    }
  }
  
  ##' set the original data to be equal to the weighted data
  coeff.var.cases = coeff.2
  incidence.per.1000 = incidence.2
  mean.br = mbr2
  mean.vac = mvacc2
  
  
  
```


```{r, echo = F}

  ##' collect cv data for Nigeria, unweighted
  
    coeff.var = cbind(cbind(subset.data$Country, subset.data$WHO_REGION), coeff.var)
    coeff.var = data.frame(coeff.var)
    colnames(coeff.var) = c("Country", "WHO_REGION", paste("X", 1989:2017, sep = ""))
    nigeria.cv = filter(coeff.var, Country == "Nigeria")
    nigeria.cv[paste("X", 1989:2017, sep = "")] = 
    as.numeric(as.character(as.matrix(nigeria.cv[paste("X", 1989:2017, sep = "")])))

    cvs = as.matrix(as.numeric(as.character(nigeria.cv[paste("X", 1989:2017, sep = "")])))
    nigeria.cv = data.frame(cbind(1989:2017, cvs))
    colnames(nigeria.cv) = c("year", "cv")
    nigeria.cv = filter(nigeria.cv, year > 1989)
    
    
    ##' plot the Nigeria unweighted cv data
    ggplot(nigeria.cv, aes(x = year, y = cv)) + geom_point(cex = 3, col = 'grey') +
    geom_line() + theme_bw() + ylab("coefficient of variation")
    
    
    
    ##' collect the weighted cv data for Nigeria, 
    coeff.var.cases = cbind(cbind(subset.data$Country, subset.data$WHO_REGION), coeff.var.cases)
    coeff.var.cases = data.frame(coeff.var.cases)
    colnames(coeff.var.cases) = c("Country", "WHO_REGION", paste("X", 1989:2017, sep = ""))
    nigeria.cv = filter(coeff.var.cases, Country == "Nigeria")
    nigeria.cv[paste("X", 1989:2017, sep = "")] = 
    as.numeric(as.character(as.matrix(nigeria.cv[paste("X", 1989:2017, sep = "")])))

    cvs = as.matrix(as.numeric(as.character(nigeria.cv[paste("X", 1989:2017, sep = "")])))
    nigeria.cv = data.frame(cbind(1989:2017, cvs))
    colnames(nigeria.cv) = c("year", "cv")
    nigeria.cv = filter(nigeria.cv, year > 1989)

    ##' plot the Nigeria weighted cv data
    ggplot(nigeria.cv, aes(x = year, y = cv)) + geom_point(cex = 3, col = 'grey') +
    geom_line() + theme_bw() + ylab("mean coefficient of variation")
  

```

We used an established discrete time age-structured mathematical model, introduced in @metcalf2012a and @metcalf2012b to simulate measles transmission dynamics for each country in the WHO Americas and Africa Regions.  We applied the same Gaussian weights as in the empirical analysis to create an incidence-space for each country over time, and compared this to estimates of measles incidence per @statespace and @simons2012.

```{r, echo=F}
country.codes <- read.csv("./data/country_codes2.csv")
country.names.amro <- country.codes$Report_country_name[country.codes$Region_Code=="AMRO"]
country.names.afro <- country.codes$Report_country_name[country.codes$Region_Code=="AFRO"]

#need population size 1981 to 2017 per AMRO and AFRO country 
pop.amro <- matrix(NA, length(country.names.amro), 37) #1981 to 2017
pop.afro <- matrix(NA, length(country.names.afro), 37) #1981 to 2017
for (c in 1:length(country.names.amro)){
  country <- country.names.amro[c]
  cc <- as.numeric(country.codes$uncode[country.codes$Report_country_name==country])
  data(pop) #from wpp2015 package
  data(popproj) #for population for 2016 and 2017
  pop.total.1950.2020.by5 <-  as.numeric(cbind(pop[pop$country_code==cc,3:ncol(pop)], popproj[popproj$country_code==cc,3]))
  f <- smooth.spline(seq(1950,2020,5), pop.total.1950.2020.by5)
  pop.total.1981.2017 <- predict(f, seq(1981,2017,1))$y*1000
  pop.amro[c,] <- pop.total.1981.2017
}
for (c in 1:length(country.names.afro)){
  country <- country.names.afro[c]
  cc <- as.numeric(country.codes$uncode[country.codes$Report_country_name==country])
  data(pop) #from wpp2015 package
  data(popproj) #for population for 2016 and 2017
  pop.total.1950.2020.by5 <-  as.numeric(cbind(pop[pop$country_code==cc,3:ncol(pop)], popproj[popproj$country_code==cc,3]))
  f <- smooth.spline(seq(1950,2020,5), pop.total.1950.2020.by5)
  pop.total.1981.2017 <- predict(f, seq(1981,2017,1))$y*1000
  pop.afro[c,] <- pop.total.1981.2017
}

##' sort countries (names, iso3, and uncodes) by population size
amro.order <- match(rev(sort(pop.amro[,30])), pop.amro[,30])
afro.order <- match(rev(sort(pop.afro[,30])), pop.afro[,30])
pop.amro <- pop.amro[amro.order,]
uncodes.amro <- country.codes$uncode[country.codes$Region_Code=="AMRO"][amro.order]
country.names.amro <- country.codes$Report_country_name[country.codes$Region_Code=="AMRO"][amro.order]
iso3.amro <- country.codes$ISO3_code[country.codes$Region_Code=="AMRO"][amro.order]
pop.afro <- pop.afro[afro.order,]
uncodes.afro <- country.codes$uncode[country.codes$Region_Code=="AFRO"][afro.order]
country.names.afro <- country.codes$Report_country_name[country.codes$Region_Code=="AFRO"][afro.order]
iso3.afro <- country.codes$ISO3_code[country.codes$Region_Code=="AFRO"][afro.order]

##' download simulated data
incs.amro <- cvs.amro <- matrix(NA, length(uncodes.amro)*100, 28)
for (c in 1:length(uncodes.amro)){
  index <- min(which(is.na(incs.amro)))
  incs <- read.csv(paste("./sim.data/incs",  uncodes.amro[c], ".csv", sep="_"))[1:28,-1] #1990 through 2017
  incs.amro[index:(index+99),] <- t(incs)
  cvs <- read.csv(paste("./sim.data/cvs",  uncodes.amro[c], ".csv", sep="_"))[1:28,-1] #1990 through 2017
  cvs.amro[index:(index+99),] <- t(cvs)
}
incs.afro <- cvs.afro <- matrix(NA, length(uncodes.afro)*100, 28)
for (c in 1:length(uncodes.afro)){
  index <- min(which(is.na(incs.afro)))
  incs <- read.csv(paste("./sim.data/incs",  uncodes.afro[c], ".csv", sep="_"))[1:28,-1] #1990 through 2017
  incs.afro[index:(index+99),] <- t(incs)
  cvs <- read.csv(paste("./sim.data/cvs",  uncodes.afro[c], ".csv", sep="_"))[1:28,-1] #1990 through 2017
  cvs.afro[index:(index+99),] <- t(cvs)
}

cvs <- rbind(cvs.amro, cvs.afro)
incs <- rbind(incs.amro, incs.afro)

##' download estimated data for comparison - incidence per 100,000 per the state-space model
ss <- read.csv("data/State_space_cases_new.csv")
ss.inc.amro <- matrix(NA, length(uncodes.amro), ncol(ss)-1)
for (c in 1:length(uncodes.amro)){
  ss.cases <- as.numeric(ss[which(as.character(ss$iso)==as.character(iso3.amro[c])),2:ncol(ss)])
  ss.inc.amro[c,] <- ss.cases/pop.amro[c,]
}
ss.inc.amro <- as.data.frame(cbind(uncodes.amro, ss.inc.amro))
ss.inc.afro <- matrix(NA, length(uncodes.afro), ncol(ss)-1)
for (c in 1:length(uncodes.afro)){
  ss.cases <- as.numeric(ss[which(as.character(ss$iso)==as.character(iso3.afro[c])),2:ncol(ss)])
  ss.inc.afro[c,] <- ss.cases/pop.afro[c,]
}
ss.inc.afro <- as.data.frame(cbind(uncodes.afro, ss.inc.afro))

##' get gausian weighted incs and cv of state-space estimates 
list[incs.amro.ss, Am.cv.ss] <- return.cv.inc.from.ss(ss.inc.amro)
list[incs.afro.ss, Af.cv.ss] <- return.cv.inc.from.ss(ss.inc.afro)

##' square root per 100,000 people, this is the same scale as Figure 1A
incs.amro.ss <- sqrt(incs.amro.ss*100000)
incs.afro.ss <- sqrt(incs.afro.ss*100000)
incs.amro <- sqrt(incs.amro*100000)
incs.afro <- sqrt(incs.afro*100000)

```

We plotted AFRO countries in incidence-space (Fig. S3-S8).

```{r, echo = include.code, fig.height = 4, fig.width = 4}

##' make colour palette
colfunc = colorRampPalette(c("green", "white", "orange"))

##' plot AFRO
par(bty="l", mar=c(4, 4, 1, 2) + 0.1)
ylim = c(0, as.numeric(max(incs.afro), na.rm = T))
xlim = c(0,4)
for (c in 1:length(uncodes.afro)){
   plot(0, bg = colfunc(28), col = 'black', pch = '', bty="n", ylab="incidence per 100,000", xlab="coefficent of variation", yaxt="n",
         xlim = xlim, ylim = ylim, mgp=c(2.5, 1.1, 0))
    axis(2, sqrt(c(1,100,500,1000,2000,4000)), labels=F)
    text(y=sqrt(c(1,100,500,1000,2000,4000)), par("usr")[1] - 0.05, 
         labels = c(1,100,500,1000,2000,4000), srt = 45, pos = 2, xpd = TRUE)
    title(country.names.afro[c], line=0)
    for(i in 1:100){
      points(cvs.afro[((100*c)-(100-i)), 2:ncol(cvs.afro)],
             incs.afro[((100*c)-(100-i)), 2:ncol(incs.afro)], 
             bg = colfunc(28), col = 'black', pch = 21)
    }
    lines(colMeans(cvs.afro[(100*c-99):(100*c), 2:ncol(cvs.afro)]), 
          colMeans(incs.afro[(100*c-99):(100*c), 2:ncol(incs.afro)]), col = 'black')
    points(Af.cv.ss[c,], incs.afro.ss[c,], pch=3, bg = colfunc(28))
    lines(Af.cv.ss[c,], incs.afro.ss[c,], col="grey")
    LEGEND(1.8,sqrt(4000), c("simulated", "estimated"), pch=c(21,3), line.col=c("black","grey"), pt.col="black",lty=1)
}

```

We plotted AMRO countries in incidence-space (Fig. S9-S12).

```{r, echo = include.code, fig.height = 4, fig.width = 4}
##' make colour palette
colfunc = colorRampPalette(c("green", "white", "orange"))

par(bty="l", mar=c(4, 4, 1, 2) + 0.1)
ylim = c(0, as.numeric(max(incs.amro), na.rm = T))
xlim = c(0,4)
for (c in 1:length(uncodes.amro)){
  plot(0, bg = colfunc(28), col = 'black', pch = '', bty="n", ylab="incidence per 100,000", xlab="coefficent of variation", yaxt="n",
         xlim = xlim, ylim = ylim, mgp=c(2.5, 1.1, 0))
    axis(2, sqrt(c(1,100,500,1000,2000)), labels=F)
    text(y=sqrt(c(1,100,500,1000,2000)), par("usr")[1] - 0.05, 
         labels = c(1,100,500,1000,2000), srt = 45, pos = 2, xpd = TRUE)
    title(country.names.amro[c], line=-1.5)
    for(i in 1:100){
      points(cvs.amro[((100*c)-(100-i)), 2:ncol(cvs.amro)],
             incs.amro[((100*c)-(100-i)), 2:ncol(incs.amro)], 
             bg = colfunc(28), col = 'black', pch = 21)
    }
    lines(colMeans(cvs.amro[(100*c-99):(100*c), 2:ncol(cvs.amro)]), 
          colMeans(incs.amro[(100*c-99):(100*c), 2:ncol(incs.amro)]), col = 'black')
    points(Am.cv.ss[c,], incs.amro.ss[c,], pch=3, bg = colfunc(28))
    lines(Am.cv.ss[c,], incs.amro.ss[c,], col="grey")
    LEGEND(1.8,sqrt(2000), c("simulated", "estimated"), pch=c(21,3), line.col=c("black","grey"), pt.col="black",lty=1)
}

```

Figure S13 shows the trajectory of the Americas and Africa when we take the median of these regions paths rather than the mean.

```{r, echo = F, include = F}

taxonomy.fig.median = incidence.space.fig.median.dashed.arrow(anim.data = canonical.path.data, years = c(1990, 2017), 
                                                 regions = c("AFR",  "AMR"), shapes = c(1,2,16,17),
                                                 countries.of.interest = c("Malawi", "United States", 
                                                                           "Brazil", "Argentina",
                                                                           "Congo, Democratic Republic of the",
                                                                           "Zambia",
                                                                           "Uruguay", "Tanzania"),
                                                 colors = c( "#367526", "#7a40a0"), text.size = 4,xint=-1.07, yint = 0.25,
                                                 line.color = 'grey1', arrow.size = 2,
                                                 breaks = c(1,5,10,15,20,40,60))


```


```{r, echo = F, fig.height = 10, fig.width = 10}
taxonomy.fig.median

```

Figure S16 of the supplement has the location of countries in the WHO Africa and Americas Regions in incidence-space in 1990 and 2014 post scaling of incidence and CV. This is re-created here. The dotted line represents movement between 2015 and 2017.

```{r, echo = include.code, include = F}

d = canonical.path.data 

years = 1990:2017

d = d %>% filter(., Year %in% years, WHO_REGION %in% regions, Incidence > 0,
                 Country != "")
j = which(d$Year < 1995 & d$Coefficient.of.Variation == 0)
if(length(j) > 0){
    d = d[-(j), ]
}



d$Incidence = log(d$Incidence+0.000001)

##' input d with non-square rooted incidence values. Then we take the square root of the 
##' incidence to match the path calculation


d$Incidence = scl(d$Incidence)
d$Coefficient.of.Variation = scl(d$Coefficient.of.Variation)

logged.scaled.path = awesome.mega.figure.scaled.dashed.arrow (anim.data = d, years = c(1990, 2017), 
                                     regions = c("AFR",  "AMR"), shapes = c(1,2,16,17),
                                     countries.of.interest = c("Malawi", "United States", 
                                                               "Brazil", "Argentina",
                                                               "Congo, Democratic Republic of the",
                                                               "Zambia",
                                                               "Uruguay", "Tanzania"),
                                     colors = c( "#367526", "#7a40a0"), text.size = 4,xint=1.07, yint = 0.25,
                                     line.color = 'grey1', arrow.size = 2,
                                     breaks = c(1,5,10,15,20,40,60))


```


```{r, fig.height = 10, fig.width = 10, echo = include.code}
logged.scaled.path
```

Here begins the supplemental analysis assessing direction of movement and distance of movements. This is the median and IQR difference between observed and expected movements.

```{r, echo = F}
#Direction of movement analysis 
df.direction <- df #keeping in mind this data frame excludes country/years when not moving from the last position on the path

#Add population size to the data frame
df.direction$pop <- as.numeric(rep(NA, nrow(df.direction)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(df.direction)){
  row <- which(pop.by.year$Country.Name==df.direction$country[a])
  col <- which((1961:2017)==df.direction$year[a])+2
  df.direction$pop[a] <- pop.by.year[row,col]
  if (is.na(df.direction$pop[a]) | df.direction$pop[a]=="#N/A") {df.direction$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(df.direction$pop[a]) | df.direction$pop[a]=="#N/A") {df.direction$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(df.direction$pop[a]) | df.direction$pop[a]=="#N/A") {df.direction$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(df.direction$pop[a]) | df.direction$pop[a]=="#N/A") {df.direction$pop[a] <- pop.by.year[row,(col-4)]}
}
df.direction$pop <- as.numeric(df.direction$pop)

#Add country and year to the dataframe
df.direction <- df.direction %>%
  mutate(Country=country, Year=as.numeric(year))

#NOTE: df angles are defined from -180 to 180 with -90 degrees at top and 90 degrees at bottom
#     we want the opposite so must multiple angle by -1 in the analyses below.
df.direction <- df.direction %>%
  mutate(angle.diff.abs = abs(angle.diff*(-1)),
         angle.diff.noabs = angle.diff*(-1))

#IQR angle diff 
quantile(df.direction$angle.diff.noabs)
quantile(df.direction$angle.diff.abs)

```

Same analysis, but expected and observed movments based on three years away.

```{r, echo=F}
#Direction of movement analysis, observed movement three years out

#Angle difference - now actual angle is three years out 
position.and.movement.comparison = data.frame(matrix(NA, nrow(d1b), 15))
colnames(position.and.movement.comparison) = c("country", "region", "year", 
                                               "actual.x", "actual.y",
                                               "next.actual.x", "next.actual.y",
                                               "actual.x.change", "actual.y.change",
                                               "canonical.x","canonical.y", 
                                               "next.canonical.x", "next.canonical.y",
                                               "canonical.x.change", "canonical.y.change")
##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
  c1 = d1b$Country[i]
  y = d1b$Year[i]
  pos = d1b$closest[i]
  
  ##' for each country, each year, find the data for the same country the following year
  
  k = d1b %>% filter(Country == c1, Year == (y+3)) #looking three years ahead (i.e., 3 for observed, and 15 for expected)
    if(nrow(k)>0){
        if(pos < (nrow(granular.canonical.path)-5)){
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           granular.canonical.path$x[(pos+5)], granular.canonical.path$y[(pos+5)],
                                                           granular.canonical.path$x[(pos+5)]-d1b$canonical.x[i],
                                                           granular.canonical.path$y[(pos+5)]-d1b$canonical.y[i])
       } else if (pos < (nrow(granular.canonical.path)-1)) { #if within the last 5 granular points, then just use last position (186)
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           granular.canonical.path$x[186], granular.canonical.path$y[186],
                                                           granular.canonical.path$x[186]-d1b$canonical.x[i],
                                                           granular.canonical.path$y[186]-d1b$canonical.y[i])
       } else { #else means the country is at the end of the granular path, so force canonical path change to 0
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           0,0)
            
        }
    count = count + 1
  }
}

#remove non filled in rows
df.tmp3out<- position.and.movement.comparison %>% filter(!is.na(country))
#making numeric
df.tmp3out$actual.x.change = df.tmp3out$actual.x.change %>% as.character %>% as.numeric
df.tmp3out$actual.y.change = df.tmp3out$actual.y.change %>% as.character %>% as.numeric
df.tmp3out$canonical.x.change = df.tmp3out$canonical.x.change %>% as.character %>% as.numeric
df.tmp3out$canonical.y.change = df.tmp3out$canonical.y.change %>% as.character %>% as.numeric
#determine movements at the end of the granular pathway
end.x <- granular.canonical.path$x[length(granular.canonical.path$x)]
df.tmp3out$path.end <- ifelse(df.tmp3out$canonical.x==end.x & df.tmp3out$next.canonical.x==end.x, 1, 0)
#force actual movement of observations not moving from the end of the path to zero
df.tmp3out$actual.x.change[which(df.tmp3out$path.end==1)] <- 0
df.tmp3out$actual.y.change[which(df.tmp3out$path.end==1)] <- 0
#calculating the angle
df.tmp3out$actual.angle <- (atan2(df.tmp3out$actual.y.change,df.tmp3out$actual.x.change)*-180/pi)
df.tmp3out$canonical.angle <- (atan2(df.tmp3out$canonical.y.change,df.tmp3out$canonical.x.change)*-180/pi) 

#Angle difference
df.tmp3out$angle.diff <- df.tmp3out$actual.angle-df.tmp3out$canonical.angle
#series of if statements: to get angle difference between 180 and -180, rather than -360 and 360.
dft <- df.tmp3out%>% filter(canonical.angle<= -90 & actual.angle>= 90)
df.tmp3out$angle.diff[(df.tmp3out$canonical.angle<= -90 & df.tmp3out$actual.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df.tmp3out%>% filter(actual.angle<= -90 & canonical.angle>= 90)
df.tmp3out$angle.diff[(df.tmp3out$actual.angle<= -90 & df.tmp3out$canonical.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df.tmp3out%>% filter(actual.angle<= -90 & canonical.angle<= 90 & canonical.angle>= 0 & angle.diff< -180)
df.tmp3out$angle.diff[(df.tmp3out$actual.angle<= -90 & df.tmp3out$canonical.angle<= 90 & df.tmp3out$canonical.angle>= 0 & df.tmp3out$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df.tmp3out%>% filter(canonical.angle>= 90 & actual.angle>= -90 & actual.angle<= 0 & angle.diff< -180)
df.tmp3out$angle.diff[(df.tmp3out$canonical.angle>= 90 & df.tmp3out$actual.angle>= -90 & df.tmp3out$actual.angle<= 0 & df.tmp3out$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)

#Add population size to the data frame
df.tmp3out$pop <- as.numeric(rep(NA, nrow(df.tmp3out)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(df.tmp3out)){
  row <- which(pop.by.year$Country.Name==df.tmp3out$country[a])
  col <- which((1961:2017)==df.tmp3out$year[a])+2
  df.tmp3out$pop[a] <- pop.by.year[row,col]
  if (is.na(df.tmp3out$pop[a]) | df.tmp3out$pop[a]=="#N/A") {df.tmp3out$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(df.tmp3out$pop[a]) | df.tmp3out$pop[a]=="#N/A") {df.tmp3out$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(df.tmp3out$pop[a]) | df.tmp3out$pop[a]=="#N/A") {df.tmp3out$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(df.tmp3out$pop[a]) | df.tmp3out$pop[a]=="#N/A") {df.tmp3out$pop[a] <- pop.by.year[row,(col-4)]}
}
df.tmp3out$pop <- as.numeric(df.tmp3out$pop)

#Add country and year to the dataframe
df.tmp3out <- df.tmp3out %>%
  mutate(Country=country, Year=as.numeric(year))

#NOTE: df angles are defined from -180 to 180 with -90 degrees at top and 90 degrees at bottom
#     we want the opposite so must multiple angle by -1 in the analyses below.
df.tmp3out <- df.tmp3out %>%
  mutate(angle.diff.abs = abs(angle.diff*(-1)),
         angle.diff.noabs = angle.diff*(-1))

#If countries at end of the path, force observed direction of movement to zero IF moving towards (0,0)
df.tmp3out <- right_join(d1, df.tmp3out, by= c("Country", "Year")) #to get closest
#which(df.tmp3out$closest==38 & df.tmp3out$angle.diff.abs<(-90))
#which(df.tmp3out$closest==38 & df.tmp3out$angle.diff.abs>90)
df.tmp3out$angle.diff.abs[which(df.tmp3out$closest==38 & df.tmp3out$angle.diff.abs>90)] <- 0
df.tmp3out$angle.diff.noabs[which(df.tmp3out$closest==38 & df.tmp3out$angle.diff.abs>90)] <- 0

#IQR angle diff 
quantile(df.tmp3out$angle.diff.noabs)
quantile(df.tmp3out$angle.diff.abs)

```

First, we assess direction of movement based on absolute quadrant comparison.  The following code also produces the overall proportion of observed movements within same absolute quadrant of expected movmenent and proportion by region, the estimate of proportion of movements with +-45 degress of observed movements, the median and inter-quartile range of observed vector length, Table S1 and Fig S18A.

```{r, echo=F}
#Direction of movement analysis continued
#observed vs expected relative movement
#looking at 45, 90, 135, and 180 degrees difference in observed-expected movement
df.direction.tmpA <- df.direction %>%
  mutate(angle.diff.quad = NA) %>%
  mutate(angle.diff.quad = ifelse(angle.diff.noabs<45 & angle.diff.noabs>(-45),1,
                                  ifelse(angle.diff.noabs<90 & angle.diff.noabs>(-90) & is.na(angle.diff.quad),2,
                                         ifelse(angle.diff.noabs<135 & angle.diff.noabs>(-135) & is.na(angle.diff.quad),3, 
                                                ifelse(angle.diff.noabs<180 & angle.diff.noabs>(-180) & is.na(angle.diff.quad),4, NA))))) 
#table(df.directionC$country, df.directionC$angle.diff.quad)
table(df.direction.tmpA$angle.diff.quad)/nrow(df.direction.tmpA) #moving +-45 degrees 54.10% of the time


#observed vs expected absolute quadrant movement
#define canonical angle and absolute angle by quadrant, then compare

#NOTE: df angles are defined from -180 to 180 with -90 degrees at top and 90 degrees at bottom
#     we want the opposite so must multiple angle by -1 in the analyses below.

df.direction2 <- df.direction %>%
  mutate(actual.angle = actual.angle*(-1),
         canonical.angle = canonical.angle*(-1)) %>%
  mutate(actual.angle.quad = NA,
         canonical.angle.quad = NA) %>%
  mutate(actual.angle.quad = ifelse(actual.angle<91 & actual.angle>(-1),1,
                                    ifelse(actual.angle<180 & actual.angle>(90),2,
                                           ifelse(actual.angle<0 & actual.angle>(-91),4, 
                                                  ifelse(actual.angle>(-180) & actual.angle<(-90),3,NA)))),
         canonical.angle.quad = ifelse(canonical.angle<91 & canonical.angle>(-1),1,
                                    ifelse(canonical.angle<180 & canonical.angle>(90),2,
                                           ifelse(canonical.angle<0 & canonical.angle>(-91),4, 
                                                  ifelse(canonical.angle>(-180) & canonical.angle<(-90),3,NA))))) %>%
  mutate(quad.diff=actual.angle.quad-canonical.angle.quad) %>%
  mutate(final.quad.diff = ifelse(quad.diff==(3) | quad.diff==(-1),(-1), 
                                  ifelse(quad.diff==(-3) | quad.diff==(1), 1, 
                                         ifelse(quad.diff==(-2) | quad.diff==2, 2, 0))))
#the final.quad.diff has four different categories.  0 means observed movement within same quadrant as expected movement.
#-1 means observed movement is 1 quadrant away (clockwise) from the expected movement (e.g., if observed in III but expected in IV) or
#-1 means observed movement is 3 quadrants away counter-clockwise, so 1 closkwise (e.e., if observed in IV and expected in I)
#1 mean observed movement is 1 quadrant away (counter-clockwise) from expected movement (e.g., if observed in IV but expected in III) or
#1 means observed movments is 3 quadrants clockwise, so 1 counter-clockwise (e.g., observed in I and epxced in IV)
#2 means obsered movements is 3 quadrants from expected movements in either direction.

#check table to make sure it worked
#table(df.directionD$quad.diff, df.directionD$final.quad.diff)

#summary
sum(df.direction2$final.quad.diff==0)/nrow(df.direction2) #moving to the correct quadrant 54.98% of the time
#summary by country
#table(df.directionD$country, df.directionD$final.quad.diff)
df.direction2.tmpA <- df.direction2 %>%
  group_by(country) %>%
  dplyr::summarise(quadm1 = sum(final.quad.diff==(-1))/n(),
                   quad0 = sum(final.quad.diff==(0))/n(),
                   quad1 = sum(final.quad.diff==(1))/n(),
                   quad2 = sum(final.quad.diff==2)/n())
#summary by region
df.direction.tmpB <- df.direction2 %>%
  group_by(region) %>%
  dplyr::summarise(quadm1 = sum(final.quad.diff==(-1))/n(),
                   quad0 = sum(final.quad.diff==(0))/n(),
                   quad1 = sum(final.quad.diff==(1))/n(),
                   quad2 = sum(final.quad.diff==2)/n())
print(df.direction.tmpB) #region estimates of observed vs expected absolute quadrant

#Add in length of vector for each actual movement and get quartile for the actual vector length
df.direction2 <- df.direction2 %>%
  mutate(actual.vector.length = sqrt(actual.x.change.raw^2 + actual.y.change.raw^2)) %>%
  mutate(actual.vector.length.quart=cut(actual.vector.length, breaks=c((-1),quantile(actual.vector.length,c(0.25,0.5,0.75)),1), labels=c(1,2,3,4)))
quantile(df.direction2$actual.vector.length) #vector length

#Table S1 - 1990 to 2017
df.direction2.tmpC <- df.direction2 %>%
  group_by(actual.vector.length.quart) %>%
  dplyr::summarise(quadm1 = sum(final.quad.diff==(-1)),
                   quad0 = sum(final.quad.diff==0),
                   quad1 = sum(final.quad.diff==1),
                   quad2 = sum(final.quad.diff==2),
                   sum = n(),
                   quadm1p = sum(final.quad.diff==(-1))/n(),
                   quad0p = sum(final.quad.diff==(0))/n(),
                   quad1p = sum(final.quad.diff==(1))/n(),
                   quad2p = sum(final.quad.diff==2)/n())

#Fig. S18A - Difference in observed and expected quadrants by country and year
library(lattice)
regions <- unique(df.direction2$region)
for (r in 1:length(regions)){
  df.direction2.region <- df.direction2 %>%
    filter(region==regions[r])
  #setting up the dataset for levelplot
  df.direction2.region2 <- df.direction2.region %>%
    dplyr::select(country, region, year, final.quad.diff) %>%
    spread(year, final.quad.diff)
  rownames(df.direction2.region2) <- df.direction2.region2$country
  df.direction2.region2 <- df.direction2.region2[,-c(1:2)]
  rgb.palette <- colorRampPalette(c("#ffffbf","#74a9cf","#fee08b","#e31a1c"), space = "rgb")
  print(levelplot(t(as.matrix(df.direction2.region2)), xlab="time (years)", ylab="", col.regions=rgb.palette(4), aspect="fill", cuts=3, main=regions[r]))
}

```

Fig. S18C and S18D - Difference in observed and expected movements looking at each dimension (incidence and CV) separately.

```{r, echo=F}
#Fig. S18C and S18D - Difference in observed and expected  movements
#Look at each dimension alone using unit vectors (because standardizes to magnitude of 1)
df$actual.magnitude <- sqrt(df$actual.x.change.raw^2 + df$actual.y.change.raw^2)
df$actual.uvx <- df$actual.x.change/df$actual.magnitude
df$actual.uvy <- df$actual.y.change/df$actual.magnitude
df$actual.uvy[which(df.direction$angle.diff.abs==0)] <- 0 #zero = once you get to the end of the path, no actual movement
df$actual.uvx[which(df.direction$angle.diff.abs==0)] <- 0 #zero - once you get to the end of the path, no actual movement

df$canonical.magnitude <- sqrt(df$canonical.x.change^2 + df$canonical.y.change^2)
df$canonical.uvx <- df$canonical.x.change/df$canonical.magnitude
df$canonical.uvy <- df$canonical.y.change/df$canonical.magnitude
df$canonical.uvx[which(df$canonical.magnitude==0)] <- 0 #once you get to the end of the path, no expected movement
df$canonical.uvy[which(df$canonical.magnitude==0)] <- 0 #once you get to the end of the path, no expected movement

#difference in incidence (y) and variance (x) components of the unit vectors
df$var.diff <- df$actual.uvx-df$canonical.uvx
df$inc.diff <- df$actual.uvy-df$canonical.uvy

#renaming data frame
df.direction3 <- df

seq.vlu <- 0.2
seq.range <- seq(-2,2,0.2)
df.direction3 <- df.direction3 %>% #labeled group per upper limit (e.g., 0 is (-0.2 to 0], and .2 is (0, 0.2] etc.)
  mutate(var.diff.grouped=cut(var.diff, breaks=seq.range, labels=as.character(seq.range[-1])),
         inc.diff.grouped=cut(inc.diff, breaks=seq.range, labels=as.character(seq.range[-1])))
regions <- unique(df.direction3$region)

#plot CV (x-axis)
for (r in 1:length(regions)){
  df.direction3.region <- df.direction3 %>%
    filter(region==regions[r])
  all.colors <- c("#7f2704","#a63603","#d94801","#f16913","#fd8d3c","#fdae6b", "#fdd0a2","#fee6ce","#fff5eb","#f7fcf0","#f7fcf0","#fff5f0","#fee0d2", "#fcbba1", "#fc9272", "#fb6a4a", "#ef3b2c", "#cb181d", "#a50f15","#67000d")
  color.index <- match(sort(unique(df.direction3.region$var.diff.grouped)), seq.range[-1])
  if(sum(diff(color.index)!=1)!=0) { #make sure no missing values in between
    color.index <- seq(color.index[1], color.index[length(color.index)], 1)
  }
  #setting up the data frame for plotting
  df.direction3.region.X <- df.direction3.region %>%
    dplyr::select(country, region, year, var.diff.grouped) %>%
    spread(year, var.diff.grouped)
  rownames(df.direction3.region.X) <- df.direction3.region.X$country #names the rows 
  df.direction3.region.X <- df.direction3.region.X[,-c(1:2)] #get rid of first two columns to prep plot
  rgb.palette <- colorRampPalette(all.colors[color.index], space = "rgb") #set up the color palette 
  print(levelplot(t(as.matrix(df.direction3.region.X)), xlab="time (years)", ylab="", col.regions=rgb.palette(length(color.index)), aspect="fill", cuts=(length(color.index)-1), main=paste("CV:",regions[r])))
}

#plot Incidence (y-axis)
for (r in 1:length(regions)){
  df.direction3.region <- df.direction3 %>%
    filter(region==regions[r])
  all.colors <- c("#7f2704","#a63603","#d94801","#f16913","#fd8d3c","#fdae6b", "#fdd0a2","#fee6ce","#fff5eb","#f7fcf0","#f7fcf0","#fff5f0","#fee0d2", "#fcbba1", "#fc9272", "#fb6a4a", "#ef3b2c", "#cb181d", "#a50f15","#67000d")
  color.index <- match(sort(unique(df.direction3.region$inc.diff.grouped)), seq.range[-1])
  if(sum(diff(color.index)!=1)!=0) { #make sure no missing values in between
    color.index <- seq(color.index[1], color.index[length(color.index)], 1)
  }
  #setting up the data frame for plotting
  df.direction3.region.Y <- df.direction3.region %>%
    dplyr::select(country, region, year, inc.diff.grouped) %>%
    spread(year, inc.diff.grouped)
  rownames(df.direction3.region.Y) <- df.direction3.region.Y$country #names the rows 
  df.direction3.region.Y <- df.direction3.region.Y[,-c(1:2)] #get rid of first two columns to prep plot
  rgb.palette <- colorRampPalette(all.colors[color.index], space = "rgb") #set up the color palette 
  print(levelplot(t(as.matrix(df.direction3.region.Y)), xlab="time (years)", ylab="", col.regions=rgb.palette(length(color.index)), aspect="fill", cuts=(length(color.index)-1), main=paste("Incidence:",regions[r])))
}

```

The last analysis assess direction of movement based on absolute error in angle differences, Fig, S18B.

```{r, echo=F}
#Direction of movement analysis continued
#Looking at absolute error in angle differences
#1990 to 2017
df.direction.tmpC <- df.direction %>%
  mutate(actual.vector.length = sqrt(actual.x.change.raw^2 + actual.y.change.raw^2)) %>%
  mutate(actual.vector.length.decile=cut(actual.vector.length, breaks=c((-1),quantile(actual.vector.length,seq(0.1,0.9,0.1)),1), labels=1:10))
ggplot(df.direction.tmpC) + geom_boxplot(aes(x=actual.vector.length.decile, y=angle.diff.abs)) + theme_classic() +
  labs(x="Decile of observed vector length", y="Absolute difference b/w observed and expected angles")


#Absolute error by country and year
df.direction4 <- df.direction %>%
  mutate(angle.diff.abs.declie=cut(angle.diff.abs,  breaks=c(-1,seq(9,180,9)), labels=1:20))
rgb.palette <- colorRampPalette(c("#238443","#41ab5d","#78c679","#addd8e","#d9f0a3","#ffffe5","#ffffcc","#ffffb3","#fff698","#fdf286",
                                  "#fddd9b","#fdd29b","#fdc085","#fdac71","#fc8d59","#ef6548","#d7301f","#b30000","#7f2704","#67000d"))
regions <- unique(df.direction4$region)
for (r in 1:length(regions)){
  df.direction4.region <- df.direction4 %>%
    filter(region==regions[r])
  #setting up the dataset for levelplot
  df.direction4.region <- df.direction4.region %>%
    dplyr::select(country, region, year, angle.diff.abs.declie) %>%
    spread(year, angle.diff.abs.declie)
  rownames(df.direction4.region) <- df.direction4.region$country
  df.direction4.region <- df.direction4.region[,-c(1:2)]
  print(levelplot(t(as.matrix(df.direction4.region)), xlab="time (years)", ylab="", col.regions=rgb.palette(20), aspect="fill", cuts=19, main=regions[r]))
}

```

Distance from path analysis.  The following codes reproduces Fig. S20 and S21.

```{r, echo=F, fig.height = 2, fig.width = 5}
## Distance from path analysis
df.distance <- position.and.movement.comparison %>% filter(!is.na(country))

#making numeric
df.distance$actual.x.change = df.distance$actual.x.change %>% as.character %>% as.numeric
df.distance$actual.y.change = df.distance$actual.y.change %>% as.character %>% as.numeric
df.distance$canonical.x.change = df.distance$canonical.x.change %>% as.character %>% as.numeric
df.distance$canonical.y.change = df.distance$canonical.y.change %>% as.character %>% as.numeric

#calculating the angle
df.distance$actual.angle <- (atan2(df.distance$actual.y.change,df.distance$actual.x.change)*-180/pi)
df.distance$canonical.angle <- (atan2(df.distance$canonical.y.change,df.distance$canonical.x.change)*-180/pi) 

#Angle difference
df.distance$angle.diff <- df.distance$actual.angle-df.distance$canonical.angle
#series of if statements: to get angle difference between 180 and -180, rather than -360 and 360.
dft <- df.distance %>% filter(canonical.angle<= -90 & actual.angle>= 90)
df.distance$angle.diff[(df.distance$canonical.angle<= -90 & df.distance$actual.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df.distance %>% filter(actual.angle<= -90 & canonical.angle>= 90)
df.distance$angle.diff[(df.distance$actual.angle<= -90 & df.distance$canonical.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df.distance %>% filter(actual.angle<= -90 & canonical.angle<= 90 & canonical.angle>= 0 & angle.diff< -180)
df.distance$angle.diff[(df.distance$actual.angle<= -90 & df.distance$canonical.angle<= 90 & df.distance$canonical.angle>= 0 & df.distance$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df.distance %>% filter(canonical.angle>= 90 & actual.angle>= -90 & actual.angle<= 0 & angle.diff< -180)
df.distance$angle.diff[(df.distance$canonical.angle>= 90 & df.distance$actual.angle>= -90 & df.distance$actual.angle<= 0 & df.distance$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)

#Add population size to the data frame
df.distance <- df.distance
df.distance$pop <- as.numeric(rep(NA, nrow(df.distance)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(df.distance)){
  row <- which(pop.by.year$Country.Name==df.distance$country[a])
  col <- which((1961:2017)==df.distance$year[a])+2
  df.distance$pop[a] <- pop.by.year[row,col]
  if (is.na(df.distance$pop[a]) | df.distance$pop[a]=="#N/A") {df.distance$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(df.distance$pop[a]) | df.distance$pop[a]=="#N/A") {df.distance$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(df.distance$pop[a]) | df.distance$pop[a]=="#N/A") {df.distance$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(df.distance$pop[a]) | df.distance$pop[a]=="#N/A") {df.distance$pop[a] <- pop.by.year[row,(col-4)]}
}
df.distance$pop <- as.numeric(df.distance$pop)

#If moving towards 0,0 then make distance 0, otherwise calculate distance
#the last 6 points on the granular path are not moving.
end.x <- granular.canonical.path$x[length(granular.canonical.path$x)]
#fill in 0s where wanted
df.distance <- df.distance %>%
  mutate(actual.angle = actual.angle*(-1)) %>%
  mutate(actual.angle.quad = NA) %>%
  mutate(actual.angle.quad = ifelse(actual.angle<91 & actual.angle>(-1),1,
                                    ifelse(actual.angle<180 & actual.angle>(90),2,
                                           ifelse(actual.angle<0 & actual.angle>(-91),4, 
                                                  ifelse(actual.angle>(-180) & actual.angle<(-90),3,NA)))))
df.distance$path.end <- ifelse(df.distance$canonical.x==end.x & df.distance$next.canonical.x==end.x, 1, 0)


```


```{r, echo=F, fig.height = 2, fig.width = 5}
#Revised to be percentage of the entire range of the path
x.range <- diff(as.numeric(range(df.distance$canonical.x)))
y.range <- diff(as.numeric(range(df.distance$canonical.y)))
#IQR distance from path by country (plotted by population size)
df.distanceL <- df.distance %>%
  mutate(x.diff = 100*(as.numeric(actual.x) - as.numeric(canonical.x))/x.range,
         y.diff = 100*(as.numeric(actual.y) - as.numeric(canonical.y))/y.range,
         log_pop=log(as.numeric(pop))) %>%
  mutate(x.diff = ifelse(path.end==1 & actual.angle.quad==3, 0, x.diff),
         y.diff = ifelse(path.end==1 & actual.angle.quad==3, 0, y.diff))
p1 <- ggplot(df.distanceL) + theme_classic() + aes(x=log_pop, y=x.diff) + 
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), se=F) +
  geom_point(alpha=0.3, shape=1) +
  ylim(-120,120) + labs(x="Log Population Size", y="CV Distance from Path \n(Percent of Path CV Range)") + 
  geom_hline(yintercept=0, linetype="dashed", color = "darkgrey", size=1.5)
p2 <- ggplot(df.distanceL) + aes(x=log_pop, y=y.diff) + geom_point(alpha=0.3, shape=1) + theme_classic() +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs"), se=F)+
  ylim(-120,120) + labs(x="Log Population Size", y="Incidence Distance from Path \n(Percent of Path Incidence Range)") + 
  geom_hline(yintercept=0, linetype="dashed", color = "darkgrey", size=1.5)
grid.arrange(p1, p2, nrow = 1)

#IQR distance from path by position on the path
df.distance <- df.distance %>%
  mutate(Country=country, Year=as.numeric(year))
df.distanceM <- right_join(d1, df.distance, by= c("Country", "Year"))
df.distanceM <- df.distanceM %>%
  mutate(x.diff = 100*(as.numeric(actual.x) - as.numeric(canonical.x.y))/x.range,
         y.diff = 100*(as.numeric(actual.y) - as.numeric(canonical.y.y))/y.range) %>%
  mutate(x.diff = ifelse(path.end==1 & actual.angle.quad==3, 0, x.diff),
         y.diff = ifelse(path.end==1 & actual.angle.quad==3, 0, y.diff)) %>%
  group_by(closest) %>%
  dplyr::summarise(med_distance_X=median(x.diff),
            low_X=quantile(x.diff, 0.25),
            high_X=quantile(x.diff, 0.75),
            med_distance_Y=median(y.diff),
            low_Y=quantile(y.diff, 0.25),
            high_Y=quantile(y.diff, 0.75))  
p1 <- ggplot(df.distanceM) + geom_point(aes(x=closest, y=med_distance_X)) + theme_classic() +
  geom_smooth(aes(x=closest, y=med_distance_X), method = "gam", formula = y ~ s(x, bs = "cs"), se=F) +
  geom_errorbar(aes(x=closest, ymin=low_X,ymax=high_X,width=0.2)) +  ylim(-100,100) + 
  labs(x="Positions on the Path", y="Median CV Distance from Path \n(Percent of Path CV Range)") + 
  geom_hline(yintercept=0, linetype="dashed", color = "darkgrey", size=1.5) + 
  scale_x_continuous(breaks = c(0,10,19.5,29,38), labels=c("0%","25%","50%","75%", "100%"))
p2 <- ggplot(df.distanceM) + geom_point(aes(x=closest, y=med_distance_Y)) + theme_classic() +
  geom_smooth(aes(x=closest, y=med_distance_Y), method = "gam", formula = y ~ s(x, bs = "cs"), se=F) +
  geom_errorbar(aes(x=closest, ymin=low_Y,ymax=high_Y,width=0.2)) +  ylim(-100,100) +
  labs(x="Positions on the Path", y="Median Incidence Distance from Path \n(Percent of Path Incidence Range)") + 
  geom_hline(yintercept=0, linetype="dashed", color = "darkgrey", size=1.5) + 
  scale_x_continuous(breaks = c(0,10,19.5,29,38), labels=c("0%","25%","50%","75%", "100%"))
grid.arrange(p1, p2, nrow = 1)

## Distance from path analysis
## Total distance (putting X and Y together)
#can look by country, by year, by position on path

# Total length of the canonical path
gran <- granular.canonical.path
length.gran <- 0
for (g in 2:nrow(gran)){
  xchange <- gran$x[g]-gran$x[g-1]
  ychange <- gran$y[g]-gran$y[g-1]
  tmp.length <- sqrt(xchange^2 + ychange^2)
  length.gran <- length.gran + tmp.length
}
crude <- canonical.path
length.crude <- 0
for (g in 2:nrow(crude)){
  xchange <- crude$x[g]-crude$x[g-1]
  ychange <- crude$y[g]-crude$y[g-1]
  tmp.length <- sqrt(xchange^2 + ychange^2)
  length.crude <- length.crude + tmp.length
}
#they are the same, as they should be
length.canonical.path <- length.gran

#IQR distance from path by country (plotted by population size)
df.distanceO <- df.distance %>%
  mutate(x.diff = as.numeric(actual.x) - as.numeric(canonical.x),
         y.diff = as.numeric(actual.y) - as.numeric(canonical.y)) %>%
  mutate(x.diff = ifelse(path.end==1 & actual.angle.quad==3, 0, x.diff),
         y.diff = ifelse(path.end==1 & actual.angle.quad==3, 0, y.diff)) %>%
  mutate(length.diff = sqrt(x.diff^2 + y.diff^2),
         length.diff.percentile = 100*(length.diff/length.canonical.path),
         log_pop= log(as.numeric(pop)))
ggplot(df.distanceO) + geom_point(aes(x=log_pop, y=length.diff.percentile), alpha=0.3, shape=1) + theme_classic() +
  geom_smooth(aes(x=log_pop, y=length.diff.percentile), method = "gam", formula = y ~ s(x, bs = "cs"), se=F, col="orange") +
  ylim(0,50) + labs(x="Log Population Size", y="Distance from Path \n(Percent of Path Length)")

#quantile(df.distanceO$length.diff) #median and IQR distance from path
#quantile(df.distanceO$x.diff) #median and IQR distance in cv
#quantile(df.distanceO$y.diff) #median and IQR distance in incidence

quantile(df.distanceO$length.diff/length.canonical.path) #median and IQR as a proportion of the length of the path 
quantile(df.distanceO$x.diff/x.range) #median and IQR distance in cv as a proportion of the range of CV
quantile(df.distanceO$y.diff/y.range) #median and IQR distance in incidence as a proportion of the range of incidence

#IQR distance from path by position on the path
df.distance <- df.distance %>%
  mutate(Country=country, Year=as.numeric(year))
df.distanceK <- right_join(d1, df.distance, by= c("Country", "Year"))
df.distanceK <- df.distanceK %>%
  mutate(x.diff = as.numeric(actual.x) - as.numeric(canonical.x.y),
         y.diff = as.numeric(actual.y) - as.numeric(canonical.y.y)) %>%
  mutate(x.diff = ifelse(path.end==1 & actual.angle.quad==3, 0, x.diff),
         y.diff = ifelse(path.end==1 & actual.angle.quad==3, 0, y.diff)) %>%
  mutate(length.diff = sqrt(x.diff^2 + y.diff^2),
         length.diff.percentile = 100*(length.diff/length.canonical.path)) %>%
  group_by(closest) %>%
  dplyr::summarise(med_distance_percentile=median(length.diff.percentile),
            low_distance_percentile=quantile(length.diff.percentile, 0.25),
            high_distance_percentile=quantile(length.diff.percentile, 0.75),
            med_distance=median(length.diff),
            low_distance=quantile(length.diff, 0.25),
            high_distance=quantile(length.diff, 0.75)) 
ggplot(df.distanceK) + geom_point(aes(x=closest, y=med_distance_percentile), shape=1) + theme_classic() +
  geom_smooth(aes(x=closest, y=med_distance_percentile), method = "gam", formula = y ~ s(x, bs = "cs"), se=F,  col="orange") +
  geom_errorbar(aes(x=closest, ymin=low_distance_percentile,ymax=high_distance_percentile,width=0.2)) +  ylim(0,50) + 
  labs(x="Positions on the Path", y="Median Distance from Path \n(Percent of Path Length)") + 
  scale_x_continuous(breaks = c(0,10,19.5,29,38), labels=c("0%","25%","50%","75%", "100%"))

```

Figures S22 contains the results of modeling incidence and coefficient of variation as dependent variables separately, with birth rate, vaccination proportion and (birth rate) times (1-vaccination proportion) all used independent variables (one at a time) using generalized additive models (GAM). The term (birth rate) times (1-vaccination proportion) is an approximation of how quickly individuals who are susceptible to measles are recruited into the population, therefore we term this the rate of susceptible recruitment. To produce the GAM plots, we first need to construct a data set which has the estimated mean age of susceptibles by country and by year.

```{r, echo = include.code, include = F}

mean.age.sus = read.csv(file = "data/mean_age_sus.csv", stringsAsFactors = F)
rownames(mean.age.sus) = mean.age.sus$X
mean.age.sus = mean.age.sus[, -(1)]
colnames(mean.age.sus) = gsub("X", "", colnames(mean.age.sus))


list[anim.data, Af.data, Amr.data, Rest.data] = 
    prepare.anim.data.for.analysis(input.data = canonical.path.data,
                                   mean.age.sus = mean.age.sus)
Amr.af.data = rbind(Af.data, Amr.data)
all.but.euro = rbind(Amr.af.data, filter(Rest.data, WHO_REGION != "EUR"))
Combined.data = rbind(Rest.data, Amr.af.data)


list[h, z, j, z1, colfunc.br, colfunc.vacc, colfunc.br.vacc] = produce.gams.plot(data = Combined.data,
                  ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500)),
                  tick.labels = c(0,25,100, 250,500))

list[ha, za, ja, z1a, colfunc.br, colfunc.vacc, colfunc.br.vacc] = produce.gams.plot(data = all.but.euro,
                  ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500)),
                  tick.labels = c(0,25,100, 250,500))


```

We can then plot these predicted paths in the incidence-space over values of birth rate, vaccination rate, and the rate of susceptible recruitment with reported cases (Fig. S22).

```{r, echo = F, fig.height = 8, fig.width = 8}
tick.labels = c(0,25,100, 250,500)
ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500))
plot.alpha = 0.8
##' construct the plot
    plot(h$x, sqrt(100*h$y), yaxt = "n", xlab = "coefficient of variation", 
         ylab = "mean incidence per 100,000",
         col = alpha(colfunc.br(nrow(h)),plot.alpha), 
         pch = 16, cex = 1.5, xlim = c(min(z1$x), max(z1$x)), frame.plot = FALSE,
         ylim = c(0, sqrt(100*max(z1$y))), cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5)
    points(z$x, sqrt(100 * z$y), col = alpha(colfunc.vacc(nrow(z)), plot.alpha),
           pch = 17, cex = 1.5)
    points(j$x, sqrt(100 * j$y), col = alpha(colfunc.br.vacc(nrow(j)), plot.alpha),
           pch = 15, cex = 1.5)
    legend('topright', bty = 'n', c("br","vacc","br(1-vacc)"), pch = c(16, 17,15), 
           col = c("darkgreen", "navyblue","firebrick"), cex = 1.5)
    
    ##' tick marks trick, to get the true values rather than sqrt value on y axis
    axis(2, at=ticks, labels=tick.labels, cex.axis = 1.5)
```
   
    
```{r, echo = F, fig.height = 8, fig.width = 8} 
       plot(ha$x, sqrt(100*ha$y), yaxt = "n", xlab = "coefficient of variation", 
         ylab = "mean incidence per 100,000",
         col = alpha(colfunc.br(nrow(ha)),plot.alpha), 
         pch = 16, cex = 1.5, xlim = c(min(z1a$x), max(z1a$x)), frame.plot = FALSE,
         ylim = c(0, sqrt(100*max(z1$y))), cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5)
    points(za$x, sqrt(100 * za$y), col = alpha(colfunc.vacc(nrow(za)), plot.alpha),
           pch = 17, cex = 1.5)
    points(ja$x, sqrt(100 * ja$y), col = alpha(colfunc.br.vacc(nrow(ja)), plot.alpha),
           pch = 15, cex = 1.5)
    legend('topright', bty = 'n', c("br","vacc","br(1-vacc)"), pch = c(16, 17,15), 
           col = c("darkgreen", "navyblue","firebrick"), cex = 1.5)
    
    ##' tick marks trick, to get the true values rather than sqrt value on y axis
    axis(2, at=ticks, labels=tick.labels, cex.axis = 1.5)
    

```

Figure S22C also displays the association between incidence or coefficient of variation with the birth rate and vaccination coverage in Africa.

```{r, echo = F, fig.height = 8, fig.width = 8}


list[canonical.path.data.anim, Af.data, Amr.data, Rest.data] = 
    prepare.anim.data.for.analysis(input.data = canonical.path.data.reported,
                                   mean.age.sus = mean.age.sus)


L = canonical.path.data.anim[which(canonical.path.data.anim$Mean.Age.Sus >0), ]
L = L%>% filter(WHO_REGION == "AFR")

L = L[-(which(L$Incidence ==0 & L$Coefficient.of.Variation ==0)), ]


L = L[-(which(L$Mean.vaccination == 0)), ]

par(mfrow=c(2,2))
plot(sqrt(100*Incidence)  ~ Mean.birth.rate, data = L,  bty="n",
     cex = 0.75,col="grey40", cex.axis = 1.5, yaxt = "n",
     xlab = list("", cex = 1.5), 
     ylab = list("incidence per 100000", cex = 1.5))
L = L[order(L$Mean.birth.rate),]
loess_fit <- loess(sqrt(100*Incidence)~ Mean.birth.rate, L, degree = 1)
lines(L$Mean.birth.rate, predict(loess_fit), col = "blue", lwd = 2)
axis(2, at = c(0, 10, sqrt(500),  sqrt(1200)), labels = c(0, 100, 500, 1200), cex.axis =  1.5)


plot(sqrt(100*Incidence) ~ Mean.vaccination, data = L,  bty="n",
     cex = 0.75,col="grey40", cex.axis = 1.5, yaxt = "n",
     xlab = list("", cex = 1.5), 
     ylab = list("", cex = 1.5))
L = L[order(L$Mean.vaccination),]
loess_fit <- loess(sqrt(100*Incidence)~ Mean.vaccination, L, degree = 1)
lines(L$Mean.vaccination, predict(loess_fit), col = "blue", lwd = 2)
axis(2, at = c(0, 10, sqrt(500),  sqrt(1200)), labels = c(0, 100, 500, 1200), cex.axis =  1.5)

plot(Coefficient.of.Variation ~ Mean.birth.rate, data = L,  bty="n",
     cex = 0.75,col="grey40", cex.axis = 1.5,
     xlab = list("birth rate per 1000", cex = 1.5), 
     ylab = list("coefficient of variation", cex = 1.5))
L = L[order(L$Mean.birth.rate),]
loess_fit <- loess(Coefficient.of.Variation~ Mean.birth.rate, L, degree = 1)
lines(L$Mean.birth.rate, predict(loess_fit), col = "blue", lwd = 2)


plot(Coefficient.of.Variation ~ Mean.vaccination, data = L,  bty="n",
     cex = 0.75,col="grey40", cex.axis = 1.5,
     xlab = list("vaccination %", cex = 1.5), 
     ylab = list("", cex = 1.5))
L = L[order(L$Mean.vaccination),]
loess_fit <- loess(Coefficient.of.Variation~ Mean.vaccination, L, degree = 1)
lines(L$Mean.vaccination, predict(loess_fit), col = "blue", lwd = 2)



```

Figure S29 displays the results of a sensitivity analysis of incidence-space projections.  Here we show the position and speed of movement analysis by time and country (as displayed in Fig. 3A-B in the main text) for other scalings of incidence and the coefficent of variation.  We overlay the region averages and population-weighted region averages. 

We will start with the square root incidence and then scaling both square root incidence and coefficent of variation so that all of their values are between 0 and 1. 

```{r, echo = include.code, include = FALSE}

##' square root incidence
d = canonical.path.data
use.reported.cases = TRUE
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")
make.inc.cv.scale.same = 1 
sqrt.inc = T
sqrt.cv = F
connect.canonical.path.to.zero = 0
log.incidence = F 
number.of.additional.points = 4 #4 additional points between each of 38 points

##' d1b will contain the closest point on the granular canonical path over time.
list[d1b, granular.canonical.path] = closest.path.point.movement.comparison(d = d, 
                                              use.rep.cases = use.reported.cases,
                                              regions = regions, 
                                              years = seq(1990, 2017),
                                              make.inc.cv.scale.same = make.inc.cv.scale.same,
                                              sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                              connect.canonical.path.to.zero,
                                              log.incidence = log.incidence,
                                              number.of.additional.points = number.of.additional.points) 

##' First add population size to the data.frame because we need to weight the region estimates by population size of coutry
d1b$pop <- as.numeric(rep(NA, nrow(d1b)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(d1b)){
  row <- which(pop.by.year$Country.Name==d1b$Country[a])
  col <- which((1961:2017)==d1b$Year[a])+2
  d1b$pop[a] <- pop.by.year[row,col]
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-4)]}
}
d1b$pop <- as.numeric(d1b$pop)

##' Get country-specific population weight for each region and year
##' This will be used to weight the average position by region overtime
d1b <- d1b %>%
  dplyr::group_by(WHO_REGION, Year) %>%
  dplyr::mutate(weight = pop/sum(pop))
d1b$weight <- round(d1b$weight,5)

##' create data frame to store values in
deltas.by.continent = data.frame(matrix(NA, nrow(d1b), 6))
colnames(deltas.by.continent) = c("country", "region", "year", "delta", "pos","weight")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
  c1 = d1b$Country[i]
  y = d1b$Year[i]
  pos = d1b$closest[i]
  
  ##' for each country, each year, find the data for the same country the following year
  
  k = d1b %>% filter(Country == c1, Year == (y+1))
  if(nrow(k)>0){
    pos2 = k$closest
    deltas.by.continent[count, ] =  c(c1, k$WHO_REGION, y+1, pos2-pos, pos2, k$weight)
    count = count + 1
  }
}

##' remove data which is NA
j = which(is.na(deltas.by.continent$country))
if(length(j) >0 ){
  deltas.by.continent = deltas.by.continent[-(j),]
}

##' extract the unique years from the data set containing the changes for each year
all.years = as.numeric(unique(deltas.by.continent$year))
countries = unique(deltas.by.continent$country)

##' change the data to be characters and numbers
deltas.by.continent$country = deltas.by.continent$country %>% as.character
deltas.by.continent$region = deltas.by.continent$region %>% as.character
deltas.by.continent$year = deltas.by.continent$year %>% as.character %>% as.numeric
deltas.by.continent$delta = deltas.by.continent$delta %>% as.character %>% as.numeric
deltas.by.continent$pos = deltas.by.continent$pos %>% as.character %>% as.numeric
deltas.by.continent$weight = deltas.by.continent$weight %>% as.character %>% as.numeric

##'choose a period of time over which to smooth the average position of the WHO regions. 
##'A 2 this means that we smooth using the average of a given year along with two years before and two years after
moving.av.length = 2

##' set up a dataframe to hold the weighted data
deltas.summary.weighted = data.frame(matrix(NA, (length(all.years)-2)*length(countries), 6))
colnames(deltas.summary.weighted) = c("country","region", "year", "mean.delta", "mean.pos", "weight")

count = 1
for(i in (moving.av.length+1):length(all.years - moving.av.length)){
  ##' choose the years we wish to include in the averaging
  years = all.years[(i-moving.av.length):(i+moving.av.length)]
  for(j in 1 : length(countries)){
    ##' find the require data
    c = countries[j]
    d = deltas.by.continent %>% filter(year %in% years & country ==c) 
    r = d$region[1]
    
    ##' record the regions, the year in question, along with summaries of the change in movement, along
    ##' with the mean position of the region over the years in question
    deltas.summary.weighted[count, ] = c(c, 
                                         r,
                                         years[(moving.av.length + 1)],
                                         mean(d$delta),
                                         mean(d$pos),
                                         mean(d$weight)) #keep the weight for appropriate year
    count = count + 1
  }
}

##' remove data which is NA
j = which(deltas.summary.weighted$mean.delta=="NaN")
if(length(j) >0 ){
  deltas.summary.weighted = deltas.summary.weighted[-(j),]
}

##' change the data to be characters and numbers
deltas.summary.weighted$country = deltas.summary.weighted$country %>% as.character
deltas.summary.weighted$region = deltas.summary.weighted$region %>% as.character
deltas.summary.weighted$year = deltas.summary.weighted$year %>% as.character %>% as.numeric
deltas.summary.weighted$mean.delta = deltas.summary.weighted$mean.delta %>% as.character %>% as.numeric
deltas.summary.weighted$mean.pos = deltas.summary.weighted$mean.pos %>% as.character %>% as.numeric
deltas.summary.weighted$weight = deltas.summary.weighted$weight %>% as.character %>% as.numeric

dd <- deltas.summary.weighted

##' summarise with average position for each region, by year
dd2 = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.pos = mean(mean.pos))
dd3 = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.delta = mean(mean.delta))

##' summarise the population weighted average position for each region, by year
dd2b = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.pos = sum(mean.pos*weight))
dd3b = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.delta = sum(mean.delta*weight))
```

We plot the position and speed of movement analysis with overlay of region averages,

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("sqrt(inc), both scaled 0 to 1 \nregion averages")

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("sqrt(inc), both scaled 0 to 1 \nregion averages")

```

and with overlap of population-weighted region averages.

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2b, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("sqrt(inc), both scaled 0 to 1 \npopulation-weighted region averages")

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3b, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("sqrt(inc), both scaled 0 to 1 \npopulation-weighted region averages")
```

We also assessed projection with natural logged incidence and square rooted ciefficent of variation and then scaling both so that all of their values are between 0 and 1.

```{r, echo = include.code, include = FALSE}

##' log incidence and sqrt cv
d = canonical.path.data
use.reported.cases = TRUE
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")
make.inc.cv.scale.same = 1 
sqrt.inc = F
sqrt.cv = T
connect.canonical.path.to.zero = 0
log.incidence = T 
number.of.additional.points = 4 #4 additional points between each of 38 points

##' d1b will contain the closest point on the granular canonical path over time.
list[d1b, granular.canonical.path] = closest.path.point.movement.comparison(d = d, 
                                              use.rep.cases = use.reported.cases,
                                              regions = regions, 
                                              years = seq(1990, 2017),
                                              make.inc.cv.scale.same = make.inc.cv.scale.same,
                                              sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                              connect.canonical.path.to.zero,
                                              log.incidence = log.incidence,
                                              number.of.additional.points = number.of.additional.points) 

##' First add population size to the data.frame because we need to weight the region estimates by population size of coutry
d1b$pop <- as.numeric(rep(NA, nrow(d1b)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(d1b)){
  row <- which(pop.by.year$Country.Name==d1b$Country[a])
  col <- which((1961:2017)==d1b$Year[a])+2
  d1b$pop[a] <- pop.by.year[row,col]
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-4)]}
}
d1b$pop <- as.numeric(d1b$pop)

##' Get country-specific population weight for each region and year
##' This will be used to weight the average position by region overtime
d1b <- d1b %>%
  dplyr::group_by(WHO_REGION, Year) %>%
  dplyr::mutate(weight = pop/sum(pop))
d1b$weight <- round(d1b$weight,5)

##' create data frame to store values in
deltas.by.continent = data.frame(matrix(NA, nrow(d1b), 6))
colnames(deltas.by.continent) = c("country", "region", "year", "delta", "pos","weight")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
  c1 = d1b$Country[i]
  y = d1b$Year[i]
  pos = d1b$closest[i]
  
  ##' for each country, each year, find the data for the same country the following year
  
  k = d1b %>% filter(Country == c1, Year == (y+1))
  if(nrow(k)>0){
    pos2 = k$closest
    deltas.by.continent[count, ] =  c(c1, k$WHO_REGION, y+1, pos2-pos, pos2, k$weight)
    count = count + 1
  }
}

##' remove data which is NA
j = which(is.na(deltas.by.continent$country))
if(length(j) >0 ){
  deltas.by.continent = deltas.by.continent[-(j),]
}

##' extract the unique years from the data set containing the changes for each year
all.years = as.numeric(unique(deltas.by.continent$year))
countries = unique(deltas.by.continent$country)

##' change the data to be characters and numbers
deltas.by.continent$country = deltas.by.continent$country %>% as.character
deltas.by.continent$region = deltas.by.continent$region %>% as.character
deltas.by.continent$year = deltas.by.continent$year %>% as.character %>% as.numeric
deltas.by.continent$delta = deltas.by.continent$delta %>% as.character %>% as.numeric
deltas.by.continent$pos = deltas.by.continent$pos %>% as.character %>% as.numeric
deltas.by.continent$weight = deltas.by.continent$weight %>% as.character %>% as.numeric

##'choose a period of time over which to smooth the average position of the WHO regions. 
##'A 2 this means that we smooth using the average of a given year along with two years before and two years after
moving.av.length = 2

##' set up a dataframe to hold the weighted data
deltas.summary.weighted = data.frame(matrix(NA, (length(all.years)-2)*length(countries), 6))
colnames(deltas.summary.weighted) = c("country","region", "year", "mean.delta", "mean.pos", "weight")

count = 1
for(i in (moving.av.length+1):length(all.years - moving.av.length)){
  ##' choose the years we wish to include in the averaging
  years = all.years[(i-moving.av.length):(i+moving.av.length)]
  for(j in 1 : length(countries)){
    ##' find the require data
    c = countries[j]
    d = deltas.by.continent %>% filter(year %in% years & country ==c) 
    r = d$region[1]
    
    ##' record the regions, the year in question, along with summaries of the change in movement, along
    ##' with the mean position of the region over the years in question
    deltas.summary.weighted[count, ] = c(c, 
                                         r,
                                         years[(moving.av.length + 1)],
                                         mean(d$delta),
                                         mean(d$pos),
                                         mean(d$weight)) #keep the weight for appropriate year
    count = count + 1
  }
}

##' remove data which is NA
j = which(deltas.summary.weighted$mean.delta=="NaN")
if(length(j) >0 ){
  deltas.summary.weighted = deltas.summary.weighted[-(j),]
}

##' change the data to be characters and numbers
deltas.summary.weighted$country = deltas.summary.weighted$country %>% as.character
deltas.summary.weighted$region = deltas.summary.weighted$region %>% as.character
deltas.summary.weighted$year = deltas.summary.weighted$year %>% as.character %>% as.numeric
deltas.summary.weighted$mean.delta = deltas.summary.weighted$mean.delta %>% as.character %>% as.numeric
deltas.summary.weighted$mean.pos = deltas.summary.weighted$mean.pos %>% as.character %>% as.numeric
deltas.summary.weighted$weight = deltas.summary.weighted$weight %>% as.character %>% as.numeric

dd <- deltas.summary.weighted

##' summarise with average position for each region, by year
dd2 = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.pos = mean(mean.pos))
dd3 = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.delta = mean(mean.delta))

dd2b = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.pos = sum(mean.pos*weight))
dd3b = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.delta = sum(mean.delta*weight))
```

We plot the position and speed of movement analysis with overlay of region averages,

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("log(inc) and sqrt(cv), both scaled 0 to 1 \nregion averages")

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("log(inc) and sqrt(cv), both scaled 0 to 1 \nregion averages")

```

and with overlap of population-weighted region averages.


```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2b, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("log(inc) and sqrt(cv), both scaled 0 to 1 \npopulation-weighted region averages")

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3b, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("log(inc) and sqrt(cv), both scaled 0 to 1 \npopulation-weighted region averages")
```


All analyses conducted above on countries position in incidence space and characterizing of the canonical path rely upon reported measles incident cases per the WHO. In order to assess the sensitivity of our results to reporting rates, we reran all pertinent analyses using estimated case data per @statespace and @simons2012 that corrects for under-reporting.  We begin by recreating a figure similar to Fig. 1A of the paper, demonstrating the path of the Americas and Africa through incidence space. This is seen below and is Fig. S14. The only difference is that Fig. 1A uses reported cases, and Fig. S14 uses cases corrected for under-reporting.

```{r, echo = include.code}
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")

state.space.data = 
    generate.state.space.data(window.length = 10, regions, 
                                 gaussian.st.dev=3, cutoff = 50, 
                                 interp.resolution = 20,
                                 year.shift.inc = 2)


mean.age.sus = read.csv(file = "data/mean_age_sus.csv", stringsAsFactors = F)
rownames(mean.age.sus) = mean.age.sus$X
mean.age.sus = mean.age.sus[, -(1)]
colnames(mean.age.sus) = gsub("X", "", colnames(mean.age.sus))


list[state.space.data, Af.data.state.space, Amr.data.state.space, Rest.data.state.space] = 
    prepare.anim.data.for.analysis(input.data = state.space.data,
                                   mean.age.sus = mean.age.sus)
```

```{r, echo = include.code}

state.space.fig = incidence.space.fig.dashed.arrow(anim.data = state.space.data, years = c(1990, 2017), 
                                      state.space = 1,
                                     regions = c("AFR",  "AMR"), shapes = c(1,2,16,17),
                                     countries.of.interest = c("Malawi", "United States", 
                                                               "Brazil", "Argentina",
                                                               "Congo, Democratic Republic of the",
                                                               "Zambia",
                                                               "Uruguay", "Tanzania"),
                                     colors = c( "#367526", "#7a40a0"), text.size = 4,xint=-1.07, yint = 0.25,
                                     line.color = 'grey1', arrow.size = 2,
                                     breaks = c(1,5,10,15,20,40,60))


```


```{r, fig.height = 10, fig.width = 10, echo = include.code} 
state.space.fig
```

The following chunks of code will recreate all the plots found in Fig. S23, S26-S28, and the bottom row of S29. Theses analyses are based on estimated cases that corrects for under-reporting using a state space model, rather than reported cases.  All analyses were conducted the exact same as when using reported cases, with one small exception. When building the canonical path based on estimated cases, there is a gap between African region countries and Americas region countries, as seen in the figure above (Fig. S14), therefore we forced the gap to be filled with three addtional points. For consistency with the analysis of the main text, we removed three other points. As a result there are 2 main changes to the code: the first is to replace the canonical.path.data with data from the state space model, and the second is to replace the object use.reported.cases with FALSE.
  
```{r, echo = include.code}
canonical.path.data <- state.space.data
use.reported.cases = F
```

```{r, echo = include.code, include = FALSE}

##' set up variables to use for making the canonical path and the
##' assignment of countries to the closest point on the path

d = canonical.path.data
use.rep.cases = use.reported.cases
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")
make.inc.cv.scale.same = 1 
sqrt.inc = F 
sqrt.cv = F
connect.canonical.path.to.zero = 0
log.incidence = T 
number.of.additional.points = 4 #4 additional points between each of 38 points

##' d1 will contain the closest point on the canonical path over time.
list[d1, canonical.path] = closest.path.point(d = d, 
                                              use.rep.cases = use.rep.cases,
                                              regions = regions, 
                                              years = seq(1990, 2017),
                                              make.inc.cv.scale.same = make.inc.cv.scale.same,
                                              sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                              connect.canonical.path.to.zero,
                                              log.incidence = log.incidence)

##' d1b will contain the closest point on the granular canonical path over time.
list[d1b, granular.canonical.path] = closest.path.point.movement.comparison(d = d, 
                                                                            use.rep.cases = use.rep.cases,
                                                                            regions = regions, 
                                                                            years = seq(1990, 2017),
                                                                            make.inc.cv.scale.same = make.inc.cv.scale.same,
                                                                            sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                                                            connect.canonical.path.to.zero,
                                                                            log.incidence = log.incidence,
                                                                            number.of.additional.points = number.of.additional.points) 
```

```{r, echo = include.code, fig.height = 10, fig.width = 10}

canonical.path2 <- Unscaled.Canonical.Path(canonical.path.data = canonical.path.data, 
                                           canonical.path = canonical.path, 
                                           regions=regions, 
                                           years = seq(1990, 2017))

#Newest figure which combines ribbon (pop at point) and cumulative proportion of the global pop (color)
df.tmp <- d1
#Add population size to the data frame
df.tmp$pop <- as.numeric(rep(NA, nrow(df.tmp)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(df.tmp)){
  row <- which(pop.by.year$Country.Name==df.tmp$Country[a])
  col <- which((1961:2017)==df.tmp$Year[a])+2
  df.tmp$pop[a] <- pop.by.year[row,col]
  if (is.na(df.tmp$pop[a]) | df.tmp$pop[a]=="#N/A") {df.tmp$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(df.tmp$pop[a]) | df.tmp$pop[a]=="#N/A") {df.tmp$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(df.tmp$pop[a]) | df.tmp$pop[a]=="#N/A") {df.tmp$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(df.tmp$pop[a]) | df.tmp$pop[a]=="#N/A") {df.tmp$pop[a] <- pop.by.year[row,(col-4)]}
}
df.tmp$pop <- as.numeric(df.tmp$pop)

#Best position 2012-2017 for each country
dfbest.tmp <- df.tmp %>%
  filter(Year>2012) %>%
  group_by(Country) %>%
  dplyr::summarise(closest = max(closest), pop = pop[Year==2017]) %>%
  group_by(closest) %>%
  dplyr::summarise(pop = sum(pop))

#Scaling and smoothing the population over the canonical path
population <- log(dfbest.tmp$pop)+1
index <- match(1:38, dfbest.tmp$closest)
population <- population[index]
population[is.na(population)] <- 0 #filling in missing points on the path
smoothed.pop <- rep(NA, length(population))
for (i in 2:37){
  smoothed.pop[i] <- mean(population[(i-1):(i+1)])
}
smoothed.pop[1] <- population[1]
smoothed.pop[38] <- population[38]
smoothed.scaled.pop <-  1*(smoothed.pop/sum(smoothed.pop))#scale to be between 0 and 1
#Get unit vectors for line thickness
df.polygon1 <- GetLineOrthogonalToPath(canonical.path.line=data.frame(x=canonical.path2$x, y=sqrt(canonical.path2$y)), smoothed.scaled.pop)

#plotted in sqrt incidence to be able to better deferentiate the points towards the end of the path
par(bty="n")
cols.1 <- colorRampPalette(c("red", "white", "blue"))(length(canonical.path$x))
plot(canonical.path2$x, sqrt(canonical.path2$y), pch = 21, cex = 2,
     xlab = 'coefficient of variation', ylab= 'mean incidence per 1000', bty="n", 
     yaxt = "n", cex.axis=1.5, cex.lab = 1.5, col = 'black', bg = cols.1, type="n")
axis(2, at=sqrt(c(0, 0.025, 0.1,0.5,1,1.5,2.5,5,10,20)), labels=c(0, 0.025, 0.1,0.5, 1, 1.5,2.5,5,10,20), cex.axis = 1.5, cex.lab=1.5)
for (p in 2:nrow(df.polygon1)){
  polygon(c(df.polygon1$x0[(p-1):p], rev(df.polygon1$x1[(p-1):p])), (c(df.polygon1$y0[(p-1):p],rev(df.polygon1$y1[(p-1):p]))), col="grey", border=NA)
}
points(canonical.path2$x, sqrt(canonical.path2$y), pch = 21, cex = 1.5, col = 'black', bg = cols.1)

#Earliest position for each country
dfearliest.tmp <- df.tmp %>%
  group_by(Country) %>%
  filter(Year==min(Year)) %>%
  group_by(closest) %>%
  dplyr::summarise(pop = sum(pop))

#Scaling and smoothing the population over the canonical path
population <- log(dfearliest.tmp$pop)+1
index <- match(1:38, dfearliest.tmp$closest)
population <- population[index]
population[is.na(population)] <- 0 #filling in missing points on the path
smoothed.pop <- rep(NA, length(population))
for (i in 2:37){
  smoothed.pop[i] <- mean(population[(i-1):(i+1)])
}
smoothed.pop[1] <- population[1]
smoothed.pop[38] <- population[38]
smoothed.scaled.pop <-  1*(smoothed.pop/sum(smoothed.pop))#scale to be between 0 and 1
#Get unit vectors for line thickness
df.polygon2 <- GetLineOrthogonalToPath(canonical.path.line=data.frame(x=canonical.path2$x, y=sqrt(canonical.path2$y)), smoothed.scaled.pop)

#plot it
par(bty="n")
cols.1 <- colorRampPalette(c("red", "white", "blue"))(length(canonical.path$x))
plot(canonical.path2$x, sqrt(canonical.path2$y), pch = 21, cex = 2,
     xlab = 'coefficient of variation', ylab= 'mean incidence per 1000', bty="n", 
     yaxt = "n", cex.axis=1.5, cex.lab = 1.5, col = 'black', bg = cols.1, type="n")
axis(2, at=sqrt(c(0, 0.025, 0.1,0.5,1,1.5,2.5,5,10,20)), labels=c(0, 0.025, 0.1,0.5, 1, 1.5,2.5,5,10,20), cex.axis = 1.5, cex.lab=1.5)
for (p in 2:nrow(df.polygon1)){
  polygon(c(df.polygon2$x0[(p-1):p], rev(df.polygon2$x1[(p-1):p])), (c(df.polygon2$y0[(p-1):p],rev(df.polygon2$y1[(p-1):p]))), col="grey", border=NA)
}
points(canonical.path2$x, sqrt(canonical.path2$y), pch = 21, cex = 1.5, col = 'black', bg = cols.1)

```


```{r, echo=include.code, include=FALSE}
##' First add population size to the data.frame because we need to weight the region estimates by population size of coutry
d1b$pop <- as.numeric(rep(NA, nrow(d1b)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(d1b)){
  row <- which(pop.by.year$Country.Name==d1b$Country[a])
  col <- which((1961:2017)==d1b$Year[a])+2
  d1b$pop[a] <- pop.by.year[row,col]
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-4)]}
}
d1b$pop <- as.numeric(d1b$pop)

##' Get country-specific population weight for each region and year
##' This will be used to weight the average position by region overtime
d1b <- d1b %>%
  dplyr::group_by(WHO_REGION, Year) %>%
  dplyr::mutate(weight = pop/sum(pop))
d1b$weight <- round(d1b$weight,5)

##' create data frame to store values in
deltas.by.continent = data.frame(matrix(NA, nrow(d1b), 6))
colnames(deltas.by.continent) = c("country", "region", "year", "delta", "pos","weight")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
  c1 = d1b$Country[i]
  y = d1b$Year[i]
  pos = d1b$closest[i]
  
  ##' for each country, each year, find the data for the same country the following year
  
  k = d1b %>% filter(Country == c1, Year == (y+1))
  if(nrow(k)>0){
    pos2 = k$closest
    deltas.by.continent[count, ] =  c(c1, k$WHO_REGION, y+1, pos2-pos, pos2, k$weight)
    count = count + 1
  }
}

##' remove data which is NA
j = which(is.na(deltas.by.continent$country))
if(length(j) >0 ){
  deltas.by.continent = deltas.by.continent[-(j),]
}

##' extract the unique years from the data set containing the changes for each year
all.years = as.numeric(unique(deltas.by.continent$year))
countries = unique(deltas.by.continent$country)

##' change the data to be characters and numbers
deltas.by.continent$country = deltas.by.continent$country %>% as.character
deltas.by.continent$region = deltas.by.continent$region %>% as.character
deltas.by.continent$year = deltas.by.continent$year %>% as.character %>% as.numeric
deltas.by.continent$delta = deltas.by.continent$delta %>% as.character %>% as.numeric
deltas.by.continent$pos = deltas.by.continent$pos %>% as.character %>% as.numeric
deltas.by.continent$weight = deltas.by.continent$weight %>% as.character %>% as.numeric

##'choose a period of time over which to smooth the average position of the WHO regions. 
##'A 2 this means that we smooth using the average of a given year along with two years before and two years after
moving.av.length = 2

##' set up a dataframe to hold the weighted data
deltas.summary.weighted = data.frame(matrix(NA, (length(all.years)-2)*length(countries), 6))
colnames(deltas.summary.weighted) = c("country","region", "year", "mean.delta", "mean.pos", "weight")

count = 1
for(i in (moving.av.length+1):length(all.years - moving.av.length)){
  ##' choose the years we wish to include in the averaging
  years = all.years[(i-moving.av.length):(i+moving.av.length)]
  for(j in 1 : length(countries)){
    ##' find the require data
    c = countries[j]
    d = deltas.by.continent %>% filter(year %in% years & country ==c) 
    r = d$region[1]
    
    ##' record the regions, the year in question, along with summaries of the change in movement, along
    ##' with the mean position of the region over the years in question
    deltas.summary.weighted[count, ] = c(c, 
                                         r,
                                         years[(moving.av.length + 1)],
                                         mean(d$delta),
                                         mean(d$pos),
                                         mean(d$weight)) #keep the weight for appropriate year
    count = count + 1
  }
}

##' remove data which is NA
j = which(deltas.summary.weighted$mean.delta=="NaN")
if(length(j) >0 ){
  deltas.summary.weighted = deltas.summary.weighted[-(j),]
}

##' change the data to be characters and numbers
deltas.summary.weighted$country = deltas.summary.weighted$country %>% as.character
deltas.summary.weighted$region = deltas.summary.weighted$region %>% as.character
deltas.summary.weighted$year = deltas.summary.weighted$year %>% as.character %>% as.numeric
deltas.summary.weighted$mean.delta = deltas.summary.weighted$mean.delta %>% as.character %>% as.numeric
deltas.summary.weighted$mean.pos = deltas.summary.weighted$mean.pos %>% as.character %>% as.numeric
deltas.summary.weighted$weight = deltas.summary.weighted$weight %>% as.character %>% as.numeric

dd <- deltas.summary.weighted

##' summarise with average position for each region, by year
dd2 = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.pos = mean(mean.pos))
dd3 = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.delta = mean(mean.delta))

##' summarise the population weighted average position for each region, by year
dd2b = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.pos = sum(mean.pos*weight))
dd3b = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.delta = sum(mean.delta*weight))
```

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1)

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1)

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2b, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1)

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3b, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1)

```

```{r, echo = include.code,  fig.height = 5, fig.width = 10}
plot.year = 2017

missing.countries = c("Bosnia and Herzegovina", "Central African Republic",
                      "Congo, Republic of The", "Czech Republic", "Korea, North",
                      "Congo, Democratic Republic of the", "Dominican Republic", "Gambia, The",   
                      "Burma", "Korea, South", "South Sudan")

replace.countries = c("Bosnia and Herz", "Central African Rep.", "Congo", "Czech Rep.",
                      "Dem. Rep. Korea", "Dem. Rep. Congo", "Dominican Rep.", "Gambia",
                      "Myanmar", "Korea", "S. Sudan")


list[w.plot, A, canonical.path] = plot.world.map (d = canonical.path.data, 
                                                  use.rep.cases = use.reported.cases,
                                                  regions,
                                                  year = plot.year,
                                                  make.inc.cv.scale.same = 1,
                                                  sqrt.inc = F,
                                                  missing.countries,
                                                  replace.countries,
                                                  connect.canonical.path.to.zero = 0 ,
                                                  log.incidence = T,
                                                  with.text = 1)
w.plot

```


```{r, echo=include.code}
position.and.movement.comparison = data.frame(matrix(NA, nrow(d1b), 15))
colnames(position.and.movement.comparison) = c("country", "region", "year", 
                                  "actual.x", "actual.y",
                                  "next.actual.x", "next.actual.y",
                                  "actual.x.change", "actual.y.change",
                                  "canonical.x","canonical.y", 
                                  "next.canonical.x", "next.canonical.y",
                                  "canonical.x.change", "canonical.y.change")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
    c1 = d1b$Country[i]
    y = d1b$Year[i]
    pos = d1b$closest[i]
    
    ##' for each country, each year, find the data for the same country the following year
    
    k = d1b %>% filter(Country == c1, Year == (y+1)) #looking one year ahead (i.e., 1 for observed, and 5 for expected)
    if(nrow(k)>0){
        if(pos < (nrow(granular.canonical.path)-5)){
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           granular.canonical.path$x[(pos+5)], granular.canonical.path$y[(pos+5)],
                                                           granular.canonical.path$x[(pos+5)]-d1b$canonical.x[i],
                                                           granular.canonical.path$y[(pos+5)]-d1b$canonical.y[i])
       } else if (pos < (nrow(granular.canonical.path)-1)) { #if within the last 5 granular points, then just use last position (186)
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           granular.canonical.path$x[186], granular.canonical.path$y[186],
                                                           granular.canonical.path$x[186]-d1b$canonical.x[i],
                                                           granular.canonical.path$y[186]-d1b$canonical.y[i])
       } else { #else means the country is at the end of the granular path, so force canonical path change to 0
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           0,0)
            
        }
               count = count + 1
    }
}

#remove non filled in rows
df <- position.and.movement.comparison %>% filter(!is.na(country))

#making numeric
df$actual.x.change = df$actual.x.change %>% as.character %>% as.numeric
df$actual.y.change = df$actual.y.change %>% as.character %>% as.numeric
df$canonical.x.change = df$canonical.x.change %>% as.character %>% as.numeric
df$canonical.y.change = df$canonical.y.change %>% as.character %>% as.numeric

#force observed movements at the end of the granular pathway to 0
end.x <- granular.canonical.path$x[length(granular.canonical.path$x)]
df$path.end <- ifelse(df$canonical.x==end.x & df$next.canonical.x==end.x, 1, 0)

#force actual movement of observations not moving from the end of the path to zero
df$actual.x.change.raw <- df$actual.x.change #save the raw estimates into this variable
df$actual.y.change.raw <- df$actual.y.change #save the raw estimates into this variable
df$actual.x.change[which(df$path.end==1)] <- 0
df$actual.y.change[which(df$path.end==1)] <- 0

#calculating the angle
df$actual.angle <- (atan2(df$actual.y.change,df$actual.x.change)*-180/pi)
df$canonical.angle <- (atan2(df$canonical.y.change,df$canonical.x.change)*-180/pi) 

#Angle difference
df$angle.diff <- df$actual.angle-df$canonical.angle
#series of if statements: to get angle difference between 180 and -180, rather than -360 and 360.
dft <- df %>% filter(canonical.angle<= -90 & actual.angle>= 90)
df$angle.diff[(df$canonical.angle<= -90 & df$actual.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(actual.angle<= -90 & canonical.angle>= 90)
df$angle.diff[(df$actual.angle<= -90 & df$canonical.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(actual.angle<= -90 & canonical.angle<= 90 & canonical.angle>= 0 & angle.diff< -180)
df$angle.diff[(df$actual.angle<= -90 & df$canonical.angle<= 90 & df$canonical.angle>= 0 & df$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(canonical.angle>= 90 & actual.angle>= -90 & actual.angle<= 0 & angle.diff< -180)
df$angle.diff[(df$canonical.angle>= 90 & df$actual.angle>= -90 & df$actual.angle<= 0 & df$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)

#group angles in 10s
df$canonical.angle10 <- plyr::round_any(df$canonical.angle, 10)
df$actual.angle10 <- plyr::round_any(df$actual.angle, 10)


regs = c("AMR","AFR","EMR","EUR","SEAR","WPR")
year.groups <- list(1990:1999, 2000:2009, 2010:2017)
all.plots <- list()
for (c in 1:length(regs)){
  for (y in 1:3){
    
    #filtering and grouping data to set up dataframe for plotting
    dfo <- df %>%
      dplyr::filter(region==regs[c]) %>%
      dplyr::filter(year %in% year.groups[[y]]) %>%
      dplyr::group_by(a = actual.angle10) %>%
      dplyr::summarise(n=n()) %>%
      dplyr::mutate(frequency=n/sum(n))
    dfe.tmp <- df %>%
      dplyr::filter(region==regs[c]) %>%
      dplyr::filter(year %in% year.groups[[y]]) %>%
      dplyr::group_by(a = round(canonical.angle10)) %>%
      dplyr::summarise(n=n()) %>%
      dplyr::mutate(freq=n/sum(n))
    
    #smoothing expected path
    byn <- seq(-180,179,10)
    dfe <- as.data.frame(matrix(NA, nrow=length(byn), ncol=2))
    colnames(dfe) <- c("a", "freq")
    for (i in 1:length(byn)){
      dfe$freq[i] <- ifelse(is.na(dfe.tmp$freq[match(byn[i], dfe.tmp$a)]),0,
                            dfe.tmp$freq[match(byn[i], dfe.tmp$a)])
      dfe$a[i] <- byn[i]
    }
    dfe$frequency <- rep(NA, nrow(dfe))
    for (r in 1:nrow(dfe)){
      if (r==1) {dfe$frequency[r] <- mean(dfe$freq[(r):(r+2)], na.rm=T)}
      if (r==2) {dfe$frequency[r] <- mean(dfe$freq[(r-1):(r+2)], na.rm=T)}
      if (r>=3) {dfe$frequency[r] <- mean(dfe$freq[(r-2):(r+2)], na.rm=T)}
    }
    
    #merging the datasets together into one
    byn <- seq(-180,179,10)
    dfa <- data.frame(a=rep(byn,3), obs.exp=c(rep("O",length(byn)),rep("FF",length(byn)),rep("E",length(byn))), frequency=rep(NA, length(byn)*3))
    for (i in 1:length(byn)){
      dfa$frequency[which(dfa$obs.exp=="O")[i]] <- dfo$frequency[match(dfa$a[i], dfo$a)]
      dfa$frequency[which(dfa$obs.exp=="E")[i]] <- dfe$frequency[match(dfa$a[i], dfe$a)]
    }
    dfa$label <- c(rep("Observed",length(byn)), rep("blank",length(byn)), rep("Expected",length(byn)))
    dfa$frequency[is.na(dfa$frequency)] <- 0 #because no change is NA
    dfa$frequency[which(dfa$obs.exp=="FF")] <- NA
    dfa$a[dfa$a==seq(-180,-100,10)] <- 360+dfa$a[dfa$a==seq(-180,-100,10)] #hack so the top is -90 degrees and bottom is 90 degrees
    
    #estimating median difference in angle
    dfd <- df %>%
      dplyr::filter(region==regs[c]) %>%
      dplyr::filter(year %in% year.groups[[y]]) %>%
      dplyr::summarise(med=(median(angle.diff)*(-1))) #want positive 90 at top and -90 at bottom
    
    #IQR for region and year
    df.iqr <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]])
    iqr <- round(quantile((df.iqr$angle.diff*(-1)), c(0.25, 0.5,0.75)),2) #want positive 90 degrees top, and -90 degrees bottom
    if (c==1 & y==1) print(c("Region:Year Group ", "25%","50%","75%"))
    print(c(paste(regs[c], year.groups[y]), as.numeric(iqr)))
    
    #plot it
    dfa$obs.exp <- as.numeric(dfa$obs.exp)+2
    name <- paste("reg",c,".year",y, sep="")
    all.plots[[name]] <- 
      ggplot(dfa, aes(x=a, y=obs.exp, fill=(frequency))) +
      geom_tile(colour="white") +
      scale_fill_distiller(palette="YlGnBu", direction=1, limits=c(0,0.3), na.value="white") + #can change limits=c(0,0.2) instead, but will be missing one value
      ylim(c(0, max(dfa$obs.exp) + 0.5)) +
      coord_polar(theta="x") + annotate("text", x = 0, y = 0, label = round(dfd[1,1])) +
      theme(panel.background=element_blank(),
            axis.title=element_blank(),
            panel.grid=element_blank(),
            axis.text.x=element_blank(),
            axis.ticks=element_blank(),
            axis.text.y=element_text(size=5)) + ggtitle(paste(regs[c],": ", year.groups[[y]][1], "-", year.groups[[y]][length(year.groups[[y]])], sep=""))
    
  }
}
```

```{r, fig.height = 9, fig.width = 18}
do.call(grid.arrange, c(grobs=all.plots, nrow=3, as.table=F))
```

```{r, echo = include.code, fig.height = 4, fig.width = 4}
    dfo <- df %>%
      dplyr::group_by(a = actual.angle10) %>%
      dplyr::summarise(n=n()) %>%
      dplyr::mutate(frequency=n/sum(n))
    dfe.tmp <- df %>%
      dplyr::group_by(a = round(canonical.angle10)) %>%
      dplyr::summarise(n=n()) %>%
      dplyr::mutate(freq=n/sum(n))
    
    #smoothing expected path
    byn <- seq(-180,179,10)
    dfe <- as.data.frame(matrix(NA, nrow=length(byn), ncol=2))
    colnames(dfe) <- c("a", "freq")
    for (i in 1:length(byn)){
      dfe$freq[i] <- ifelse(is.na(dfe.tmp$freq[match(byn[i], dfe.tmp$a)]),0,
                            dfe.tmp$freq[match(byn[i], dfe.tmp$a)])
      dfe$a[i] <- byn[i]
    }
    dfe$frequency <- rep(NA, nrow(dfe))
    for (r in 1:nrow(dfe)){
      if (r==1) {dfe$frequency[r] <- mean(dfe$freq[(r):(r+2)], na.rm=T)}
      if (r==2) {dfe$frequency[r] <- mean(dfe$freq[(r-1):(r+2)], na.rm=T)}
      if (r>=3) {dfe$frequency[r] <- mean(dfe$freq[(r-2):(r+2)], na.rm=T)}
    }
    
    #merging the datasets together into one
    byn <- seq(-180,179,10)
    dfa <- data.frame(a=rep(byn,3), obs.exp=c(rep("O",length(byn)),rep("FF",length(byn)),rep("E",length(byn))), frequency=rep(NA, length(byn)*3))
    for (i in 1:length(byn)){
      dfa$frequency[which(dfa$obs.exp=="O")[i]] <- dfo$frequency[match(dfa$a[i], dfo$a)]
      dfa$frequency[which(dfa$obs.exp=="E")[i]] <- dfe$frequency[match(dfa$a[i], dfe$a)]
    }
    dfa$label <- c(rep("Observed",length(byn)), rep("blank",length(byn)), rep("Expected",length(byn)))
    dfa$frequency[is.na(dfa$frequency)] <- 0 #because no change is NA
    dfa$frequency[which(dfa$obs.exp=="FF")] <- NA
    dfa$a[dfa$a==seq(-180,-100,10)] <- 360+dfa$a[dfa$a==seq(-180,-100,10)] #hack so the top is -90 degrees
    
    #estimating median difference in angle
    dfd <- df %>%
      dplyr::summarise(med=median(angle.diff)*(-1)) #want positive 90 top, and -90 bottom
    
    #plot it
    dfa$obs.exp <- as.numeric(dfa$obs.exp)+2
    all.together <-  ggplot(dfa, aes(x=a, y=obs.exp, fill=(frequency))) +
      geom_tile(colour="white") +
      scale_fill_distiller(palette="YlGnBu", direction=1, limits=c(0,0.2), na.value="white") + #Greys
      ylim(c(0, max(dfa$obs.exp) + 0.5)) +
      coord_polar(theta="x") + annotate("text", x = 0, y = 0, label = round(dfd[1,1])) +
      theme(panel.background=element_blank(),
            axis.title=element_blank(),
            panel.grid=element_blank(),
            axis.text.x=element_blank(),
            axis.ticks=element_blank(),
            axis.text.y=element_text(size=5)) +
      ggtitle("All countries and years")
    
    #estimating IQR for difference in angle
    iqr.all <- quantile(df$angle.diff*(-1), c(0.25, 0.5,0.75)) 
    print(iqr.all)
    
    
    all.together
    
```


```{r, echo = include.code, include=F}
##' import the estimated susceptibles for each country and year.
estimated.susceptibles.by.year = read.csv("data/est_sus_by_year.csv", stringsAsFactors = F)
estimated.age.dist.by.year = read.csv("data/est_age_dist_by_year.csv", stringsAsFactors = F)
```

```{r, echo = include.code, include=F}
estimated.susceptibles.by.year = estimated.susceptibles.by.year[, -(1)]
estimated.age.dist.by.year = estimated.age.dist.by.year[, -(1)]
##' run code to generate the number of susceptibles by age by canonical path point
list[dist.by.age, canonical.path, prop.sus, d1, prop.sus.by.age] = 
    plots.for.sus.dist.by.canonical.path (d1 = canonical.path.data, 
                                          d2 = estimated.susceptibles.by.year, 
                                          d3 = estimated.age.dist.by.year,
                                          rep.cases = use.reported.cases,
                                          regions,
                                          make.inc.cv.scale.same = 1,
                                          sqrt.inc = F,
                                          connect.canonical.path.to.zero = 0,
                                          log.incidence = 1,
                                          make.figure.plot = F)
cols.1 <- colorRampPalette(c("red", "white", "blue"))(length(canonical.path$x))
```

```{r, echo = include.code, fig.height = 6, fig.width = 9}

    plot( prop.sus[, 2]*100, pch = 21, cex = 2, ylim=c(4,15),
          xlab = '', ylab= '% susceptible', bty="n",
          xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black')
    smoo <- with(prop.sus[!is.na(prop.sus$y),],smooth.spline(x,y*100, df=4))
    result <- with(prop.sus, predict(smoo,x[is.na(y)]))
    prop.sus[is.na(prop.sus$y),] <- result
    lines(smoo, col='black', lwd=2)
    abline(h = 5, lwd = 2, lty = 2)
    abline(h = ((1/15)*100), lwd = 2, lty = 2)
    
```

```{r, echo = include.code, fig.height = 5, fig.width = 8}

##' import the data on mean age of measles cases
mean.measles.age <- read.csv("data/mean_age_meas.csv", stringsAsFactors = F)

##' melt the mean age of measles data 
melt.mean.measles.age = melt(mean.measles.age, id.vars = c("ISO3", "WHO_REGION", "Country")) %>%
    na.omit

##' remove the X from the year data
melt.mean.measles.age$variable = substr(melt.mean.measles.age$variable, 2, 5) %>% as.numeric

##' rename the columns 
colnames(melt.mean.measles.age) = c("ISO3", "WHO_REGION", "country", "year", "value")

##' remove data for countries which are not included in the canonical path data
k = which(melt.mean.measles.age$country %in% c("occupied Palestinian territory", "#N/A"))
melt.mean.measles.age = melt.mean.measles.age[-(k), ]

##' add a column which will contain the canonical path location of each country and year
melt.mean.measles.age$closest = NA

##' find the canonical path location for each country and year in the mean measles age data
for(i in 1 : nrow(melt.mean.measles.age)){
    k = which(d1$Country == melt.mean.measles.age$country[i] &
                                                     d1$Year == melt.mean.measles.age$year[i])
    if(length(k) > 0){
        melt.mean.measles.age$closest[i] = d1$closest[k]
    }
}

##' find all the locations on the canonical path that the data on the mean age of measles are on
all.closest = unique(melt.mean.measles.age$closest)

##' which locations on the canonical path are not included in this data
missing = setdiff(1:max(all.closest, na.rm = T), all.closest)

##' generate a data set called X, that has the same dimensions as the melted mean measles data
X = data.frame(matrix(NA, length(missing),6))

##' give this data set the same column names as the melted data
colnames(X) = colnames(melt.mean.measles.age)

##' assign the missing canonical path points to the data set X, along with a value outside of the range of the possible mean age of the measles cases
X$closest = missing
X$value = -100

##' combine the melted measles data and the missing data so that we can make a boxplot of the mean age of measles cases
melt.mean.measles.age = rbind(melt.mean.measles.age, X)
```

```{r, echo = include.code, fig.height = 5, fig.width = 10}

boxplot(age ~ point, data = dist.by.age, outline = F, bty = "n",
        ylim = c(0, 60), xaxt = "n", frame.plot = F, xlab = "position on canonical path",
        cex.axis = 1.5, cex.lab = 1.5)

boxplot(value/12 ~ closest, 
        data = melt.mean.measles.age, boxlwd=0.01, whisklwd=2, staplelwd=2.5,
        ylim = c(0,700/12), border = rgb(red = 10/255, green = 10/255, blue = 100/255, alpha = 0.55),
        col = rgb(red = 1/255, green = 10/255, blue = 100/255, alpha = 0.4),
        ylab ="age", xaxt = "n", frame.plot = F,
        pars = list(boxwex = 0.38, staplewex = 0.5, outwex = 0),
        cex.axis = 1.5, cex.lab = 1.5, outline = F, add= T)

axis(1, at = c(1,length(unique(dist.by.age$point))),labels = c("",""))


```


```{r, echo = include.code, include = F}

prop.sus.by.age <- prop.sus.by.age[,-1]
a = 1:59
n = 5
min = c(seq.int(from=1, to=length(a), by=n))
max = c((min-1)[2:length(min)], length(a))
prop.sus.by.age.group = apply(prop.sus.by.age, 1, function(x) sapply(1:length(min), function(i) mean(x[min[i]:max[i]])))
prop.sus.by.age.group <- rbind(prop.sus.by.age.group, prop.sus[, 2]) #add in prop.sus for ALL ages to the last row (same as Fig. 2A)

dist.by.age.rep = dist.by.age
points = unique(dist.by.age.rep$point)
perc.by.age.sia.rep = data.frame(matrix(NA, max(points), 5))
perc.by.age.sia.rep[,1] = 1:max(points)
colnames(perc.by.age.sia.rep) = c("pos", "perc.to.5", "perc.to.10", "perc.to.15", "age.for.90.perc")

for(i in 1 : length(points)){
    p = dist.by.age.rep[which(dist.by.age.rep$point == points[i]), ]
    if(nrow(p) > 1){ #xxamy this if statement was added
    p1 = p %>% filter(age <= 5)
    p2 = p %>% filter(age <= 10)
    p3 = p %>% filter(age <= 15)
    p4 = p[order(p$age), ]
    
    perc.by.age.sia.rep[points[i], ] = c(points[i], 
                             nrow(p1)*100/nrow(p),
                             nrow(p2)*100/nrow(p),
                             nrow(p3)*100/nrow(p),
                             p4[floor(nrow(p)*0.9), 2] )
    }
}


##'  adjust positions of the percentage age to sia age to go from 1 to
##' the number of points that have countries assigned to them
perc.by.age.sia.rep$pos = 1:nrow(perc.by.age.sia.rep)
#plot(perc.by.age.sia.rep$pos, perc.by.age.sia.rep$age.for.90.perc)
#k=unique(dist.by.age$point)
#k = k[order(k)]

```


```{r, echo = include.code, fig.height = 6, fig.width = 9.5}

levelplot(t(as.matrix(prop.sus.by.age.group)), ylab="age (years)", 
          xlab="position on canonical path", xaxt = "n",
          col.regions=colorRampPalette(brewer.pal(9,"Greys")),
          scales=list(y=list(at=1:13, labels=c("<5","5-9","10-14","15-19","20-24","25-29","30-34","35-39","40-44","45-49",
                                                                                            "50-54","55-59", "all"))))

plot( perc.by.age.sia.rep$pos, perc.by.age.sia.rep$perc.to.5, pch = 21, cex = 2,
      xlab = '', ylab= '% of susceptibles 5 or under', bty="n",
      xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black', ylim = c(10,70))
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$perc.to.5),], smooth.spline(pos,perc.to.5, df=7), cv = T)
lines(smoo, col='black', lwd=2)
abline(h = 50, lwd = 2, lty = 2)
abline(h = 2/30, lwd = 2, lty = 2)


plot(perc.by.age.sia.rep$pos, perc.by.age.sia.rep$age.for.90.perc, pch = 21, cex = 2,
     xlab = '', ylab= 'oldest SIA age to reach 90% of susceptibles', bty="n",ylim = c(14,42),
     xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black')
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$age.for.90.perc),], smooth.spline(pos,age.for.90.perc, df=6))
result <- with(perc.by.age.sia.rep, predict(smoo,pos[is.na(perc.by.age.sia.rep$age.for.90.perc)]))
perc.by.age.sia.rep[is.na(perc.by.age.sia.rep$age.for.90.perc),5] <- result$y
lines(smoo, col='black', lwd=2)

plot( perc.by.age.sia.rep$pos, perc.by.age.sia.rep$perc.to.15, pch = 21, cex = 2,
      xlab = '', ylab= '% of susceptibles 15 or under', bty="n",
      xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black')
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$perc.to.15),], smooth.spline(pos,perc.to.15, df=3), cv = T)
lines(smoo, col='black', lwd=2)
```


Similar to Fig. S22, we can assess the expected mean and coefficient of variation of incidence given a range of birth rates, vaccination coverage levels, and susceptible recruitment but instead using estimated measles incidence, rather than reported. This is seen below and Fig. S23 of the paper.

```{r, echo = include.code, include = F}

Amr.Af.data.state.space = rbind(Af.data.state.space, Amr.data.state.space)
all.but.euro.state.space = rbind(Amr.Af.data.state.space, filter(Rest.data, WHO_REGION != "EUR"))
Combined.data.state.space = rbind(Rest.data.state.space, Amr.Af.data.state.space)


list[h, z, j, z1, colfunc.br, colfunc.vacc, colfunc.br.vacc] = produce.gams.plot(data = Combined.data.state.space,
                  ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500)),
                  tick.labels = c(0,25,100, 250,500))

list[ha, za, ja, z1a, colfunc.br, colfunc.vacc, colfunc.br.vacc] = produce.gams.plot(data = all.but.euro.state.space,
                  ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500)),
                  tick.labels = c(0,25,100, 250,500))
 
```



```{r, echo = include.code, fig.height = 8, fig.width = 8}
tick.labels = c(0,25,100, 250,500)
ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500))
plot.alpha = 0.8
##' construct the plot
    plot(h$x, sqrt(100*h$y), yaxt = "n", xlab = "coefficient of variation", 
         ylab = "mean incidence per 100,000",
         col = alpha(colfunc.br(nrow(h)),plot.alpha), 
         pch = 16, cex = 1.5, xlim = c(min(z1$x), max(z1$x)), frame.plot = FALSE,
         ylim = c(0, sqrt(100*max(z1$y))), cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5)
    points(z$x, sqrt(100 * z$y), col = alpha(colfunc.vacc(nrow(z)), plot.alpha),
           pch = 17, cex = 1.5)
    points(j$x, sqrt(100 * j$y), col = alpha(colfunc.br.vacc(nrow(j)), plot.alpha),
           pch = 15, cex = 1.5)
    legend('topright', bty = 'n', c("br","vacc","br(1-vacc)"), pch = c(16, 17,15), 
           col = c("darkgreen", "navyblue","firebrick"), cex = 1.5)
    
    ##' tick marks trick, to get the true values rather than sqrt value on y axis
    axis(2, at=ticks, labels=tick.labels, cex.axis = 1.5)
```
   
    
```{r, echo = include.code, fig.height = 8, fig.width = 8} 
       plot(ha$x, sqrt(100*ha$y), yaxt = "n", xlab = "coefficient of variation", 
         ylab = "mean incidence per 100,000",
         col = alpha(colfunc.br(nrow(ha)),plot.alpha), 
         pch = 16, cex = 1.5, xlim = c(min(z1a$x), max(z1a$x)), frame.plot = FALSE,
         ylim = c(0, sqrt(100*max(z1$y))), cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5)
    points(za$x, sqrt(100 * za$y), col = alpha(colfunc.vacc(nrow(za)), plot.alpha),
           pch = 17, cex = 1.5)
    points(ja$x, sqrt(100 * ja$y), col = alpha(colfunc.br.vacc(nrow(ja)), plot.alpha),
           pch = 15, cex = 1.5)
    legend('topright', bty = 'n', c("br","vacc","br(1-vacc)"), pch = c(16, 17,15), 
           col = c("darkgreen", "navyblue","firebrick"), cex = 1.5)
    
    ##' tick marks trick, to get the true values rather than sqrt value on y axis
    axis(2, at=ticks, labels=tick.labels, cex.axis = 1.5)
    

```

Figure S24 shows the age distribution of cases in Malawi and Angola from 2006-2013. This figure is reproduced below.

```{r, echo = F, fig.height = 8, fig.width = 12}

Cases.by.age = read.csv("data/Angola_Malawi_cases.csv")


par(mfrow = c(1,2))
plot.case.boxplots(Cases.by.age, "Malawi", col = "#9964BF", alpha = 0.75)
plot.case.boxplots(Cases.by.age, "Angola", col = "#9964BF", alpha = 0.75)



```

# References










