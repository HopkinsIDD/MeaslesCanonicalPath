---
title: "Measles and the Canonical Path to Elimination"
output:
  pdf_document: default
  html_document:
    keep_md: yes
bibliography: bibliography.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn=-1)
require(ggplot2)
require(mgcv)
require(tmap)
require(magrittr)
require(tidyverse)
require(RColorBrewer)
require(tmap)
require(reshape2)
require(wpp2015)
require(wesanderson)
library(lattice)
require(SDMTools)
library(gridExtra)
##' if we want to reproduce the code in the output, then change the next line to include.code = T
include.code = F
source("Functions.R")
```

This notebook will construct the figures for the paper by Graham et al., titled "Measles and the Canonical Path to Elimination." First we weighted case data along with population data to construct a dataset which can be used to plot each country through time in 'incidence-space', which has the incidence on the y-axis, and the coefficient of variation of incidence over time on the x-axis.

```{r,  echo = include.code, include = F}
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")

##' this line assigns the constructed data to the data set canonical.path.data
canonical.path.data = generate.data(window.length = 10, regions,
                                                      gaussian.st.dev = 3, cutoff = 50,
                                                      interp.resolution = 20, year.shift.inc = 2)



```

```{r, echo = include.code, include = F}

canonical.path.data = add.mcv2.data.to.anim.data (canonical.path.data, 
                                                                non.mcv2.alpha = 0.4, mcv2.alpha = 0.4)





```

Following the construction of this data set, we plot Figure 1A from the paper. This figure shows the position of
countries in the Americas and in Africa in two years, along with the mean path taken by these continents from 
the beginning of the data set to the end of it. These mean paths are shown by the green and purple lines in the
figure below, with the green line being for Africa and the purple one for the Americas.

```{r, echo = include.code, include=FALSE}


taxonomy.fig1 = incidence.space.fig.dashed.arrow(anim.data = canonical.path.data, years = c(1990, 2017), 
                                     regions = c("AFR",  "AMR"), shapes = c(1,2,16,17),
                                     countries.of.interest = c("Malawi", "United States", 
                                                               "Brazil", "Argentina",
                                                               "Congo, Democratic Republic of the",
                                                               "Zambia",
                                                               "Uruguay", "Tanzania"),
                                     colors = c( "#367526", "#7a40a0"), text.size = 4,xint=-1.07, yint = 0.25,
                                     line.color = 'grey1', arrow.size = 2,
                                     breaks = c(1,5,10,15,20,40,60))


```


```{r, fig.height = 10, fig.width = 10, echo = include.code} 
taxonomy.fig1
```

By combining the trajectories, we can create the canonical path towards elimination seen in Fig. 1B in the paper.
This figure was created in Adobe Illustrator, so cannot be reproduced here.

The canonical path seen in Fig. 2A is constructed by putting the incidence and coefficient of variation on the same scale (by multiplying the incidence by max(coefficient of variation) / max(incidence)) and then calculating the mean trajectories of Africa and the Americas over time, and combining these at the point that they intersect, i.e. at the point that the green and purple lines cross in the plot above.

```{r, echo = include.code}
use.reported.cases = TRUE
list[d1a, canonical.path2] = closest.path.point(d = canonical.path.data, 
                                                  use.rep.cases = use.reported.cases,
                                                  regions = regions, 
                                                  years = seq(1990, 2017),
                                                  make.inc.cv.scale.same = 0,
                                                  sqrt.inc = T,
                                                  connect.canonical.path.to.zero = 0,
                                                  log.incidence = 0,
                                                  make.figure.plot = T)

```


```{r, echo = include.code, fig.height = 6, fig.width = 8}
cols.1 <- colorRampPalette(c("red", "white", "blue"))(length(canonical.path2$x))
 plot(canonical.path2$x, canonical.path2$y, pch = 21, cex = 2,
         xlab = 'coefficient of variation', ylab= 'scaled mean incidence', bty="n", 
         yaxt = "n", cex.axis=1.5, cex.lab = 1.5, col = 'black', bg = cols.1)
    axis(2, at=c(sqrt(0.1),sqrt(seq(0,1.2, 0.2))), labels=c(0.1,seq(0, 1.2, 0.2)), cex.axis = 1.5)

```

The analysis performed in the paper relies on the fact that when we calculate the position of a country at a given time in the incidence-space, we can calculate which point on the canonical path this country's location is closest to. However, we can see that when we do this there are positions which are close to each other distance wise on this path, but far in terms of progression towards elimination, due to the fact that on the lower end of incidence, there is very little distance between the points. For example if, in a given year, a country lay at the point 1.4 on the x-axis, and has a fairly low incidence, then it could easily be assigned to a point very close to the end of the path to elimination or one which is about half way along the path. This is not a desirable property of the canonical path. To help distinguish the points more clearly, and help this assignment of nations, we do two things. Firstly, we take the log (natural base) of the incidence, and secondly, we transform both the incidence and the coefficient of variation data to be on the 0-1 scale. This is done in the chunk below.

```{r, echo = include.code, include = FALSE}

##' set up variables to use for making the canonical path and the
##' assignment of countries to the closest point on the path

d = canonical.path.data
use.reported.cases = TRUE
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")
make.inc.cv.scale.same = 1 
sqrt.inc = F 
sqrt.cv = F
connect.canonical.path.to.zero = 0
log.incidence = T 
number.of.additional.points = 4 #4 additional points between each of 38 points

##' d1 will contain the closest point on the canonical path over time.
list[d1, canonical.path] = closest.path.point(d = d, 
                                              use.rep.cases = use.reported.cases,
                                              regions = regions, 
                                              years = seq(1990, 2017),
                                              make.inc.cv.scale.same = make.inc.cv.scale.same,
                                              sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                              connect.canonical.path.to.zero,
                                              log.incidence = log.incidence)

##' d1b will contain the closest point on the granular canonical path over time.
list[d1b, granular.canonical.path] = closest.path.point.movement.comparison(d = d, 
                                              use.rep.cases = use.reported.cases,
                                              regions = regions, 
                                              years = seq(1990, 2017),
                                              make.inc.cv.scale.same = make.inc.cv.scale.same,
                                              sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                              connect.canonical.path.to.zero,
                                              log.incidence = log.incidence,
                                              number.of.additional.points = number.of.additional.points) 
```

When we plot the canonical path now, we see that there is a much greater distinction between points at the low incidence part of the path (Fig. S3 in the supplement).  

```{r, echo = include.code, fig.height = 6, fig.width = 8}

plot(canonical.path$x, canonical.path$y, pch = 21, cex = 2,
         xlab = 'scaled coefficient of variation', ylab= 'scaled mean incidence', bty="n", 
     cex.axis=1.5, cex.lab = 1.5, col = 'black', bg = cols.1)
points(granular.canonical.path$x, granular.canonical.path$y, pch = 16, cex = 0.5)

```

We can now assign countries to the closest point on this path each year that we have data for, using the re-scaled canonical path. This is seen in Fig. 4A in the paper, where we plot all countries position on the path overtime.

```{r, echo = include.code, include = F}

##' First add population size to the data.frame because we need to weight the region estimates by population size of coutry
d1b$pop <- as.numeric(rep(NA, nrow(d1b)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(d1b)){
  row <- which(pop.by.year$Country.Name==d1b$Country[a])
  col <- which((1961:2017)==d1b$Year[a])+2
  d1b$pop[a] <- pop.by.year[row,col]
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-4)]}
}
d1b$pop <- as.numeric(d1b$pop)

##' Get country-specific population weight for each region and year
##' This will be used to weight the average position by region overtime
d1b <- d1b %>%
  group_by(WHO_REGION, Year) %>%
  mutate(weight = pop/sum(pop))
d1b$weight <- round(d1b$weight,5)

##' create data frame to store values in
deltas.by.continent = data.frame(matrix(NA, nrow(d1b), 6))
colnames(deltas.by.continent) = c("country", "region", "year", "delta", "pos","weight")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
  c1 = d1b$Country[i]
  y = d1b$Year[i]
  pos = d1b$closest[i]
  
  ##' for each country, each year, find the data for the same country the following year
  
  k = d1b %>% filter(Country == c1, Year == (y+1))
  if(nrow(k)>0){
    pos2 = k$closest
    deltas.by.continent[count, ] =  c(c1, k$WHO_REGION, y+1, pos2-pos, pos2, k$weight)
    count = count + 1
  }
}

##' remove data which is NA
j = which(is.na(deltas.by.continent$country))
if(length(j) >0 ){
  deltas.by.continent = deltas.by.continent[-(j),]
}

##' extract the unique years from the data set containing the changes for each year
all.years = as.numeric(unique(deltas.by.continent$year))
countries = unique(deltas.by.continent$country)

##' change the data to be characters and numbers
deltas.by.continent$country = deltas.by.continent$country %>% as.character
deltas.by.continent$region = deltas.by.continent$region %>% as.character
deltas.by.continent$year = deltas.by.continent$year %>% as.character %>% as.numeric
deltas.by.continent$delta = deltas.by.continent$delta %>% as.character %>% as.numeric
deltas.by.continent$pos = deltas.by.continent$pos %>% as.character %>% as.numeric
deltas.by.continent$weight = deltas.by.continent$weight %>% as.character %>% as.numeric

##'choose a period of time over which to smooth the average position of the WHO regions. 
##'A 2 this means that we smooth using the average of a given year along with two years before and two years after
moving.av.length = 2

##' set up a dataframe to hold the weighted data
deltas.summary.weighted = data.frame(matrix(NA, (length(all.years)-2)*length(countries), 6))
colnames(deltas.summary.weighted) = c("country","region", "year", "mean.delta", "mean.pos", "weight")

count = 1
for(i in (moving.av.length+1):length(all.years - moving.av.length)){
  ##' choose the years we wish to include in the averaging
  years = all.years[(i-moving.av.length):(i+moving.av.length)]
  for(j in 1 : length(countries)){
    ##' find the require data
    c = countries[j]
    d = deltas.by.continent %>% filter(year %in% years & country ==c) 
    r = d$region[1]
    
    ##' record the regions, the year in question, along with summaries of the change in movement, along
    ##' with the mean position of the region over the years in question
    deltas.summary.weighted[count, ] = c(c, 
                                         r,
                                         years[(moving.av.length + 1)],
                                         mean(d$delta),
                                         mean(d$pos),
                                         mean(d$weight)) #keep the weight for appropriate year
    count = count + 1
  }
}

##' remove data which is NA
j = which(deltas.summary.weighted$mean.delta=="NaN")
if(length(j) >0 ){
  deltas.summary.weighted = deltas.summary.weighted[-(j),]
}

##' change the data to be characters and numbers
deltas.summary.weighted$country = deltas.summary.weighted$country %>% as.character
deltas.summary.weighted$region = deltas.summary.weighted$region %>% as.character
deltas.summary.weighted$year = deltas.summary.weighted$year %>% as.character %>% as.numeric
deltas.summary.weighted$mean.delta = deltas.summary.weighted$mean.delta %>% as.character %>% as.numeric
deltas.summary.weighted$mean.pos = deltas.summary.weighted$mean.pos %>% as.character %>% as.numeric
deltas.summary.weighted$weight = deltas.summary.weighted$weight %>% as.character %>% as.numeric

dd <- deltas.summary.weighted

##' summarise with average position for each region, by year
dd2 = dd %>% 
  group_by(region, year) %>%
  summarise(mean.pos = mean(mean.pos))
dd3 = dd %>% 
  group_by(region, year) %>%
  summarise(mean.delta = mean(mean.delta))
```

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1)

```

Countries do not necessarily progress smoothly along the path as if, for example, after years of low incidence is interrupted by a year of high incidence, then this will increase the x and y position of the country in incidence-space and hence the position on the canonical path will head backwards. We demonstrate these movements along the path by plotting the % change in path potion between 1990 and 2017 for each country in addition to region averages, as see in Fig. 4B in the paper.

```{r, fig.height = 6, fig.width = 6, echo = include.code} 

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1)

```

We can alternatively overlay population-weighted region averages by year, as seen in supplemental Fig. S21.

```{r, echo = include.code, include = F}
##' summarise the population weighted average position for each region, by year
dd2b = dd %>% 
  group_by(region, year) %>%
  summarise(mean.pos = sum(mean.pos*weight))
dd3b = dd %>% 
  group_by(region, year) %>%
  summarise(mean.delta = sum(mean.delta*weight))

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2b, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1)

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3b, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1)

```

Given our assignment of all countries to the closest point on the path, for any given year a map can be produced which is colored according to each countries position along the path. This is seen below for 2017 (Fig. 2C of the paper).  We have also made available web application, developed with R package Shiny, to view all countries position on the canonical path between 1980 and 2014 (available at http://iddynamics.jhsph.edu/apps/shiny/measlescanonicalpath/).

```{r, fig.height = 6, fig.width = 10, echo = include.code}
plot.year = 2017

missing.countries = c("Bosnia and Herzegovina", "Central African Republic",
                       "Congo, Republic of The", "Czech Republic", "Korea, North",
                       "Congo, Democratic Republic of the", "Dominican Republic", "Gambia, The",   
                       "Burma", "Korea, South", "South Sudan")

replace.countries = c("Bosnia and Herz", "Central African Rep.", "Congo", "Czech Rep.",
                       "Dem. Rep. Korea", "Dem. Rep. Congo", "Dominican Rep.", "Gambia",
                       "Myanmar", "Korea", "S. Sudan")
 
 
list[w.plot, A, canonical.path] = plot.world.map (d = canonical.path.data, 
                                                  use.rep.cases = 1,
                                                  regions,
                                                  year = plot.year,
                                                  make.inc.cv.scale.same = 1,
                                                  sqrt.inc = F,
                                                  missing.countries,
                                                  replace.countries,
                                                  connect.canonical.path.to.zero = 0 ,
                                                  log.incidence = T,
                                                  with.text = 1)
```

```{r, echo = include.code, fig.height = 4.6, fig.width = 10}
w.plot
```

We can also capture direction of movement of each country within the incidence space in order to assess "deviations" from the path or trajectories of countries in incidence space that were different than expected given the characterized canonical path.  Fig. 4C in the paper is reproduced here.  

```{r, echo=include.code}
position.and.movement.comparison = data.frame(matrix(NA, nrow(d1b), 15))
colnames(position.and.movement.comparison) = c("country", "region", "year", 
                                  "actual.x", "actual.y",
                                  "next.actual.x", "next.actual.y",
                                  "actual.x.change", "actual.y.change",
                                  "canonical.x","canonical.y", 
                                  "next.canonical.x", "next.canonical.y",
                                  "canonical.x.change", "canonical.y.change")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
    c1 = d1b$Country[i]
    y = d1b$Year[i]
    pos = d1b$closest[i]
    
    ##' for each country, each year, find the data for the same country the following year
    
    k = d1b %>% filter(Country == c1, Year == (y+1)) #looking one year ahead (i.e., 1 for observed, and 5 for expected)
    if(nrow(k)>0){
        if(pos < (nrow(granular.canonical.path)-5)){
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           granular.canonical.path$x[(pos+5)], granular.canonical.path$y[(pos+5)],
                                                           granular.canonical.path$x[(pos+5)]-d1b$canonical.x[i],
                                                           granular.canonical.path$y[(pos+5)]-d1b$canonical.y[i])
            
        } else { #else means the country is at the end of the granular path, so force canonical path change to 0
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           0,0)
            
        }
               count = count + 1
    }
}

#remove non filled in rows
df <- position.and.movement.comparison %>% filter(!is.na(country))

#making numeric
df$actual.x.change = df$actual.x.change %>% as.character %>% as.numeric
df$actual.y.change = df$actual.y.change %>% as.character %>% as.numeric
df$canonical.x.change = df$canonical.x.change %>% as.character %>% as.numeric
df$canonical.y.change = df$canonical.y.change %>% as.character %>% as.numeric

#calculating the angle
df$actual.angle <- (atan2(df$actual.y.change,df$actual.x.change)*-180/pi)
df$canonical.angle <- (atan2(df$canonical.y.change,df$canonical.x.change)*-180/pi) 

#Angle difference
df$angle.diff <- df$actual.angle-df$canonical.angle
#series of if statements: to get angle difference between 180 and -180, rather than -360 and 360.
dft <- df %>% filter(canonical.angle<= -90 & actual.angle>= 90)
df$angle.diff[(df$canonical.angle<= -90 & df$actual.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(actual.angle<= -90 & canonical.angle>= 90)
df$angle.diff[(df$actual.angle<= -90 & df$canonical.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(actual.angle<= -90 & canonical.angle<= 90 & canonical.angle>= 0 & angle.diff< -180)
df$angle.diff[(df$actual.angle<= -90 & df$canonical.angle<= 90 & df$canonical.angle>= 0 & df$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(canonical.angle>= 90 & actual.angle>= -90 & actual.angle<= 0 & angle.diff< -180)
df$angle.diff[(df$canonical.angle>= 90 & df$actual.angle>= -90 & df$actual.angle<= 0 & df$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)

#group angles in 10s
df$canonical.angle10 <- plyr::round_any(df$canonical.angle, 10)
df$actual.angle10 <- plyr::round_any(df$actual.angle, 10)

```

We can plot the expected movement and observed movement for each region over 10 or 8 year increments.  The heat map captures the frequency of countries movement in a direction grouped by 10 degree angle groups. This plot will look slightly different than the main text because the main text range is from 0 to >20%, where we grouped frequencies between 20 and 25% into one color dark blue color.  Below we show the range 0 to 25%. 

```{r,echo = include.code}
#looping through regions
regs = c("AMR","AFR","EMR","EUR","SEAR","WPR")
year.groups <- list(1990:1999, 2000:2009, 2010:2017)
all.plots <- list()
for (c in 1:length(regs)){
  for (y in 1:3){
    
    #filtering and grouping data to set up dataframe for plotting
    dfo <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]]) %>%
      group_by(a = actual.angle10) %>%
      summarise(n=n()) %>%
      mutate(frequency=n/sum(n))
    dfe.tmp <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]]) %>%
      group_by(a = round(canonical.angle10)) %>%
      summarise(n=n()) %>%
      mutate(freq=n/sum(n))
    
    #smoothing expected path
    byn <- seq(-180,179,10)
    dfe <- as.data.frame(matrix(NA, nrow=length(byn), ncol=2))
    colnames(dfe) <- c("a", "freq")
    for (i in 1:length(byn)){
      dfe$freq[i] <- ifelse(is.na(dfe.tmp$freq[match(byn[i], dfe.tmp$a)]),0,
                            dfe.tmp$freq[match(byn[i], dfe.tmp$a)])
      dfe$a[i] <- byn[i]
    }
    dfe$frequency <- rep(NA, nrow(dfe))
    for (r in 1:nrow(dfe)){
      if (r==1) {dfe$frequency[r] <- mean(dfe$freq[(r):(r+2)], na.rm=T)}
      if (r==2) {dfe$frequency[r] <- mean(dfe$freq[(r-1):(r+2)], na.rm=T)}
      if (r>=3) {dfe$frequency[r] <- mean(dfe$freq[(r-2):(r+2)], na.rm=T)}
    }
    
    #merging the datasets together into one
    byn <- seq(-180,179,10)
    dfa <- data.frame(a=rep(byn,3), obs.exp=c(rep("O",length(byn)),rep("FF",length(byn)),rep("E",length(byn))), frequency=rep(NA, length(byn)*3))
    for (i in 1:length(byn)){
      dfa$frequency[which(dfa$obs.exp=="O")[i]] <- dfo$frequency[match(dfa$a[i], dfo$a)]
      dfa$frequency[which(dfa$obs.exp=="E")[i]] <- dfe$frequency[match(dfa$a[i], dfe$a)]
    }
    dfa$label <- c(rep("Observed",length(byn)), rep("blank",length(byn)), rep("Expected",length(byn)))
    dfa$frequency[is.na(dfa$frequency)] <- 0 #because no change is NA
    dfa$frequency[which(dfa$obs.exp=="FF")] <- NA
    dfa$a[dfa$a==seq(-180,-100,10)] <- 360+dfa$a[dfa$a==seq(-180,-100,10)] #hack so the top is -90 degrees
    
    #estimating median difference in angle
    dfd <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]]) %>%
      summarise(med=(median(angle.diff)*(-1))) #want positive 90 at top and -90 at bottom
    
    #IQR for region and year
    df.iqr <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]])
    iqr <- quantile((df.iqr$angle.diff*(-1)), c(0.25, 0.5,0.75)) #want positive 90 top, and -90 bottom
    print(c(paste(regs[c], year.groups[y]), iqr))
    
    #plot it
    dfa$obs.exp <- as.numeric(dfa$obs.exp)+2
    name <- paste("reg",c,".year",y, sep="")
    all.plots[[name]] <- 
      ggplot(dfa, aes(x=a, y=obs.exp, fill=(frequency))) +
      geom_tile(colour="white") +
      scale_fill_distiller(palette="YlGnBu", direction=1, limits=c(0,0.25), na.value="white") + 
      ylim(c(0, max(dfa$obs.exp) + 0.5)) +
      coord_polar(theta="x") + annotate("text", x = 0, y = 0, label = round(dfd[1,1])) +
      theme(panel.background=element_blank(),
            axis.title=element_blank(),
            panel.grid=element_blank(),
            axis.text.x=element_blank(),
            axis.ticks=element_blank(),
            axis.text.y=element_text(size=5)) + ggtitle(paste(regs[c],": ", year.groups[[y]][1], "-", year.groups[[y]][length(year.groups[[y]])], sep=""))
    
  }
}
```

We can plot all regions and years here as shown in Fig. 4C.

```{r, fig.height = 9, fig.width = 18}
do.call(grid.arrange, c(grobs=all.plots, nrow=3, as.table=F))
```

We can also plot the expected and observed movements for all countries and years, as shown as the top of Fig. 4C. 

```{r, echo = include.code, fig.height = 3, fig.width = 3}
    dfo <- df %>%
      group_by(a = actual.angle10) %>%
      summarise(n=n()) %>%
      mutate(frequency=n/sum(n))
    dfe.tmp <- df %>%
      group_by(a = round(canonical.angle10)) %>%
      summarise(n=n()) %>%
      mutate(freq=n/sum(n))
    
    #smoothing expected path
    byn <- seq(-180,179,10)
    dfe <- as.data.frame(matrix(NA, nrow=length(byn), ncol=2))
    colnames(dfe) <- c("a", "freq")
    for (i in 1:length(byn)){
      dfe$freq[i] <- ifelse(is.na(dfe.tmp$freq[match(byn[i], dfe.tmp$a)]),0,
                            dfe.tmp$freq[match(byn[i], dfe.tmp$a)])
      dfe$a[i] <- byn[i]
    }
    dfe$frequency <- rep(NA, nrow(dfe))
    for (r in 1:nrow(dfe)){
      if (r==1) {dfe$frequency[r] <- mean(dfe$freq[(r):(r+2)], na.rm=T)}
      if (r==2) {dfe$frequency[r] <- mean(dfe$freq[(r-1):(r+2)], na.rm=T)}
      if (r>=3) {dfe$frequency[r] <- mean(dfe$freq[(r-2):(r+2)], na.rm=T)}
    }
    
    #merging the datasets together into one
    byn <- seq(-180,179,10)
    dfa <- data.frame(a=rep(byn,3), obs.exp=c(rep("O",length(byn)),rep("FF",length(byn)),rep("E",length(byn))), frequency=rep(NA, length(byn)*3))
    for (i in 1:length(byn)){
      dfa$frequency[which(dfa$obs.exp=="O")[i]] <- dfo$frequency[match(dfa$a[i], dfo$a)]
      dfa$frequency[which(dfa$obs.exp=="E")[i]] <- dfe$frequency[match(dfa$a[i], dfe$a)]
    }
    dfa$label <- c(rep("Observed",length(byn)), rep("blank",length(byn)), rep("Expected",length(byn)))
    dfa$frequency[is.na(dfa$frequency)] <- 0 #because no change is NA
    dfa$frequency[which(dfa$obs.exp=="FF")] <- NA
    dfa$a[dfa$a==seq(-180,-100,10)] <- 360+dfa$a[dfa$a==seq(-180,-100,10)] #hack so the top is -90 degrees
    
    #estimating median difference in angle
    dfd <- df %>%
      summarise(med=median(angle.diff)*(-1)) #want positive 90 top, and -90 bottom
    
    #plot it
    dfa$obs.exp <- as.numeric(dfa$obs.exp)+2
    all.together <-  ggplot(dfa, aes(x=a, y=obs.exp, fill=(frequency))) +
      geom_tile(colour="white") +
      scale_fill_distiller(palette="YlGnBu", direction=1, limits=c(0,0.2), na.value="white") + #Greys
      ylim(c(0, max(dfa$obs.exp) + 0.5)) +
      coord_polar(theta="x") + annotate("text", x = 0, y = 0, label = round(dfd[1,1])) +
      theme(panel.background=element_blank(),
            axis.title=element_blank(),
            panel.grid=element_blank(),
            axis.text.x=element_blank(),
            axis.ticks=element_blank(),
            axis.text.y=element_text(size=5)) +
      ggtitle("All countries and years")
    
    #estimating IQR for difference in angle
    iqr.all <- quantile(df$angle.diff*(-1), c(0.25, 0.5,0.75)) 
    print(iqr.all)
    
    #how often angle differences plus or minus 45 degrees
    #observations are year and country
    df.xtra <- df %>%
      filter(angle.diff > 45 | angle.diff < (-45))
    nrow(df.xtra) / nrow(df)
    
    all.together
    
```

Along with this analysis, we used a method for estimating the susceptibility in each year of age which was developed by @tak2015. Each age cohort's susceptibility is estimated based on its opportunity for immunization (via routine and supplementary activities) and risk of natural infection. The probability of immunization was estimated per WHO reported administrative vaccination coverage estimates (@who). The probability of natural infection by age was estimated by assuming a constant hazard of infection over age that scaled each year relative to the proportional decline in estimated measles incidence corrected for under-reporting. Measles incidence, corrected for under-reporting, was estimated using a state space model per @statespace and @simons2012. The following chunks of code first uses the state-space model to estimate the number of measles cases (corrected for under-reporting) by year and country, then goes on to infer susceptibility by age for each country and each year.

```{r, eval=F, include=F, eval = FALSE}
##' this chunk of code runs the state space model that estimates measles incidence as "output-estimated_incidence.csv"
##' and then copied and renamed "State_space_cases_new.csv" 
source("state.space.model/run_state_space_model.R")

```

```{r, eval=F, include=F, eval = FALSE}
##' this chunk of code infers susceptiblity from the estimated measles incidence, birth rates, and vaccination rates
All.countries = as.character(unique(canonical.path.data$Country))
All.countries = All.countries[-(which(All.countries %in% c("")))]

All.countries= All.countries[order(All.countries)]
years = seq(1990,2017)

number.of.susceptibles = number.of.individuals = data.frame(matrix(0, length(years) * length(All.countries), 62))
colnames(number.of.susceptibles) = colnames(number.of.individuals) = c("Country", "Year", paste("X",0:59, sep = ""))
mean.age.sus = data.frame(matrix(0, length(All.countries), length(years) + 1))
colnames(mean.age.sus) = c("", paste(years))
mean.age.sus[,1] = All.countries

count = 1
for(i in 1 : length(All.countries)){
    for(j in 1 : length(years)){
        list[tot.susc,tot.susc.disrupted,
             pred,ages, rel.foi,
             prop.vacc, prop.vacc.disrupted,
             prop.nat.imm, coverage, years.sia,
             age.range, ages.vacc, coverage.sia,
             mat.protect] = getLexisVaccPopStructSpecifyYear(country = All.countries[i],
                                                             barchart.susc = T,
                                                             proportion.pop=F,
                                                             year = years[j], max.x = 3000000,
                                                             output.plot = F)
        tot.imm <- mat.protect+(pred-mat.protect)*prop.vacc + (pred-mat.protect)*(1-prop.vacc)*(prop.nat.imm)
        
        denom <- rep(1,length(pred))
        tot.susc <- pred-tot.imm
        
        k = which(mean.age.sus[,1] == All.countries[i])
        l = which(colnames(mean.age.sus) == years[j])
        mean.age.sus[k, l] = sum(tot.susc * 0:59)/sum(tot.susc)
        
        number.of.individuals[count, ] = c(All.countries[i], years[j], round(as.numeric(pred)))
        number.of.susceptibles[count, ] = c(All.countries[i], years[j], round(as.numeric(tot.susc)))
        count = count + 1
    }
    print(paste(All.countries[i], "done"))
}

for(i in 0:59){
    number.of.susceptibles[ , paste("X", i, sep = "")] = as.numeric(number.of.susceptibles[ , paste("X", i, sep = "")])
    number.of.individuals[ , paste("X", i, sep = "")] = as.numeric(number.of.individuals[ , paste("X", i, sep = "")])
}
write.csv(number.of.susceptibles, "data/est_sus_by_year.csv")
write.csv(number.of.individuals, "data/est_age_dist_by_year.csv")
write.csv(mean.age.sus, "data/mean_age_sus.csv", row.names=F)
```

For ease, we can simply read in the already estimated proportion susceptible by age, year, and country.

```{r, echo = include.code, include=F}
##' import the estimated susceptibles for each country and year.
estimated.susceptibles.by.year = read.csv("data/est_sus_by_year.csv", stringsAsFactors = F)
estimated.age.dist.by.year = read.csv("data/est_age_dist_by_year.csv", stringsAsFactors = F)
```

We can then use the dataset of the number of susceptibles by country, year, and age, to link each country and year to the canonical path and determine the estimated total proportion of susceptibles, and age-specific proportion susceptibles at each canonical path point. 

```{r, echo = include.code, include=F}
estimated.susceptibles.by.year = estimated.susceptibles.by.year[, -(1)]
estimated.age.dist.by.year = estimated.age.dist.by.year[, -(1)]
##' run code to generate the number of susceptibles by age by canonical path point
list[dist.by.age, canonical.path, prop.sus, d1, prop.sus.by.age] = 
    plots.for.sus.dist.by.canonical.path (d1 = canonical.path.data, 
                                          d2 = estimated.susceptibles.by.year, 
                                          d3 = estimated.age.dist.by.year,
                                          rep.cases = 1,
                                          regions,
                                          make.inc.cv.scale.same = 1,
                                          sqrt.inc = F,
                                          connect.canonical.path.to.zero = 0,
                                          log.incidence = 1,
                                          make.figure.plot = F)
cols.1 <- colorRampPalette(c("red", "white", "blue"))(length(canonical.path$x))
```

Here we plot the proportion of susceptible individuals by canonical path point (Fig. 2B in the paper). The horizontal dashed lines display the critical level of immunity if the basic reproduction number of measles is 15 or 20 (critical level = 1-(1 / basic reproductive number)).

```{r, echo = include.code, fig.height = 4, fig.width = 6}

    plot( prop.sus[, 2]*100, pch = 21, cex = 2,
          xlab = '', ylab= '% susceptible', bty="n",
          xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black')
    smoo <- with(prop.sus[!is.na(prop.sus$y),],smooth.spline(x,y*100, df=4))
    result <- with(prop.sus, predict(smoo,x[is.na(y)]))
    prop.sus[is.na(prop.sus$y),] <- result
    lines(smoo, col='black', lwd=2)
    abline(h = 5, lwd = 2, lty = 2)
    abline(h = ((1/15)*100), lwd = 2, lty = 2)
    
```

We plot the age distribution of susceptibles by canonical path point 

```{r, echo = F}

boxplot(age ~ point, data = dist.by.age, col = cols.1, outline = F, bty = "n",
        ylim = c(0, 60), xaxt = "n", frame.plot = F, xlab = "position on canonical path")

```

We also have data on the mean age of measles cases in multiple countries from 2000-2016. This data has increasing numbers of data as time goes on.

```{r, echo = include.code, fig.height = 5, fig.width = 8}

##' import the data on mean age of measles cases 
mean.measles.age <- read.csv("data/mean_age_meas.csv", stringsAsFactors = F)

##' melt the mean age of measles data 
melt.mean.measles.age = melt(mean.measles.age, id.vars = c("ISO3", "WHO_REGION", "Country")) %>%
    na.omit

##' remove the X from the year data
melt.mean.measles.age$variable = substr(melt.mean.measles.age$variable, 2, 5) %>% as.numeric

##' rename the columns 
colnames(melt.mean.measles.age) = c("ISO3", "WHO_REGION", "country", "year", "value")

##' remove data for countries which are not included in the canonical path data
k = which(melt.mean.measles.age$country %in% c("occupied Palestinian territory", "#N/A"))
melt.mean.measles.age = melt.mean.measles.age[-(k), ]

##' add a column which will contain the canonical path location of each country and year
melt.mean.measles.age$closest = NA

##' find the canonical path location for each country and year in the mean measles age data
for(i in 1 : nrow(melt.mean.measles.age)){
    k = which(d1$Country == melt.mean.measles.age$country[i] &
                                                     d1$Year == melt.mean.measles.age$year[i])
    if(length(k) > 0){
        melt.mean.measles.age$closest[i] = d1$closest[k]
    }
}

##' find all the locations on the canonical path that the data on the mean age of measles are on
all.closest = unique(melt.mean.measles.age$closest)

##' which locations on the canonical path are not included in this data
missing = setdiff(1:max(all.closest, na.rm = T), all.closest)

##' generate a data set called X, that has the same dimensions as the melted mean measles data
X = data.frame(matrix(NA, length(missing),6))

##' give this data set the same column names as the melted data
colnames(X) = colnames(melt.mean.measles.age)

##' assign the missing canonical path points to the data set X, along with a value outside of the range of the possible mean age of the measles cases
X$closest = missing
X$value = -100

##' combine the melted measles data and the missing data so that we can make a boxplot of the mean age of measles cases
melt.mean.measles.age = rbind(melt.mean.measles.age, X)
```

Again, these data can be linked to canonical path point. Here we make a boxplot of the estimated distribution of ages against the mean age of measles cases, to see how they compare (Fig. 3B). The estimates are hollow-wider boxes, and the case data is filled narrow purple boxes. 

```{r, echo = include.code, fig.height = 6, fig.width = 9}

boxplot(age ~ point, data = dist.by.age, outline = F, bty = "n",
        ylim = c(0, 60), xaxt = "n", frame.plot = F, xlab = "position on canonical path",
        cex.axis = 1.5, cex.lab = 1.5)

boxplot(value/12 ~ closest, 
        data = melt.mean.measles.age, boxlwd=0.01, whisklwd=2, staplelwd=2.5,
        ylim = c(0,700/12), border = rgb(red = 10/255, green = 10/255, blue = 100/255, alpha = 0.55),
        col = rgb(red = 1/255, green = 10/255, blue = 100/255, alpha = 0.4),
        ylab ="age", xaxt = "n", frame.plot = F,
        pars = list(boxwex = 0.38, staplewex = 0.5, outwex = 0),
        cex.axis = 1.5, cex.lab = 1.5, outline = F, add= T)

axis(1, at = c(1,length(unique(dist.by.age$point))),labels = c("",""))


```


The figures below show the estimated proportion of susceptibles who are under 5 (Fig. 2C), and the age at which an SIA would have to go up to in order to cover 90% of all susceptibles (Fig. 2D).

```{r, echo = include.code, include = F}

prop.sus.by.age <- prop.sus.by.age[,-1]
a = 1:59
n = 5
min = c(seq.int(from=1, to=length(a), by=n))
max = c((min-1)[2:length(min)], length(a))
prop.sus.by.age.group = apply(prop.sus.by.age, 1, function(x) sapply(1:length(min), function(i) mean(x[min[i]:max[i]])))
prop.sus.by.age.group <- rbind(prop.sus.by.age.group, prop.sus[, 2]) #add in prop.sus for ALL ages to the last row (same as Fig. 2A)

dist.by.age.rep = dist.by.age
points = unique(dist.by.age.rep$point)
perc.by.age.sia.rep = data.frame(matrix(NA, max(points), 5))
perc.by.age.sia.rep[,1] = 1:max(points)
colnames(perc.by.age.sia.rep) = c("pos", "perc.to.5", "perc.to.10", "perc.to.15", "age.for.90.perc")

for(i in 1 : length(points)){
    p = dist.by.age.rep[which(dist.by.age.rep$point == points[i]), ]
    if(nrow(p) > 1){ #xxamy this if statement was added
    p1 = p %>% filter(age <= 5)
    p2 = p %>% filter(age <= 10)
    p3 = p %>% filter(age <= 15)
    p4 = p[order(p$age), ]
    
    perc.by.age.sia.rep[points[i], ] = c(points[i], 
                             nrow(p1)*100/nrow(p),
                             nrow(p2)*100/nrow(p),
                             nrow(p3)*100/nrow(p),
                             p4[floor(nrow(p)*0.9), 2] )
    }
}


##'  adjust positions of the percentage age to sia age to go from 1 to
##' the number of points that have countries assigned to them
perc.by.age.sia.rep$pos = 1:nrow(perc.by.age.sia.rep)
#plot(perc.by.age.sia.rep$pos, perc.by.age.sia.rep$age.for.90.perc)
#k=unique(dist.by.age$point)
#k = k[order(k)]

```


```{r, echo = include.code, fig.height = 6, fig.width = 9}

levelplot(t(as.matrix(prop.sus.by.age.group)), ylab="age (years)", 
          xlab="position on canonical path", xaxt = "n",
          col.regions=colorRampPalette(brewer.pal(9,"Greys")),
          scales=list(y=list(at=1:13, labels=c("<5","5-9","10-14","15-19","20-24","25-29","30-34","35-39","40-44","45-49",
                                                                                            "50-54","55-59", "all"))))

plot( perc.by.age.sia.rep$pos, perc.by.age.sia.rep$perc.to.5, pch = 21, cex = 2,
      xlab = '', ylab= '% of susceptibles 5 or under', bty="n",
      xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black',ylim = c(10,60))
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$perc.to.5),], smooth.spline(pos,perc.to.5))
result <- with(perc.by.age.sia.rep, predict(smoo,pos[is.na(perc.by.age.sia.rep$perc.to.5)]))
perc.by.age.sia.rep[is.na(perc.by.age.sia.rep$perc.to.5),2] <- result$y
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$perc.to.5),], smooth.spline(pos,perc.to.5), cv = T)
lines(smoo, col='black', lwd=2)
abline(h = 50, lwd = 2, lty = 2)
abline(h = 2/30, lwd = 2, lty = 2)


plot(perc.by.age.sia.rep$pos, perc.by.age.sia.rep$age.for.90.perc, pch = 21, cex = 2,
     xlab = '', ylab= 'oldest SIA age to reach 90% of susceptibles', bty="n",ylim = c(15,42),
     xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black')
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$age.for.90.perc),], smooth.spline(pos,age.for.90.perc, df=6))
result <- with(perc.by.age.sia.rep, predict(smoo,pos[is.na(perc.by.age.sia.rep$age.for.90.perc)]))
perc.by.age.sia.rep[is.na(perc.by.age.sia.rep$age.for.90.perc),5] <- result$y
lines(smoo, col='black', lwd=2)
```


# Supplementary 

Here we reproduce the figures seen in the supplement of the paper.  The following codes reproduces Fig. S1. 

```{r, echo = F}

list[subset.pop.by.year, subset.vaccination, subset.birth.rates, subset.data] = get.data.for.animation(regions)
nigeria.pop = subset.pop.by.year %>% filter(Country.Name== "Nigeria") %>% data.frame 
j = which(colnames(nigeria.pop) %in%paste("X", 1981:2017, sep = ""))
nigeria.pop = nigeria.pop[j] %>% t %>% data.frame
colnames(nigeria.pop) = "pop"
nigeria.pop$pop = nigeria.pop$pop %>% as.character %>% as.numeric

cases.by.country.by.year = read.csv("data/Measles_cases_by_year.csv", stringsAsFactors = FALSE)

nigeria.cases = cases.by.country.by.year %>%
    filter(Cname == "Nigeria") 

j = which(colnames(nigeria.cases) %in% paste("X", 1981:2017, sep = ""))

nigeria.cases = nigeria.cases[rev(j)] %>% as.character %>% as.numeric %>% data.frame 
nigeria.cases = cbind(seq(1981, 2017), nigeria.cases)
colnames(nigeria.cases) = c("year", "cases")
nigeria.inc = data.frame(cbind(1981:2017, 100000 * nigeria.cases$cases / nigeria.pop$pop))
colnames(nigeria.inc) = c("year", "inc")

ggplot(nigeria.inc, aes(x = year, y = inc)) + geom_point(cex = 3, col = 'grey') +
     geom_line() + theme_bw() + ylab("incidence per 100,000")

```

```{r, echo = F}

year.shift.inc = 2
cutoff = 50
w2 = matrix(0, nrow(nigeria.inc), nrow(nigeria.inc))
x2 = 1981:2017
for (i in 10 : length(x2)){
    ##' set up the gaussian weights for averaging
    
    w.input = x2 - x2[i] + year.shift.inc
    w2[i, ] = output.weights.gaussian.with.cutoff(w.input, st.dev=3, cutoff)
    
    ##' make sure that the weights add up to 1 for each of the specific weightings
    j = which(w.input == (year.shift.inc + 1))
    if(length(j) > 0){
        w2[i,j : length(w2[i,])] = 0
        w2[i, ] = w2[i, ] / sum(w2[i, ])
    }
    if(i == length(x2)){
        w2[i, ] = w2[i, ] / sum(w2[i, ])
    }
    
}

k = cbind(w2[10,], 1981:2017, "1990")
k = rbind(k, cbind(w2[30, ],1981:2017, "2010"))
k = data.frame(k)
colnames(k) = c("weight", "year", "w")
k$weight[which(k$weight == 0)] = NA
k$weight = as.numeric(as.character(k$weight))
k$year = as.numeric(as.character(k$year))


ggplot(k, aes(x = year, y = weight, col = factor(w))) + geom_point(cex = 3) +
    geom_line() +
    theme_bw() + theme(legend.position="none") +
    scale_colour_manual(values=wes_palette("Darjeeling1")[c(1,5)]) #potentially Darjeeling without the 1 pending R version


```


```{r, echo = F}
weighted.mean.inc = data.frame(cbind(1981:2017, NA, "A"))
colnames(weighted.mean.inc) = c("year", "mean.inc", "type")
weighted.mean.inc$mean.inc = as.numeric(as.character(weighted.mean.inc$mean.inc))
weighted.mean.inc$type = as.character(weighted.mean.inc$type)
weighted.mean.inc$year = as.numeric(as.character(weighted.mean.inc$year))
for(i in 1 : nrow(w2)){
    weighted.mean.inc$mean.inc[i] = sum(w2[i, ] * nigeria.inc$inc)
}
weighted.mean.inc$type[which(weighted.mean.inc$year == 1990)] = "B"
weighted.mean.inc$type[which(weighted.mean.inc$year == 2010)] = "C"
weighted.mean.inc$type = as.factor(weighted.mean.inc$type)
weighted.mean.inc = filter(weighted.mean.inc, mean.inc > 0)


p <- ggplot(weighted.mean.inc, aes(x = year, y = mean.inc))
p + geom_point(cex = 3, aes(col = factor(type))) +
    geom_line() +
    theme_bw() + theme(legend.position="none") +
        scale_color_manual(values = c("grey",wes_palette("Darjeeling1")[c(1,5)]) ) + 
        ylab("mean incidence per 100,000") + xlim(c(1990, 2017))


```

The following codes reproduces Fig. S2. 

```{r,echo = F}

wt.cv <- function(x, wt){
    return(wt.sd(x, wt)/ wt.mean(x, wt))
}
cases.by.country.by.year = subset.data
bolivia.cases = filter(cases.by.country.by.year, Country == "Bolivia")
bolivia.cases = bolivia.cases[paste("X", 1981:2017, sep = "")]


bolivia.cv = matrix(0, 37, 2)
for(i in 1 : 37){
    bolivia.cv[i, 1] = wt.cv(as.numeric(as.character(bolivia.cases)), w2[i, ])
    if(i > 9){
        if(mean(as.numeric(as.character(bolivia.cases[paste("X", (i+1980-9):(i+1989-9),sep = "")])), na.rm = T) >0){
            bolivia.cv[i, 2] = sd(bolivia.cases[paste("X", (i+1980-9):(i+1989-9), sep = "")], na.rm = T)/
                mean(as.numeric(as.character(bolivia.cases[paste("X", (i+1980-9):(i+1989-9),sep = "")])), na.rm = T)
        }
    }
}



weighted.cv = data.frame(cbind(1990:2017, bolivia.cv[10:37, 1]))
colnames(weighted.cv) = c("year", "cv")
unweighted.cv = data.frame(cbind(1990:2017, bolivia.cv[10:37, 2]))
colnames(unweighted.cv) = c("year", "cv")
bolivia.cases = data.frame(cbind(1981:2017, as.numeric(as.character(bolivia.cases))))
colnames(bolivia.cases)  = c("year", "cases")


##' plot cases, weighted cv and unweighted cv for bolivia

bol.cases = ggplot(bolivia.cases, aes(x = year, y = cases)) + geom_point(cex = 3, col = 'grey') +
    geom_line() + theme_classic() 

unweight.cv = ggplot(unweighted.cv, aes(x = year, y = cv)) + geom_point(cex = 3, col = 'grey') +
    geom_line() + theme_bw() 

weight.cv = ggplot(weighted.cv, aes(x = year, y = cv)) + geom_point(cex = 3, col = 'grey') +
    geom_line() + theme_bw() 

##' make plot
multiplot(bol.cases, weight.cv, unweight.cv, cols = 1)




```

```{r, echo = F}
   window.length = 10
   gaussian.st.dev = 3
   cutoff = 50
   year.shift.inc = 2
   list[subset.pop.by.year, subset.vaccination, subset.birth.rates, subset.data] = get.data.for.animation(regions)
  
  x = seq(1980, 2017) 
  
  ##' interpolate the datasets to have entries for all points in time once the interpolation is done.
  list[interp.subset.data, interp.subset.vacc, interp.subset.br, interp.subset.pop] = interp.datasets(subset.data, 
                                                                                                      subset.vaccination, 
                                                                                                      subset.birth.rates, 
                                                                                                      subset.pop.by.year,
                                                                                                      x,
                                                                                                      x)
  
  ##' output matrices the correct size for our animation
  list[mean.cases, coeff.var.cases, incidence.per.1000, mean.br, mean.vac] = 
    prepare.matrices.for.animation(interp.subset.data, subset.data)
  
  ##' number of unique years that we will have data for. The longer the window, the less unique years of data.
  num.windows = length(x) - window.length + 1
  
  ##' first year of data
  year = 1980
  
  ##' setting up the datasets
  coeff.var = matrix(0, length(subset.data[ , 1]), num.windows)
  incidence.per.1000 = matrix(0, length(subset.data[ , 1]), num.windows)
  mean.br = matrix(0, length(subset.data[ , 1]), num.windows)
  mean.vac = matrix(0, length(subset.data[ , 1]), num.windows)
  
  ##' do calculations that calculate the coefficient of variation, incidence per 100, mean birth rate and
  ##' mean vaccination rate over periods of length given by the window length.
  for ( j in 1 : num.windows){
    for ( i in 1 : length(subset.data[ , 1])){
      coeff.var[i, j]  =  sd(interp.subset.data[i, paste(seq(year, year + window.length - 1))], na.rm = TRUE) /  
        mean(as.numeric(interp.subset.data[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE)
      if(is.na( mean(as.numeric(interp.subset.data[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE)) == FALSE ){
        if( mean(as.numeric(interp.subset.data[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE) == 0) {
          coeff.var[i, j]  =  0
        } 
      }
      incidence.per.1000[i, j]  =  sum(as.numeric(interp.subset.data[i,  paste(seq(year, year + window.length - 1))]) / 
                                         as.numeric(interp.subset.pop[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE) * 1000
      if(length(which(is.na(as.numeric(interp.subset.br[i, paste(seq(year, year + window.length - 1))])))) < window.length){
        mean.br[i, j]  =  mean(as.numeric(interp.subset.br[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE)
      }
      if(length(which(is.na(as.numeric(interp.subset.vacc[i, paste(seq(year, year + window.length - 1))])))) < window.length){
        mean.vac[i, j]  =  mean(as.numeric(interp.subset.vacc[i, paste(seq(year, year + window.length - 1))]), na.rm = TRUE)
      }
    }
    year = year + 1
  }
  
  incidence.per.1000.each.year = matrix(0, nrow(subset.data), length(seq(1980, 2017)))
  for(i in 1 : nrow(subset.data)){
    incidence.per.1000.each.year[i, ] = 1000 * as.numeric(interp.subset.data[i,  paste(seq(1980, 2017))]) / 
      as.numeric(interp.subset.pop[i, paste(seq(1980, 2017))])
    
  }
  ##' for calculating the weighted coefficient of variation, we need to take the weighted
    ##' mean of locally calculated coefficient of variations. The following function will
    ##' generate the matrix of weights used to calculate this weighted average.
    ##' the weights are gaussian, centred on a specific year, with
    ##' specified number of years for the standard deviation

    w1 = generate.cv.weights(coeff.var,
                             gaussian.st.dev,
                             cutoff)

    ##' for incidence, birth rate and vaccination rate, we can weight slightly differently
    ##' as there is no issue with the weighting of yearly calculated values.
    ##' the following function produces the weights used for weighting these variables

    w2 = generate.other.weights(d = incidence.per.1000.each.year,
                                window.length,
                                gaussian.st.dev,
                                cutoff, year.shift.inc)

  
  ##' make a set of matrices that are the same size as the matrices containing the data.
  coeff.2 = coeff.var
  incidence.2 = incidence.per.1000
  mbr2 = mean.br
  mvacc2 = mean.vac
  for(i in 1 : length(coeff.var[1, ])){
    for(j in 1 : length(coeff.var[, 1])){
      ##' make the entries of these newly created matrices to be the weighted averages of the originally calculated datasets
      coeff.2[j, i] = sum(coeff.var[j, ] * w1[i, ], na.rm = T)
      incidence.2[j, i] = sum(incidence.per.1000.each.year[j, ] * w2[i, ], na.rm = T)
      mbr2[j, i] =  sum(mean.br[j, i] * w2[i, ], na.rm = T)
      mvacc2[j, i] = sum(mean.vac[j, i]* w2[i, ], na.rm = T)
      
      ##' Should we do weighted average of birth rate and vaccination rate?
      ##' If so uncomment the next two lines
      
       #mbr2[j, i] = sum(mean.br[j, ] * w1[i, ], na.rm = T)
       #mvacc2[j, i] = sum(mean.vac[j, i] * w1[i, ], na.rm = T)
    }
  }
  
  ##' set the original data to be equal to the weighted data
  coeff.var.cases = coeff.2
  incidence.per.1000 = incidence.2
  mean.br = mbr2
  mean.vac = mvacc2
  
  
  
```


```{r, echo = F}

  ##' collect cv data for Nigeria, unweighted
  
    coeff.var = cbind(cbind(subset.data$Country, subset.data$WHO_REGION), coeff.var)
    coeff.var = data.frame(coeff.var)
    colnames(coeff.var) = c("Country", "WHO_REGION", paste("X", 1989:2017, sep = ""))
    nigeria.cv = filter(coeff.var, Country == "Nigeria")
    nigeria.cv[paste("X", 1989:2017, sep = "")] = 
    as.numeric(as.character(as.matrix(nigeria.cv[paste("X", 1989:2017, sep = "")])))

    cvs = as.matrix(as.numeric(as.character(nigeria.cv[paste("X", 1989:2017, sep = "")])))
    nigeria.cv = data.frame(cbind(1989:2017, cvs))
    colnames(nigeria.cv) = c("year", "cv")
    nigeria.cv = filter(nigeria.cv, year > 1989)
    
    
    ##' plot the Nigeria unweighted cv data
    ggplot(nigeria.cv, aes(x = year, y = cv)) + geom_point(cex = 3, col = 'grey') +
    geom_line() + theme_bw() + ylab("coefficient of variation")
    
    
    
    ##' collect the weighted cv data for Nigeria, 
    coeff.var.cases = cbind(cbind(subset.data$Country, subset.data$WHO_REGION), coeff.var.cases)
    coeff.var.cases = data.frame(coeff.var.cases)
    colnames(coeff.var.cases) = c("Country", "WHO_REGION", paste("X", 1989:2017, sep = ""))
    nigeria.cv = filter(coeff.var.cases, Country == "Nigeria")
    nigeria.cv[paste("X", 1989:2017, sep = "")] = 
    as.numeric(as.character(as.matrix(nigeria.cv[paste("X", 1989:2017, sep = "")])))

    cvs = as.matrix(as.numeric(as.character(nigeria.cv[paste("X", 1989:2017, sep = "")])))
    nigeria.cv = data.frame(cbind(1989:2017, cvs))
    colnames(nigeria.cv) = c("year", "cv")
    nigeria.cv = filter(nigeria.cv, year > 1989)

    ##' plot the Nigeria weighted cv data
    ggplot(nigeria.cv, aes(x = year, y = cv)) + geom_point(cex = 3, col = 'grey') +
    geom_line() + theme_bw() + ylab("mean coefficient of variation")
  

```


Figure S4 of the supplement has the location of countries in the WHO Africa and Americas Regions in incidence-space in 1990 and 2014 post scaling of incidence and CV. This is re-created here.

```{r, echo = include.code, include = F}

d = canonical.path.data 

years = 1990:2017

d = d %>% filter(., Year %in% years, WHO_REGION %in% regions, Incidence > 0,
                 Country != "")
j = which(d$Year < 1995 & d$Coefficient.of.Variation == 0)
if(length(j) > 0){
    d = d[-(j), ]
}



d$Incidence = log(d$Incidence+0.000001)

##' input d with non-square rooted incidence values. Then we take the square root of the 
##' incidence to match the path calculation


d$Incidence = scl(d$Incidence)
d$Coefficient.of.Variation = scl(d$Coefficient.of.Variation)

logged.scaled.path = awesome.mega.figure.scaled.dashed.arrow (anim.data = d, years = c(1990, 2017), 
                                     regions = c("AFR",  "AMR"), shapes = c(1,2,16,17),
                                     countries.of.interest = c("Malawi", "United States", 
                                                               "Brazil", "Argentina",
                                                               "Congo, Democratic Republic of the",
                                                               "Zambia",
                                                               "Uruguay", "Tanzania"),
                                     colors = c( "#367526", "#7a40a0"), text.size = 4,xint=1.07, yint = 0.25,
                                     line.color = 'grey1', arrow.size = 2,
                                     breaks = c(1,5,10,15,20,40,60))


```


```{r, fig.height = 10, fig.width = 10, echo = include.code}
logged.scaled.path
```

Figure S5 shows the trajectory of the Americas and Africa when we take the median of these regions paths rather than the mean.

```{r, echo = F, include = F}

taxonomy.fig.median = incidence.space.fig.median.dashed.arrow(anim.data = canonical.path.data, years = c(1990, 2017), 
                                                 regions = c("AFR",  "AMR"), shapes = c(1,2,16,17),
                                                 countries.of.interest = c("Malawi", "United States", 
                                                                           "Brazil", "Argentina",
                                                                           "Congo, Democratic Republic of the",
                                                                           "Zambia",
                                                                           "Uruguay", "Tanzania"),
                                                 colors = c( "#367526", "#7a40a0"), text.size = 4,xint=-1.07, yint = 0.25,
                                                 line.color = 'grey1', arrow.size = 2,
                                                 breaks = c(1,5,10,15,20,40,60))


```



```{r, echo = F, fig.height = 10, fig.width = 10}
taxonomy.fig.median

```


We used an established discrete time age-structured mathematical model, introduced in @metcalf2012a and @metcalf2012b to simulate measles transmission dynamics for each country in the WHO Americas and Africa Regions.  We used the same Gaussian weights as in the empirical analysis to create an incidence-space for each country over time, and compared this to estimates of measles incidence per @statespace and @simons2012.

```{r, echo=F}
country.codes <- read.csv("./data/country_codes2.csv")
country.names.amro <- country.codes$Report_country_name[country.codes$Region_Code=="AMRO"]
country.names.afro <- country.codes$Report_country_name[country.codes$Region_Code=="AFRO"]

#need population size 1981 to 2017 per AMRO and AFRO country 
pop.amro <- matrix(NA, length(country.names.amro), 37) #1981 to 2017
pop.afro <- matrix(NA, length(country.names.afro), 37) #1981 to 2017
for (c in 1:length(country.names.amro)){
  country <- country.names.amro[c]
  cc <- as.numeric(country.codes$uncode[country.codes$Report_country_name==country])
  data(pop) #from wpp2015 package
  data(popproj) #for population for 2016 and 2017
  pop.total.1950.2020.by5 <-  as.numeric(cbind(pop[pop$country_code==cc,3:ncol(pop)], popproj[popproj$country_code==cc,3]))
  f <- smooth.spline(seq(1950,2020,5), pop.total.1950.2020.by5)
  pop.total.1981.2017 <- predict(f, seq(1981,2017,1))$y*1000
  pop.amro[c,] <- pop.total.1981.2017
}
for (c in 1:length(country.names.afro)){
  country <- country.names.afro[c]
  cc <- as.numeric(country.codes$uncode[country.codes$Report_country_name==country])
  data(pop) #from wpp2015 package
  data(popproj) #for population for 2016 and 2017
  pop.total.1950.2020.by5 <-  as.numeric(cbind(pop[pop$country_code==cc,3:ncol(pop)], popproj[popproj$country_code==cc,3]))
  f <- smooth.spline(seq(1950,2020,5), pop.total.1950.2020.by5)
  pop.total.1981.2017 <- predict(f, seq(1981,2017,1))$y*1000
  pop.afro[c,] <- pop.total.1981.2017
}

##' sort countries (names, iso3, and uncodes) by population size
amro.order <- match(rev(sort(pop.amro[,30])), pop.amro[,30])
afro.order <- match(rev(sort(pop.afro[,30])), pop.afro[,30])
pop.amro <- pop.amro[amro.order,]
uncodes.amro <- country.codes$uncode[country.codes$Region_Code=="AMRO"][amro.order]
country.names.amro <- country.codes$Report_country_name[country.codes$Region_Code=="AMRO"][amro.order]
iso3.amro <- country.codes$ISO3_code[country.codes$Region_Code=="AMRO"][amro.order]
pop.afro <- pop.afro[afro.order,]
uncodes.afro <- country.codes$uncode[country.codes$Region_Code=="AFRO"][afro.order]
country.names.afro <- country.codes$Report_country_name[country.codes$Region_Code=="AFRO"][afro.order]
iso3.afro <- country.codes$ISO3_code[country.codes$Region_Code=="AFRO"][afro.order]

##' download simulated data
incs.amro <- cvs.amro <- matrix(NA, length(uncodes.amro)*100, 28)
for (c in 1:length(uncodes.amro)){
  index <- min(which(is.na(incs.amro)))
  incs <- read.csv(paste("./sim.data/incs",  uncodes.amro[c], ".csv", sep="_"))[1:28,-1] #1990 through 2017
  incs.amro[index:(index+99),] <- t(incs)
  cvs <- read.csv(paste("./sim.data/cvs",  uncodes.amro[c], ".csv", sep="_"))[1:28,-1] #1990 through 2017
  cvs.amro[index:(index+99),] <- t(cvs)
}
incs.afro <- cvs.afro <- matrix(NA, length(uncodes.afro)*100, 28)
for (c in 1:length(uncodes.afro)){
  index <- min(which(is.na(incs.afro)))
  incs <- read.csv(paste("./sim.data/incs",  uncodes.afro[c], ".csv", sep="_"))[1:28,-1] #1990 through 2017
  incs.afro[index:(index+99),] <- t(incs)
  cvs <- read.csv(paste("./sim.data/cvs",  uncodes.afro[c], ".csv", sep="_"))[1:28,-1] #1990 through 2017
  cvs.afro[index:(index+99),] <- t(cvs)
}

cvs <- rbind(cvs.amro, cvs.afro)
incs <- rbind(incs.amro, incs.afro)

##' download estimated data for comparison - incidence per 100,000 per the state-space model
ss <- read.csv("data/State_space_cases_new.csv")
ss.inc.amro <- matrix(NA, length(uncodes.amro), ncol(ss)-1)
for (c in 1:length(uncodes.amro)){
  ss.cases <- as.numeric(ss[which(as.character(ss$iso)==as.character(iso3.amro[c])),2:ncol(ss)])
  ss.inc.amro[c,] <- ss.cases/pop.amro[c,]
}
ss.inc.amro <- as.data.frame(cbind(uncodes.amro, ss.inc.amro))
ss.inc.afro <- matrix(NA, length(uncodes.afro), ncol(ss)-1)
for (c in 1:length(uncodes.afro)){
  ss.cases <- as.numeric(ss[which(as.character(ss$iso)==as.character(iso3.afro[c])),2:ncol(ss)])
  ss.inc.afro[c,] <- ss.cases/pop.afro[c,]
}
ss.inc.afro <- as.data.frame(cbind(uncodes.afro, ss.inc.afro))

##' get gausian weighted incs and cv of state-space estimates 
list[incs.amro.ss, Am.cv.ss] <- return.cv.inc.from.ss(ss.inc.amro)
list[incs.afro.ss, Af.cv.ss] <- return.cv.inc.from.ss(ss.inc.afro)

##' square root per 100,000 people, this is the same scale as Figure 1A
incs.amro.ss <- sqrt(incs.amro.ss*100000)
incs.afro.ss <- sqrt(incs.afro.ss*100000)
incs.amro <- sqrt(incs.amro*100000)
incs.afro <- sqrt(incs.afro*100000)

```

We plotted AFRO countries in incidence-space (Fig. S6-S11).

```{r, echo = include.code, fig.height = 4, fig.width = 4}

##' make colour palette
colfunc = colorRampPalette(c("green", "white", "orange"))

##' plot AFRO
par(bty="l", mar=c(4, 4, 1, 2) + 0.1)
ylim = c(0, as.numeric(max(incs.afro), na.rm = T))
xlim = c(0,4)
for (c in 1:length(uncodes.afro)){
   plot(0, bg = colfunc(28), col = 'black', pch = '', bty="n", ylab="incidence per 100,000", xlab="coefficent of variation", yaxt="n",
         xlim = xlim, ylim = ylim, mgp=c(2.5, 1.1, 0))
    axis(2, sqrt(c(1,100,500,1000,2000,4000)), labels=F)
    text(y=sqrt(c(1,100,500,1000,2000,4000)), par("usr")[1] - 0.05, 
         labels = c(1,100,500,1000,2000,4000), srt = 45, pos = 2, xpd = TRUE)
    title(country.names.afro[c], line=0)
    for(i in 1:100){
      points(cvs.afro[((100*c)-(100-i)), 2:ncol(cvs.afro)],
             incs.afro[((100*c)-(100-i)), 2:ncol(incs.afro)], 
             bg = colfunc(28), col = 'black', pch = 21)
    }
    lines(colMeans(cvs.afro[(100*c-99):(100*c), 2:ncol(cvs.afro)]), 
          colMeans(incs.afro[(100*c-99):(100*c), 2:ncol(incs.afro)]), col = 'black')
    points(Af.cv.ss[c,], incs.afro.ss[c,], pch=3, bg = colfunc(28))
    lines(Af.cv.ss[c,], incs.afro.ss[c,], col="grey")
    LEGEND(1.8,sqrt(4000), c("simulated", "observed"), pch=c(21,3), line.col=c("black","grey"), pt.col="black",lty=1)
}

```

We plotted AMRO countries in incidence-space (Fig. S12-S15).

```{r, echo = include.code, fig.height = 4, fig.width = 4}
##' make colour palette
colfunc = colorRampPalette(c("green", "white", "orange"))

par(bty="l", mar=c(4, 4, 1, 2) + 0.1)
ylim = c(0, as.numeric(max(incs.amro), na.rm = T))
xlim = c(0,4)
for (c in 1:length(uncodes.amro)){
  plot(0, bg = colfunc(28), col = 'black', pch = '', bty="n", ylab="incidence per 100,000", xlab="coefficent of variation", yaxt="n",
         xlim = xlim, ylim = ylim, mgp=c(2.5, 1.1, 0))
    axis(2, sqrt(c(1,100,500,1000,2000)), labels=F)
    text(y=sqrt(c(1,100,500,1000,2000)), par("usr")[1] - 0.05, 
         labels = c(1,100,500,1000,2000), srt = 45, pos = 2, xpd = TRUE)
    title(country.names.amro[c], line=-1.5)
    for(i in 1:100){
      points(cvs.amro[((100*c)-(100-i)), 2:ncol(cvs.amro)],
             incs.amro[((100*c)-(100-i)), 2:ncol(incs.amro)], 
             bg = colfunc(28), col = 'black', pch = 21)
    }
    lines(colMeans(cvs.amro[(100*c-99):(100*c), 2:ncol(cvs.amro)]), 
          colMeans(incs.amro[(100*c-99):(100*c), 2:ncol(incs.amro)]), col = 'black')
    points(Am.cv.ss[c,], incs.amro.ss[c,], pch=3, bg = colfunc(28))
    lines(Am.cv.ss[c,], incs.amro.ss[c,], col="grey")
    LEGEND(1.8,sqrt(2000), c("simulated", "observed"), pch=c(21,3), line.col=c("black","grey"), pt.col="black",lty=1)
}

```

The estimated case data per @statespace and @simons2012 can also be used to plot a figure similar to figure 1 of the paper, demonstrating the path of the Americas and Africa through incidence space. This is seen below and is Fig. S16. The only difference is that Fig. 1A uses reported cases, and Fig. S16 uses cases corrected for under-reporting.

```{r, echo = include.code}
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")

state.space.data = 
    generate.state.space.data(window.length = 10, regions, 
                                 gaussian.st.dev=3, cutoff = 50, 
                                 interp.resolution = 20,
                                 year.shift.inc = 2)


mean.age.sus = read.csv(file = "data/mean_age_sus.csv", stringsAsFactors = F)
rownames(mean.age.sus) = mean.age.sus$X
mean.age.sus = mean.age.sus[, -(1)]
colnames(mean.age.sus) = gsub("X", "", colnames(mean.age.sus))


list[state.space.data, Af.data.state.space, Amr.data.state.space, Rest.data.state.space] = 
    prepare.anim.data.for.analysis(input.data = state.space.data,
                                   mean.age.sus = mean.age.sus)
```

```{r, echo = include.code}

state.space.fig = incidence.space.fig.dashed.arrow(anim.data = state.space.data, years = c(1990, 2017), 
                                      state.space = 1,
                                     regions = c("AFR",  "AMR"), shapes = c(1,2,16,17),
                                     countries.of.interest = c("Malawi", "United States", 
                                                               "Brazil", "Argentina",
                                                               "Congo, Democratic Republic of the",
                                                               "Zambia",
                                                               "Uruguay", "Tanzania"),
                                     colors = c( "#367526", "#7a40a0"), text.size = 4,xint=-1.07, yint = 0.25,
                                     line.color = 'grey1', arrow.size = 2,
                                     breaks = c(1,5,10,15,20,40,60))


```


```{r, fig.height = 10, fig.width = 10, echo = include.code} 
state.space.fig
```

The following chunks of code will recreate all the plots found in supplemental figures S17, S18, and S19. This analysis is now based on estimated cases, that corrects for under-reporting using a state space model, rather than reported cases.  All analyses were conducted the exact same as when using reported cases, with one small exception. When building the canonical path based on estiamted cases, there is a gap between African region countries and Americas region countries, as seen in the figure above (Fig. S16), therefore we forced the gap to be filled with three addtional points. For consistency, we removed three other points. As a result there are 2 main changes to the code: the first is to replace the canonical.path.data with data from the state space model, and the second is to replace the object use.reported.cases with FALSE.
  
```{r, echo = include.code}
canonical.path.data <- state.space.data
use.reported.cases = F
```


```{r, echo = include.code, fig.height = 6, fig.width = 8}
list[d1a, canonical.path2] = closest.path.point(d = canonical.path.data, 
                                                use.rep.cases = use.reported.cases,
                                                regions = regions, 
                                                years = seq(1990, 2017),
                                                make.inc.cv.scale.same = 0,
                                                sqrt.inc = T,
                                                connect.canonical.path.to.zero = 0,
                                                log.incidence = 0,
                                                make.figure.plot = T)

cols.1 <- colorRampPalette(c("red", "white", "blue"))(length(canonical.path2$x))
plot(canonical.path2$x, canonical.path2$y, pch = 21, cex = 2,
     xlab = 'coefficient of variation', ylab= 'scaled mean incidence', bty="n", 
     yaxt = "n", cex.axis=1.5, cex.lab = 1.5, col = 'black', bg = cols.1)
axis(2, at=c(sqrt(0.1),sqrt(seq(0,1.2, 0.2))), labels=c(0.1,seq(0, 1.2, 0.2)), cex.axis = 1.5)

```


```{r, echo = include.code, include = FALSE}

##' set up variables to use for making the canonical path and the
##' assignment of countries to the closest point on the path

d = canonical.path.data
use.rep.cases = use.reported.cases
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")
make.inc.cv.scale.same = 1 
sqrt.inc = F 
sqrt.cv = F
connect.canonical.path.to.zero = 0
log.incidence = T 
number.of.additional.points = 4 #4 additional points between each of 38 points

##' d1 will contain the closest point on the canonical path over time.
list[d1, canonical.path] = closest.path.point(d = d, 
                                              use.rep.cases = use.rep.cases,
                                              regions = regions, 
                                              years = seq(1990, 2017),
                                              make.inc.cv.scale.same = make.inc.cv.scale.same,
                                              sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                              connect.canonical.path.to.zero,
                                              log.incidence = log.incidence)

##' d1b will contain the closest point on the granular canonical path over time.
list[d1b, granular.canonical.path] = closest.path.point.movement.comparison(d = d, 
                                                                            use.rep.cases = use.rep.cases,
                                                                            regions = regions, 
                                                                            years = seq(1990, 2017),
                                                                            make.inc.cv.scale.same = make.inc.cv.scale.same,
                                                                            sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                                                            connect.canonical.path.to.zero,
                                                                            log.incidence = log.incidence,
                                                                            number.of.additional.points = number.of.additional.points) 
```

```{r, echo=include.code, include=FALSE}
##' First add population size to the data.frame because we need to weight the region estimates by population size of coutry
d1b$pop <- as.numeric(rep(NA, nrow(d1b)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(d1b)){
  row <- which(pop.by.year$Country.Name==d1b$Country[a])
  col <- which((1961:2017)==d1b$Year[a])+2
  d1b$pop[a] <- pop.by.year[row,col]
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-4)]}
}
d1b$pop <- as.numeric(d1b$pop)

##' Get country-specific population weight for each region and year
##' This will be used to weight the average position by region overtime
d1b <- d1b %>%
  group_by(WHO_REGION, Year) %>%
  mutate(weight = pop/sum(pop))
d1b$weight <- round(d1b$weight,5)

##' create data frame to store values in
deltas.by.continent = data.frame(matrix(NA, nrow(d1b), 6))
colnames(deltas.by.continent) = c("country", "region", "year", "delta", "pos","weight")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
  c1 = d1b$Country[i]
  y = d1b$Year[i]
  pos = d1b$closest[i]
  
  ##' for each country, each year, find the data for the same country the following year
  
  k = d1b %>% filter(Country == c1, Year == (y+1))
  if(nrow(k)>0){
    pos2 = k$closest
    deltas.by.continent[count, ] =  c(c1, k$WHO_REGION, y+1, pos2-pos, pos2, k$weight)
    count = count + 1
  }
}

##' remove data which is NA
j = which(is.na(deltas.by.continent$country))
if(length(j) >0 ){
  deltas.by.continent = deltas.by.continent[-(j),]
}

##' extract the unique years from the data set containing the changes for each year
all.years = as.numeric(unique(deltas.by.continent$year))
countries = unique(deltas.by.continent$country)

##' change the data to be characters and numbers
deltas.by.continent$country = deltas.by.continent$country %>% as.character
deltas.by.continent$region = deltas.by.continent$region %>% as.character
deltas.by.continent$year = deltas.by.continent$year %>% as.character %>% as.numeric
deltas.by.continent$delta = deltas.by.continent$delta %>% as.character %>% as.numeric
deltas.by.continent$pos = deltas.by.continent$pos %>% as.character %>% as.numeric
deltas.by.continent$weight = deltas.by.continent$weight %>% as.character %>% as.numeric

##'choose a period of time over which to smooth the average position of the WHO regions. 
##'A 2 this means that we smooth using the average of a given year along with two years before and two years after
moving.av.length = 2

##' set up a dataframe to hold the weighted data
deltas.summary.weighted = data.frame(matrix(NA, (length(all.years)-2)*length(countries), 6))
colnames(deltas.summary.weighted) = c("country","region", "year", "mean.delta", "mean.pos", "weight")

count = 1
for(i in (moving.av.length+1):length(all.years - moving.av.length)){
  ##' choose the years we wish to include in the averaging
  years = all.years[(i-moving.av.length):(i+moving.av.length)]
  for(j in 1 : length(countries)){
    ##' find the require data
    c = countries[j]
    d = deltas.by.continent %>% filter(year %in% years & country ==c) 
    r = d$region[1]
    
    ##' record the regions, the year in question, along with summaries of the change in movement, along
    ##' with the mean position of the region over the years in question
    deltas.summary.weighted[count, ] = c(c, 
                                         r,
                                         years[(moving.av.length + 1)],
                                         mean(d$delta),
                                         mean(d$pos),
                                         mean(d$weight)) #keep the weight for appropriate year
    count = count + 1
  }
}

##' remove data which is NA
j = which(deltas.summary.weighted$mean.delta=="NaN")
if(length(j) >0 ){
  deltas.summary.weighted = deltas.summary.weighted[-(j),]
}

##' change the data to be characters and numbers
deltas.summary.weighted$country = deltas.summary.weighted$country %>% as.character
deltas.summary.weighted$region = deltas.summary.weighted$region %>% as.character
deltas.summary.weighted$year = deltas.summary.weighted$year %>% as.character %>% as.numeric
deltas.summary.weighted$mean.delta = deltas.summary.weighted$mean.delta %>% as.character %>% as.numeric
deltas.summary.weighted$mean.pos = deltas.summary.weighted$mean.pos %>% as.character %>% as.numeric
deltas.summary.weighted$weight = deltas.summary.weighted$weight %>% as.character %>% as.numeric

dd <- deltas.summary.weighted

##' summarise with average position for each region, by year
dd2 = dd %>% 
  group_by(region, year) %>%
  summarise(mean.pos = mean(mean.pos))
dd3 = dd %>% 
  group_by(region, year) %>%
  summarise(mean.delta = mean(mean.delta))

##' summarise the population weighted average position for each region, by year
dd2b = dd %>% 
  group_by(region, year) %>%
  summarise(mean.pos = sum(mean.pos*weight))
dd3b = dd %>% 
  group_by(region, year) %>%
  summarise(mean.delta = sum(mean.delta*weight))
```

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1)

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1)

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2b, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1)

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3b, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1)

```

```{r, echo = include.code,  fig.height = 6, fig.width = 10}
plot.year = 2017

missing.countries = c("Bosnia and Herzegovina", "Central African Republic",
                      "Congo, Republic of The", "Czech Republic", "Korea, North",
                      "Congo, Democratic Republic of the", "Dominican Republic", "Gambia, The",   
                      "Burma", "Korea, South", "South Sudan")

replace.countries = c("Bosnia and Herz", "Central African Rep.", "Congo", "Czech Rep.",
                      "Dem. Rep. Korea", "Dem. Rep. Congo", "Dominican Rep.", "Gambia",
                      "Myanmar", "Korea", "S. Sudan")


list[w.plot, A, canonical.path] = plot.world.map (d = canonical.path.data, 
                                                  use.rep.cases = use.reported.cases,
                                                  regions,
                                                  year = plot.year,
                                                  make.inc.cv.scale.same = 1,
                                                  sqrt.inc = F,
                                                  missing.countries,
                                                  replace.countries,
                                                  connect.canonical.path.to.zero = 0 ,
                                                  log.incidence = T,
                                                  with.text = 1)
w.plot

```


```{r, echo=include.code}
position.and.movement.comparison = data.frame(matrix(NA, nrow(d1b), 15))
colnames(position.and.movement.comparison) = c("country", "region", "year", 
                                  "actual.x", "actual.y",
                                  "next.actual.x", "next.actual.y",
                                  "actual.x.change", "actual.y.change",
                                  "canonical.x","canonical.y", 
                                  "next.canonical.x", "next.canonical.y",
                                  "canonical.x.change", "canonical.y.change")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
    c1 = d1b$Country[i]
    y = d1b$Year[i]
    pos = d1b$closest[i]
    
    ##' for each country, each year, find the data for the same country the following year
    
    k = d1b %>% filter(Country == c1, Year == (y+1)) #looking one year ahead (i.e., 1 for observed, and 5 for expected)
    if(nrow(k)>0){
        if(pos < (nrow(granular.canonical.path)-5)){
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           granular.canonical.path$x[(pos+5)], granular.canonical.path$y[(pos+5)],
                                                           granular.canonical.path$x[(pos+5)]-d1b$canonical.x[i],
                                                           granular.canonical.path$y[(pos+5)]-d1b$canonical.y[i])
            
        } else { #else means the country is at the end of the granular path, so force canonical path change to 0
            position.and.movement.comparison[count, ] =  c(c1, k$WHO_REGION, y, 
                                                           d1b$Coefficient.of.Variation[i], d1b$Incidence[i],
                                                           k$Coefficient.of.Variation, k$Incidence,
                                                           k$Coefficient.of.Variation - d1b$Coefficient.of.Variation[i],
                                                           k$Incidence - d1b$Incidence[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           d1b$canonical.x[i], d1b$canonical.y[i],
                                                           0,0)
            
        }
               count = count + 1
    }
}

#remove non filled in rows
df <- position.and.movement.comparison %>% filter(!is.na(country))

#making numeric
df$actual.x.change = df$actual.x.change %>% as.character %>% as.numeric
df$actual.y.change = df$actual.y.change %>% as.character %>% as.numeric
df$canonical.x.change = df$canonical.x.change %>% as.character %>% as.numeric
df$canonical.y.change = df$canonical.y.change %>% as.character %>% as.numeric

#calculating the angle
df$actual.angle <- (atan2(df$actual.y.change,df$actual.x.change)*-180/pi)
df$canonical.angle <- (atan2(df$canonical.y.change,df$canonical.x.change)*-180/pi) 

#Angle difference
df$angle.diff <- df$actual.angle-df$canonical.angle
#series of if statements: to get angle difference between 180 and -180, rather than -360 and 360.
dft <- df %>% filter(canonical.angle<= -90 & actual.angle>= 90)
df$angle.diff[(df$canonical.angle<= -90 & df$actual.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(actual.angle<= -90 & canonical.angle>= 90)
df$angle.diff[(df$actual.angle<= -90 & df$canonical.angle>= 90)] <- 180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(actual.angle<= -90 & canonical.angle<= 90 & canonical.angle>= 0 & angle.diff< -180)
df$angle.diff[(df$actual.angle<= -90 & df$canonical.angle<= 90 & df$canonical.angle>= 0 & df$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)
dft <- df %>% filter(canonical.angle>= 90 & actual.angle>= -90 & actual.angle<= 0 & angle.diff< -180)
df$angle.diff[(df$canonical.angle>= 90 & df$actual.angle>= -90 & df$actual.angle<= 0 & df$angle.diff< -180)] <- 
  180-abs(dft$actual.angle)+180-abs(dft$canonical.angle)

#group angles in 10s
df$canonical.angle10 <- plyr::round_any(df$canonical.angle, 10)
df$actual.angle10 <- plyr::round_any(df$actual.angle, 10)


regs = c("AMR","AFR","EMR","EUR","SEAR","WPR")
year.groups <- list(1990:1999, 2000:2009, 2010:2017)
all.plots <- list()
for (c in 1:length(regs)){
  for (y in 1:3){
    
    #filtering and grouping data to set up dataframe for plotting
    dfo <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]]) %>%
      group_by(a = actual.angle10) %>%
      summarise(n=n()) %>%
      mutate(frequency=n/sum(n))
    dfe.tmp <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]]) %>%
      group_by(a = round(canonical.angle10)) %>%
      summarise(n=n()) %>%
      mutate(freq=n/sum(n))
    
    #smoothing expected path
    byn <- seq(-180,179,10)
    dfe <- as.data.frame(matrix(NA, nrow=length(byn), ncol=2))
    colnames(dfe) <- c("a", "freq")
    for (i in 1:length(byn)){
      dfe$freq[i] <- ifelse(is.na(dfe.tmp$freq[match(byn[i], dfe.tmp$a)]),0,
                            dfe.tmp$freq[match(byn[i], dfe.tmp$a)])
      dfe$a[i] <- byn[i]
    }
    dfe$frequency <- rep(NA, nrow(dfe))
    for (r in 1:nrow(dfe)){
      if (r==1) {dfe$frequency[r] <- mean(dfe$freq[(r):(r+2)], na.rm=T)}
      if (r==2) {dfe$frequency[r] <- mean(dfe$freq[(r-1):(r+2)], na.rm=T)}
      if (r>=3) {dfe$frequency[r] <- mean(dfe$freq[(r-2):(r+2)], na.rm=T)}
    }
    
    #merging the datasets together into one
    byn <- seq(-180,179,10)
    dfa <- data.frame(a=rep(byn,3), obs.exp=c(rep("O",length(byn)),rep("FF",length(byn)),rep("E",length(byn))), frequency=rep(NA, length(byn)*3))
    for (i in 1:length(byn)){
      dfa$frequency[which(dfa$obs.exp=="O")[i]] <- dfo$frequency[match(dfa$a[i], dfo$a)]
      dfa$frequency[which(dfa$obs.exp=="E")[i]] <- dfe$frequency[match(dfa$a[i], dfe$a)]
    }
    dfa$label <- c(rep("Observed",length(byn)), rep("blank",length(byn)), rep("Expected",length(byn)))
    dfa$frequency[is.na(dfa$frequency)] <- 0 #because no change is NA
    dfa$frequency[which(dfa$obs.exp=="FF")] <- NA
    dfa$a[dfa$a==seq(-180,-100,10)] <- 360+dfa$a[dfa$a==seq(-180,-100,10)] #hack so the top is -90 degrees
    
    #estimating median difference in angle
    dfd <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]]) %>%
      summarise(med=(median(angle.diff)*(-1))) #want positive 90 at top and -90 at bottom
    
    #IQR for region and year
    df.iqr <- df %>%
      filter(region==regs[c]) %>%
      filter(year %in% year.groups[[y]])
    iqr <- quantile((df.iqr$angle.diff*(-1)), c(0.25, 0.5,0.75)) #want positive 90 top, and -90 bottom
    print(c(paste(regs[c], year.groups[y]), iqr))
    
    #plot it
    dfa$obs.exp <- as.numeric(dfa$obs.exp)+2
    name <- paste("reg",c,".year",y, sep="")
    all.plots[[name]] <- 
      ggplot(dfa, aes(x=a, y=obs.exp, fill=(frequency))) +
      geom_tile(colour="white") +
      scale_fill_distiller(palette="YlGnBu", direction=1, limits=c(0,0.3), na.value="white") + #can change limits=c(0,0.2) instead, but will be missing one value
      ylim(c(0, max(dfa$obs.exp) + 0.5)) +
      coord_polar(theta="x") + annotate("text", x = 0, y = 0, label = round(dfd[1,1])) +
      theme(panel.background=element_blank(),
            axis.title=element_blank(),
            panel.grid=element_blank(),
            axis.text.x=element_blank(),
            axis.ticks=element_blank(),
            axis.text.y=element_text(size=5)) + ggtitle(paste(regs[c],": ", year.groups[[y]][1], "-", year.groups[[y]][length(year.groups[[y]])], sep=""))
    
  }
}
```

```{r, fig.height = 9, fig.width = 18}
do.call(grid.arrange, c(grobs=all.plots, nrow=3, as.table=F))
```

```{r, echo = include.code, fig.height = 3, fig.width = 3}
    dfo <- df %>%
      group_by(a = actual.angle10) %>%
      summarise(n=n()) %>%
      mutate(frequency=n/sum(n))
    dfe.tmp <- df %>%
      group_by(a = round(canonical.angle10)) %>%
      summarise(n=n()) %>%
      mutate(freq=n/sum(n))
    
    #smoothing expected path
    byn <- seq(-180,179,10)
    dfe <- as.data.frame(matrix(NA, nrow=length(byn), ncol=2))
    colnames(dfe) <- c("a", "freq")
    for (i in 1:length(byn)){
      dfe$freq[i] <- ifelse(is.na(dfe.tmp$freq[match(byn[i], dfe.tmp$a)]),0,
                            dfe.tmp$freq[match(byn[i], dfe.tmp$a)])
      dfe$a[i] <- byn[i]
    }
    dfe$frequency <- rep(NA, nrow(dfe))
    for (r in 1:nrow(dfe)){
      if (r==1) {dfe$frequency[r] <- mean(dfe$freq[(r):(r+2)], na.rm=T)}
      if (r==2) {dfe$frequency[r] <- mean(dfe$freq[(r-1):(r+2)], na.rm=T)}
      if (r>=3) {dfe$frequency[r] <- mean(dfe$freq[(r-2):(r+2)], na.rm=T)}
    }
    
    #merging the datasets together into one
    byn <- seq(-180,179,10)
    dfa <- data.frame(a=rep(byn,3), obs.exp=c(rep("O",length(byn)),rep("FF",length(byn)),rep("E",length(byn))), frequency=rep(NA, length(byn)*3))
    for (i in 1:length(byn)){
      dfa$frequency[which(dfa$obs.exp=="O")[i]] <- dfo$frequency[match(dfa$a[i], dfo$a)]
      dfa$frequency[which(dfa$obs.exp=="E")[i]] <- dfe$frequency[match(dfa$a[i], dfe$a)]
    }
    dfa$label <- c(rep("Observed",length(byn)), rep("blank",length(byn)), rep("Expected",length(byn)))
    dfa$frequency[is.na(dfa$frequency)] <- 0 #because no change is NA
    dfa$frequency[which(dfa$obs.exp=="FF")] <- NA
    dfa$a[dfa$a==seq(-180,-100,10)] <- 360+dfa$a[dfa$a==seq(-180,-100,10)] #hack so the top is -90 degrees
    
    #estimating median difference in angle
    dfd <- df %>%
      summarise(med=median(angle.diff)*(-1)) #want positive 90 top, and -90 bottom
    
    #plot it
    dfa$obs.exp <- as.numeric(dfa$obs.exp)+2
    all.together <-  ggplot(dfa, aes(x=a, y=obs.exp, fill=(frequency))) +
      geom_tile(colour="white") +
      scale_fill_distiller(palette="YlGnBu", direction=1, limits=c(0,0.2), na.value="white") + #Greys
      ylim(c(0, max(dfa$obs.exp) + 0.5)) +
      coord_polar(theta="x") + annotate("text", x = 0, y = 0, label = round(dfd[1,1])) +
      theme(panel.background=element_blank(),
            axis.title=element_blank(),
            panel.grid=element_blank(),
            axis.text.x=element_blank(),
            axis.ticks=element_blank(),
            axis.text.y=element_text(size=5)) +
      ggtitle("All countries and years")
    
    #estimating IQR for difference in angle
    iqr.all <- quantile(df$angle.diff*(-1), c(0.25, 0.5,0.75)) 
    print(iqr.all)
    
    #how often angle differences plus or minus 45 degrees
    #observations are year and country
    df.xtra <- df %>%
      filter(angle.diff > 45 | angle.diff < (-45))
    nrow(df.xtra) / nrow(df)
    
    all.together
    
```


```{r, echo = include.code, include=F}
##' import the estimated susceptibles for each country and year.
estimated.susceptibles.by.year = read.csv("data/est_sus_by_year.csv", stringsAsFactors = F)
estimated.age.dist.by.year = read.csv("data/est_age_dist_by_year.csv", stringsAsFactors = F)
```

```{r, echo = include.code, include=F}
estimated.susceptibles.by.year = estimated.susceptibles.by.year[, -(1)]
estimated.age.dist.by.year = estimated.age.dist.by.year[, -(1)]
##' run code to generate the number of susceptibles by age by canonical path point
list[dist.by.age, canonical.path, prop.sus, d1, prop.sus.by.age] = 
    plots.for.sus.dist.by.canonical.path (d1 = canonical.path.data, 
                                          d2 = estimated.susceptibles.by.year, 
                                          d3 = estimated.age.dist.by.year,
                                          rep.cases = use.reported.cases,
                                          regions,
                                          make.inc.cv.scale.same = 1,
                                          sqrt.inc = F,
                                          connect.canonical.path.to.zero = 0,
                                          log.incidence = 1,
                                          make.figure.plot = F)
cols.1 <- colorRampPalette(c("red", "white", "blue"))(length(canonical.path$x))
```

```{r, echo = include.code, fig.height = 4, fig.width = 6}

    plot( prop.sus[, 2]*100, pch = 21, cex = 2,
          xlab = '', ylab= '% susceptible', bty="n",
          xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black')
    smoo <- with(prop.sus[!is.na(prop.sus$y),],smooth.spline(x,y*100, df=4))
    result <- with(prop.sus, predict(smoo,x[is.na(y)]))
    prop.sus[is.na(prop.sus$y),] <- result
    lines(smoo, col='black', lwd=2)
    abline(h = 5, lwd = 2, lty = 2)
    abline(h = ((1/15)*100), lwd = 2, lty = 2)
    
```

```{r, echo = include.code, fig.height = 5, fig.width = 8}

##' import the data on mean age of measles cases
mean.measles.age <- read.csv("data/mean_age_meas.csv", stringsAsFactors = F)

##' melt the mean age of measles data 
melt.mean.measles.age = melt(mean.measles.age, id.vars = c("ISO3", "WHO_REGION", "Country")) %>%
    na.omit

##' remove the X from the year data
melt.mean.measles.age$variable = substr(melt.mean.measles.age$variable, 2, 5) %>% as.numeric

##' rename the columns 
colnames(melt.mean.measles.age) = c("ISO3", "WHO_REGION", "country", "year", "value")

##' remove data for countries which are not included in the canonical path data
k = which(melt.mean.measles.age$country %in% c("occupied Palestinian territory", "#N/A"))
melt.mean.measles.age = melt.mean.measles.age[-(k), ]

##' add a column which will contain the canonical path location of each country and year
melt.mean.measles.age$closest = NA

##' find the canonical path location for each country and year in the mean measles age data
for(i in 1 : nrow(melt.mean.measles.age)){
    k = which(d1$Country == melt.mean.measles.age$country[i] &
                                                     d1$Year == melt.mean.measles.age$year[i])
    if(length(k) > 0){
        melt.mean.measles.age$closest[i] = d1$closest[k]
    }
}

##' find all the locations on the canonical path that the data on the mean age of measles are on
all.closest = unique(melt.mean.measles.age$closest)

##' which locations on the canonical path are not included in this data
missing = setdiff(1:max(all.closest, na.rm = T), all.closest)

##' generate a data set called X, that has the same dimensions as the melted mean measles data
X = data.frame(matrix(NA, length(missing),6))

##' give this data set the same column names as the melted data
colnames(X) = colnames(melt.mean.measles.age)

##' assign the missing canonical path points to the data set X, along with a value outside of the range of the possible mean age of the measles cases
X$closest = missing
X$value = -100

##' combine the melted measles data and the missing data so that we can make a boxplot of the mean age of measles cases
melt.mean.measles.age = rbind(melt.mean.measles.age, X)
```

```{r, echo = include.code, fig.height = 6, fig.width = 9}

boxplot(age ~ point, data = dist.by.age, outline = F, bty = "n",
        ylim = c(0, 60), xaxt = "n", frame.plot = F, xlab = "position on canonical path",
        cex.axis = 1.5, cex.lab = 1.5)

boxplot(value/12 ~ closest, 
        data = melt.mean.measles.age, boxlwd=0.01, whisklwd=2, staplelwd=2.5,
        ylim = c(0,700/12), border = rgb(red = 10/255, green = 10/255, blue = 100/255, alpha = 0.55),
        col = rgb(red = 1/255, green = 10/255, blue = 100/255, alpha = 0.4),
        ylab ="age", xaxt = "n", frame.plot = F,
        pars = list(boxwex = 0.38, staplewex = 0.5, outwex = 0),
        cex.axis = 1.5, cex.lab = 1.5, outline = F, add= T)

axis(1, at = c(1,length(unique(dist.by.age$point))),labels = c("",""))


```


```{r, echo = include.code, include = F}

prop.sus.by.age <- prop.sus.by.age[,-1]
a = 1:59
n = 5
min = c(seq.int(from=1, to=length(a), by=n))
max = c((min-1)[2:length(min)], length(a))
prop.sus.by.age.group = apply(prop.sus.by.age, 1, function(x) sapply(1:length(min), function(i) mean(x[min[i]:max[i]])))
prop.sus.by.age.group <- rbind(prop.sus.by.age.group, prop.sus[, 2]) #add in prop.sus for ALL ages to the last row (same as Fig. 2A)

dist.by.age.rep = dist.by.age
points = unique(dist.by.age.rep$point)
perc.by.age.sia.rep = data.frame(matrix(NA, max(points), 5))
perc.by.age.sia.rep[,1] = 1:max(points)
colnames(perc.by.age.sia.rep) = c("pos", "perc.to.5", "perc.to.10", "perc.to.15", "age.for.90.perc")

for(i in 1 : length(points)){
    p = dist.by.age.rep[which(dist.by.age.rep$point == points[i]), ]
    if(nrow(p) > 1){ #xxamy this if statement was added
    p1 = p %>% filter(age <= 5)
    p2 = p %>% filter(age <= 10)
    p3 = p %>% filter(age <= 15)
    p4 = p[order(p$age), ]
    
    perc.by.age.sia.rep[points[i], ] = c(points[i], 
                             nrow(p1)*100/nrow(p),
                             nrow(p2)*100/nrow(p),
                             nrow(p3)*100/nrow(p),
                             p4[floor(nrow(p)*0.9), 2] )
    }
}


##'  adjust positions of the percentage age to sia age to go from 1 to
##' the number of points that have countries assigned to them
perc.by.age.sia.rep$pos = 1:nrow(perc.by.age.sia.rep)
#plot(perc.by.age.sia.rep$pos, perc.by.age.sia.rep$age.for.90.perc)
#k=unique(dist.by.age$point)
#k = k[order(k)]

```


```{r, echo = include.code, fig.height = 6, fig.width = 9}

levelplot(t(as.matrix(prop.sus.by.age.group)), ylab="age (years)", 
          xlab="position on canonical path", xaxt = "n",
          col.regions=colorRampPalette(brewer.pal(9,"Greys")),
          scales=list(y=list(at=1:13, labels=c("<5","5-9","10-14","15-19","20-24","25-29","30-34","35-39","40-44","45-49",
                                                                                            "50-54","55-59", "all"))))

plot( perc.by.age.sia.rep$pos, perc.by.age.sia.rep$perc.to.5, pch = 21, cex = 2,
      xlab = '', ylab= '% of susceptibles 5 or under', bty="n",
      xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black', ylim = c(10,70))
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$perc.to.5),], smooth.spline(pos,perc.to.5))
result <- with(perc.by.age.sia.rep, predict(smoo,pos[is.na(perc.by.age.sia.rep$perc.to.5)]))
perc.by.age.sia.rep[is.na(perc.by.age.sia.rep$perc.to.5),2] <- result$y
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$perc.to.5),], smooth.spline(pos,perc.to.5), cv = T)
lines(smoo, col='black', lwd=2)
abline(h = 50, lwd = 2, lty = 2)
abline(h = 2/30, lwd = 2, lty = 2)


plot(perc.by.age.sia.rep$pos, perc.by.age.sia.rep$age.for.90.perc, pch = 21, cex = 2,
     xlab = '', ylab= 'oldest SIA age to reach 90% of susceptibles', bty="n",ylim = c(14,42),
     xaxt = "n",cex.axis=1.5, cex.lab = 1.5, bg = cols.1, col = 'black')
smoo <- with(perc.by.age.sia.rep[!is.na(perc.by.age.sia.rep$age.for.90.perc),], smooth.spline(pos,age.for.90.perc, df=6))
result <- with(perc.by.age.sia.rep, predict(smoo,pos[is.na(perc.by.age.sia.rep$age.for.90.perc)]))
perc.by.age.sia.rep[is.na(perc.by.age.sia.rep$age.for.90.perc),5] <- result$y
lines(smoo, col='black', lwd=2)
```


Figure S20 demonstrates movement along the canonical path for 10 countries of interest from the Americas, Africa, and European.  These 10 countries are highlighted from Fig. 4A-B in the main text to conceptualize an individual country's movement on the path and discuss data biases or true dynamics that may have contributed to these movements.  

```{r, fig.height=6, fig.width=12, echo=include.code}
##' filtering to the countries of interest
cc <- dd %>%
  filter(country=="Malawi" | country=="Brazil" | country=="Uruguay" | country=="Congo, Democratic Republic of the" |
           country=="Zambia" | country=="United States" | country=="France" | country=="Argentina" | country=="Tanzania") %>%
  mutate(country=ifelse(country=="Congo, Democratic Republic of the", "DRC", country))

ggplot(cc, aes(x=year, y=mean.pos/2, color=country)) + geom_line(alpha=0.6, lwd=1.5) +
  theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Paired")
ggplot(cc, aes(x=year, y=mean.delta/2, color=country)) + geom_line(alpha=0.6, lwd=1.5) +
  ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)")  + scale_colour_brewer(palette="Paired")
```

Figures S21 and S22, contains the results of modeling incidence and coefficient of variation as dependent variables separately, with birth rate, vaccination proportion and (birth rate) times (1-vaccination proportion) all used independent variables (one at a time) using generalized additive models (GAM). The term (birth rate) times (1-vaccination proportion) is an approximation of how quickly individuals who are susceptible to measles are recruited into the population, therefore we term this the rate of susceptible recruitment. To produce the GAM plots, we first need to construct a data set which has the estimated mean age of susceptibles by country and by year.

```{r, echo = include.code, include = F}
mean.age.sus = read.csv(file = "data/mean_age_sus.csv", stringsAsFactors = F)
rownames(mean.age.sus) = mean.age.sus$X
mean.age.sus = mean.age.sus[, -(1)]
colnames(mean.age.sus) = gsub("X", "", colnames(mean.age.sus))


list[anim.data, Af.data, Amr.data, Rest.data] = 
    prepare.anim.data.for.analysis(input.data = canonical.path.data,
                                   mean.age.sus = mean.age.sus)
Amr.af.data = rbind(Af.data, Amr.data)
all.but.euro = rbind(Amr.af.data, filter(Rest.data, WHO_REGION != "EUR"))
Combined.data = rbind(Rest.data, Amr.af.data)


list[h, z, j, z1, colfunc.br, colfunc.vacc, colfunc.br.vacc] = produce.gams.plot(data = Combined.data,
                  ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500)),
                  tick.labels = c(0,25,100, 250,500))

list[ha, za, ja, z1a, colfunc.br, colfunc.vacc, colfunc.br.vacc] = produce.gams.plot(data = all.but.euro,
                  ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500)),
                  tick.labels = c(0,25,100, 250,500))


```

We can then plot these predicted paths in the incidence-space over values of birth rate, vaccination rate, and the rate of susceptible recruitment with reported cases (Fig. S21).

```{r, echo = include.code, fig.height = 8, fig.width = 8}
tick.labels = c(0,25,100, 250,500)
ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500))
plot.alpha = 0.8
##' construct the plot
    plot(h$x, sqrt(100*h$y), yaxt = "n", xlab = "coefficient of variation", 
         ylab = "mean incidence per 100,000",
         col = alpha(colfunc.br(nrow(h)),plot.alpha), 
         pch = 16, cex = 1.5, xlim = c(min(z1$x), max(z1$x)), frame.plot = FALSE,
         ylim = c(0, sqrt(100*max(z1$y))), cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5)
    points(z$x, sqrt(100 * z$y), col = alpha(colfunc.vacc(nrow(z)), plot.alpha),
           pch = 17, cex = 1.5)
    points(j$x, sqrt(100 * j$y), col = alpha(colfunc.br.vacc(nrow(j)), plot.alpha),
           pch = 15, cex = 1.5)
    legend('topright', bty = 'n', c("br","vacc","br(1-vacc)"), pch = c(16, 17,15), 
           col = c("darkgreen", "navyblue","firebrick"), cex = 1.5)
    
    ##' tick marks trick, to get the true values rather than sqrt value on y axis
    axis(2, at=ticks, labels=tick.labels, cex.axis = 1.5)
```
   
    
```{r, echo = include.code, fig.height = 8, fig.width = 8} 
       plot(ha$x, sqrt(100*ha$y), yaxt = "n", xlab = "coefficient of variation", 
         ylab = "mean incidence per 100,000",
         col = alpha(colfunc.br(nrow(ha)),plot.alpha), 
         pch = 16, cex = 1.5, xlim = c(min(z1a$x), max(z1a$x)), frame.plot = FALSE,
         ylim = c(0, sqrt(100*max(z1$y))), cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5)
    points(za$x, sqrt(100 * za$y), col = alpha(colfunc.vacc(nrow(za)), plot.alpha),
           pch = 17, cex = 1.5)
    points(ja$x, sqrt(100 * ja$y), col = alpha(colfunc.br.vacc(nrow(ja)), plot.alpha),
           pch = 15, cex = 1.5)
    legend('topright', bty = 'n', c("br","vacc","br(1-vacc)"), pch = c(16, 17,15), 
           col = c("darkgreen", "navyblue","firebrick"), cex = 1.5)
    
    ##' tick marks trick, to get the true values rather than sqrt value on y axis
    axis(2, at=ticks, labels=tick.labels, cex.axis = 1.5)
    

```

Figure S21C also displays the association between incidence or coefficient of variation with the birth rate and vaccination coverage in Africa.

```{r, echo = F, fig.height = 8, fig.width = 8}


list[canonical.path.data.anim, Af.data, Amr.data, Rest.data] = 
    prepare.anim.data.for.analysis(input.data = canonical.path.data,
                                   mean.age.sus = mean.age.sus)


L = canonical.path.data.anim[which(canonical.path.data.anim$Mean.Age.Sus >0), ]
L = L%>% filter(WHO_REGION == "AFR")

L = L[-(which(L$Incidence ==0 & L$Coefficient.of.Variation ==0)), ]


L = L[-(which(L$Mean.vaccination == 0)), ]

par(mfrow=c(2,2))
plot(sqrt(100*Incidence)  ~ Mean.birth.rate, data = L,  bty="n",
     cex = 0.75,col="grey40", cex.axis = 1.5, yaxt = "n",
     xlab = list("", cex = 1.5), 
     ylab = list("incidence per 100000", cex = 1.5))
L = L[order(L$Mean.birth.rate),]
loess_fit <- loess(sqrt(100*Incidence)~ Mean.birth.rate, L, degree = 1)
lines(L$Mean.birth.rate, predict(loess_fit), col = "blue", lwd = 2)
axis(2, at = c(0, 10, sqrt(500),  sqrt(1200)), labels = c(0, 100, 500, 1200), cex.axis =  1.5)


plot(sqrt(100*Incidence) ~ Mean.vaccination, data = L,  bty="n",
     cex = 0.75,col="grey40", cex.axis = 1.5, yaxt = "n",
     xlab = list("", cex = 1.5), 
     ylab = list("", cex = 1.5))
L = L[order(L$Mean.vaccination),]
loess_fit <- loess(sqrt(100*Incidence)~ Mean.vaccination, L, degree = 1)
lines(L$Mean.vaccination, predict(loess_fit), col = "blue", lwd = 2)
axis(2, at = c(0, 10, sqrt(500),  sqrt(1200)), labels = c(0, 100, 500, 1200), cex.axis =  1.5)

plot(Coefficient.of.Variation ~ Mean.birth.rate, data = L,  bty="n",
     cex = 0.75,col="grey40", cex.axis = 1.5,
     xlab = list("birth rate per 1000", cex = 1.5), 
     ylab = list("coefficient of variation", cex = 1.5))
L = L[order(L$Mean.birth.rate),]
loess_fit <- loess(Coefficient.of.Variation~ Mean.birth.rate, L, degree = 1)
lines(L$Mean.birth.rate, predict(loess_fit), col = "blue", lwd = 2)


plot(Coefficient.of.Variation ~ Mean.vaccination, data = L,  bty="n",
     cex = 0.75,col="grey40", cex.axis = 1.5,
     xlab = list("vaccination %", cex = 1.5), 
     ylab = list("", cex = 1.5))
L = L[order(L$Mean.vaccination),]
loess_fit <- loess(Coefficient.of.Variation~ Mean.vaccination, L, degree = 1)
lines(L$Mean.vaccination, predict(loess_fit), col = "blue", lwd = 2)



```

Similarly, we can use model incidence and coefficient of variation using GAMS, as seen above for the reported case data. This is seen below and Fig. S22 of the paper.

```{r, echo = include.code, include = F}

Amr.Af.data.state.space = rbind(Af.data.state.space, Amr.data.state.space)
all.but.euro.state.space = rbind(Amr.Af.data.state.space, filter(Rest.data, WHO_REGION != "EUR"))
Combined.data.state.space = rbind(Rest.data.state.space, Amr.Af.data.state.space)


list[h, z, j, z1, colfunc.br, colfunc.vacc, colfunc.br.vacc] = produce.gams.plot(data = Combined.data.state.space,
                  ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500)),
                  tick.labels = c(0,25,100, 250,500))

list[ha, za, ja, z1a, colfunc.br, colfunc.vacc, colfunc.br.vacc] = produce.gams.plot(data = all.but.euro.state.space,
                  ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500)),
                  tick.labels = c(0,25,100, 250,500))
 
```



```{r, echo = include.code, fig.height = 8, fig.width = 8}
tick.labels = c(0,25,100, 250,500)
ticks = c(0,sqrt(25), 10, sqrt(250), sqrt(500))
plot.alpha = 0.8
##' construct the plot
    plot(h$x, sqrt(100*h$y), yaxt = "n", xlab = "coefficient of variation", 
         ylab = "mean incidence per 100,000",
         col = alpha(colfunc.br(nrow(h)),plot.alpha), 
         pch = 16, cex = 1.5, xlim = c(min(z1$x), max(z1$x)), frame.plot = FALSE,
         ylim = c(0, sqrt(100*max(z1$y))), cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5)
    points(z$x, sqrt(100 * z$y), col = alpha(colfunc.vacc(nrow(z)), plot.alpha),
           pch = 17, cex = 1.5)
    points(j$x, sqrt(100 * j$y), col = alpha(colfunc.br.vacc(nrow(j)), plot.alpha),
           pch = 15, cex = 1.5)
    legend('topright', bty = 'n', c("br","vacc","br(1-vacc)"), pch = c(16, 17,15), 
           col = c("darkgreen", "navyblue","firebrick"), cex = 1.5)
    
    ##' tick marks trick, to get the true values rather than sqrt value on y axis
    axis(2, at=ticks, labels=tick.labels, cex.axis = 1.5)
```
   
    
```{r, echo = include.code, fig.height = 8, fig.width = 8} 
       plot(ha$x, sqrt(100*ha$y), yaxt = "n", xlab = "coefficient of variation", 
         ylab = "mean incidence per 100,000",
         col = alpha(colfunc.br(nrow(ha)),plot.alpha), 
         pch = 16, cex = 1.5, xlim = c(min(z1a$x), max(z1a$x)), frame.plot = FALSE,
         ylim = c(0, sqrt(100*max(z1$y))), cex.lab = 1.5, cex.main = 1.5, cex.axis = 1.5)
    points(za$x, sqrt(100 * za$y), col = alpha(colfunc.vacc(nrow(za)), plot.alpha),
           pch = 17, cex = 1.5)
    points(ja$x, sqrt(100 * ja$y), col = alpha(colfunc.br.vacc(nrow(ja)), plot.alpha),
           pch = 15, cex = 1.5)
    legend('topright', bty = 'n', c("br","vacc","br(1-vacc)"), pch = c(16, 17,15), 
           col = c("darkgreen", "navyblue","firebrick"), cex = 1.5)
    
    ##' tick marks trick, to get the true values rather than sqrt value on y axis
    axis(2, at=ticks, labels=tick.labels, cex.axis = 1.5)
    

```

Figure S23 shows the age distribution of cases in Malawi and Angola from 2006-2013. This figure is reproduced below.

```{r, echo = F, fig.height = 8, fig.width = 12}

Cases.by.age = read.csv("data/Angola_Malawi_cases.csv")


par(mfrow = c(1,2))
plot.case.boxplots(Cases.by.age, "Malawi", col = "#9964BF", alpha = 0.75)
plot.case.boxplots(Cases.by.age, "Angola", col = "#9964BF", alpha = 0.75)



```

Figure S24 displays the results of a sensitivity analysis of incidence space projections.  Here we show the position and speed of movement analysis by time and country (as displayed in Fig. 4A-B in the main text) for other scalings of incidence and the coefficent of variation.  We overlay the region averages and population-weighted region averages. 

We will start with the square root incidence and then scaling both square root incidence and coefficent of variation so that all of their values are between 0 and 1.

```{r, echo = include.code, include = FALSE}

##' square root incidence
d = canonical.path.data
use.rep.cases = 1
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")
make.inc.cv.scale.same = 1 
sqrt.inc = T
sqrt.cv = F
connect.canonical.path.to.zero = 0
log.incidence = F 
number.of.additional.points = 4 #4 additional points between each of 38 points

##' d1b will contain the closest point on the granular canonical path over time.
list[d1b, granular.canonical.path] = closest.path.point.movement.comparison(d = d, 
                                              use.rep.cases = use.rep.cases,
                                              regions = regions, 
                                              years = seq(1990, 2017),
                                              make.inc.cv.scale.same = make.inc.cv.scale.same,
                                              sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                              connect.canonical.path.to.zero,
                                              log.incidence = log.incidence,
                                              number.of.additional.points = number.of.additional.points) 

##' First add population size to the data.frame because we need to weight the region estimates by population size of coutry
d1b$pop <- as.numeric(rep(NA, nrow(d1b)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(d1b)){
  row <- which(pop.by.year$Country.Name==d1b$Country[a])
  col <- which((1961:2017)==d1b$Year[a])+2
  d1b$pop[a] <- pop.by.year[row,col]
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-4)]}
}
d1b$pop <- as.numeric(d1b$pop)

##' Get country-specific population weight for each region and year
##' This will be used to weight the average position by region overtime
d1b <- d1b %>%
  group_by(WHO_REGION, Year) %>%
  mutate(weight = pop/sum(pop))
d1b$weight <- round(d1b$weight,5)

##' create data frame to store values in
deltas.by.continent = data.frame(matrix(NA, nrow(d1b), 6))
colnames(deltas.by.continent) = c("country", "region", "year", "delta", "pos","weight")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
  c1 = d1b$Country[i]
  y = d1b$Year[i]
  pos = d1b$closest[i]
  
  ##' for each country, each year, find the data for the same country the following year
  
  k = d1b %>% filter(Country == c1, Year == (y+1))
  if(nrow(k)>0){
    pos2 = k$closest
    deltas.by.continent[count, ] =  c(c1, k$WHO_REGION, y+1, pos2-pos, pos2, k$weight)
    count = count + 1
  }
}

##' remove data which is NA
j = which(is.na(deltas.by.continent$country))
if(length(j) >0 ){
  deltas.by.continent = deltas.by.continent[-(j),]
}

##' extract the unique years from the data set containing the changes for each year
all.years = as.numeric(unique(deltas.by.continent$year))
countries = unique(deltas.by.continent$country)

##' change the data to be characters and numbers
deltas.by.continent$country = deltas.by.continent$country %>% as.character
deltas.by.continent$region = deltas.by.continent$region %>% as.character
deltas.by.continent$year = deltas.by.continent$year %>% as.character %>% as.numeric
deltas.by.continent$delta = deltas.by.continent$delta %>% as.character %>% as.numeric
deltas.by.continent$pos = deltas.by.continent$pos %>% as.character %>% as.numeric
deltas.by.continent$weight = deltas.by.continent$weight %>% as.character %>% as.numeric

##'choose a period of time over which to smooth the average position of the WHO regions. 
##'A 2 this means that we smooth using the average of a given year along with two years before and two years after
moving.av.length = 2

##' set up a dataframe to hold the weighted data
deltas.summary.weighted = data.frame(matrix(NA, (length(all.years)-2)*length(countries), 6))
colnames(deltas.summary.weighted) = c("country","region", "year", "mean.delta", "mean.pos", "weight")

count = 1
for(i in (moving.av.length+1):length(all.years - moving.av.length)){
  ##' choose the years we wish to include in the averaging
  years = all.years[(i-moving.av.length):(i+moving.av.length)]
  for(j in 1 : length(countries)){
    ##' find the require data
    c = countries[j]
    d = deltas.by.continent %>% filter(year %in% years & country ==c) 
    r = d$region[1]
    
    ##' record the regions, the year in question, along with summaries of the change in movement, along
    ##' with the mean position of the region over the years in question
    deltas.summary.weighted[count, ] = c(c, 
                                         r,
                                         years[(moving.av.length + 1)],
                                         mean(d$delta),
                                         mean(d$pos),
                                         mean(d$weight)) #keep the weight for appropriate year
    count = count + 1
  }
}

##' remove data which is NA
j = which(deltas.summary.weighted$mean.delta=="NaN")
if(length(j) >0 ){
  deltas.summary.weighted = deltas.summary.weighted[-(j),]
}

##' change the data to be characters and numbers
deltas.summary.weighted$country = deltas.summary.weighted$country %>% as.character
deltas.summary.weighted$region = deltas.summary.weighted$region %>% as.character
deltas.summary.weighted$year = deltas.summary.weighted$year %>% as.character %>% as.numeric
deltas.summary.weighted$mean.delta = deltas.summary.weighted$mean.delta %>% as.character %>% as.numeric
deltas.summary.weighted$mean.pos = deltas.summary.weighted$mean.pos %>% as.character %>% as.numeric
deltas.summary.weighted$weight = deltas.summary.weighted$weight %>% as.character %>% as.numeric

dd <- deltas.summary.weighted

##' summarise with average position for each region, by year
dd2 = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.pos = mean(mean.pos))
dd3 = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.delta = mean(mean.delta))
```

We plot the position and speed of movement analysis with overlay of region averages,

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("sqrt(inc), both scaled 0 to 1 \nregion averages")

```

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("sqrt(inc), both scaled 0 to 1 \nregion averages")

```

and with overlap of population-weighted region averages.

```{r, echo = include.code, include = F}
##' summarise the population weighted average position for each region, by year
dd2b = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.pos = sum(mean.pos*weight))
dd3b = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.delta = sum(mean.delta*weight))

```

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2b, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("sqrt(inc), both scaled 0 to 1 \npopulation-weighted region averages")

```

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3b, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("sqrt(inc), both scaled 0 to 1 \npopulation-weighted region averages")
```

We also assessed projection with natural logged incidence and square rooted ciefficent of variation and then scaling both so that all of their values are between 0 and 1.

```{r, echo = include.code, include = FALSE}

##' log incidence and sqrt cv
d = canonical.path.data
use.rep.cases = 1
regions = c("EMR","EUR","AFR","AMR","WPR","SEAR")
make.inc.cv.scale.same = 1 
sqrt.inc = F
sqrt.cv = T
connect.canonical.path.to.zero = 0
log.incidence = T 
number.of.additional.points = 4 #4 additional points between each of 38 points

##' d1b will contain the closest point on the granular canonical path over time.
list[d1b, granular.canonical.path] = closest.path.point.movement.comparison(d = d, 
                                              use.rep.cases = use.rep.cases,
                                              regions = regions, 
                                              years = seq(1990, 2017),
                                              make.inc.cv.scale.same = make.inc.cv.scale.same,
                                              sqrt.inc = sqrt.inc, sqrt.cv=sqrt.cv,
                                              connect.canonical.path.to.zero,
                                              log.incidence = log.incidence,
                                              number.of.additional.points = number.of.additional.points) 

##' First add population size to the data.frame because we need to weight the region estimates by population size of coutry
d1b$pop <- as.numeric(rep(NA, nrow(d1b)))
pop.by.year = read.csv("data/All_populations.csv", stringsAsFactors = FALSE) 
for (a in 1:nrow(d1b)){
  row <- which(pop.by.year$Country.Name==d1b$Country[a])
  col <- which((1961:2017)==d1b$Year[a])+2
  d1b$pop[a] <- pop.by.year[row,col]
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-1)]} #kuwait has some NAs that trying to fix
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-2)]} #and some counties in the later years have some issues 41 rows total missing pops
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-3)]}
  if (is.na(d1b$pop[a]) | d1b$pop[a]=="#N/A") {d1b$pop[a] <- pop.by.year[row,(col-4)]}
}
d1b$pop <- as.numeric(d1b$pop)

##' Get country-specific population weight for each region and year
##' This will be used to weight the average position by region overtime
d1b <- d1b %>%
  group_by(WHO_REGION, Year) %>%
  mutate(weight = pop/sum(pop))
d1b$weight <- round(d1b$weight,5)

##' create data frame to store values in
deltas.by.continent = data.frame(matrix(NA, nrow(d1b), 6))
colnames(deltas.by.continent) = c("country", "region", "year", "delta", "pos","weight")

##' go through data set containing the position for each country for each year, 
##' and store the data in the new data frame we have created.
count = 1
for(i in 1:nrow(d1b)){
  c1 = d1b$Country[i]
  y = d1b$Year[i]
  pos = d1b$closest[i]
  
  ##' for each country, each year, find the data for the same country the following year
  
  k = d1b %>% filter(Country == c1, Year == (y+1))
  if(nrow(k)>0){
    pos2 = k$closest
    deltas.by.continent[count, ] =  c(c1, k$WHO_REGION, y+1, pos2-pos, pos2, k$weight)
    count = count + 1
  }
}

##' remove data which is NA
j = which(is.na(deltas.by.continent$country))
if(length(j) >0 ){
  deltas.by.continent = deltas.by.continent[-(j),]
}

##' extract the unique years from the data set containing the changes for each year
all.years = as.numeric(unique(deltas.by.continent$year))
countries = unique(deltas.by.continent$country)

##' change the data to be characters and numbers
deltas.by.continent$country = deltas.by.continent$country %>% as.character
deltas.by.continent$region = deltas.by.continent$region %>% as.character
deltas.by.continent$year = deltas.by.continent$year %>% as.character %>% as.numeric
deltas.by.continent$delta = deltas.by.continent$delta %>% as.character %>% as.numeric
deltas.by.continent$pos = deltas.by.continent$pos %>% as.character %>% as.numeric
deltas.by.continent$weight = deltas.by.continent$weight %>% as.character %>% as.numeric

##'choose a period of time over which to smooth the average position of the WHO regions. 
##'A 2 this means that we smooth using the average of a given year along with two years before and two years after
moving.av.length = 2

##' set up a dataframe to hold the weighted data
deltas.summary.weighted = data.frame(matrix(NA, (length(all.years)-2)*length(countries), 6))
colnames(deltas.summary.weighted) = c("country","region", "year", "mean.delta", "mean.pos", "weight")

count = 1
for(i in (moving.av.length+1):length(all.years - moving.av.length)){
  ##' choose the years we wish to include in the averaging
  years = all.years[(i-moving.av.length):(i+moving.av.length)]
  for(j in 1 : length(countries)){
    ##' find the require data
    c = countries[j]
    d = deltas.by.continent %>% filter(year %in% years & country ==c) 
    r = d$region[1]
    
    ##' record the regions, the year in question, along with summaries of the change in movement, along
    ##' with the mean position of the region over the years in question
    deltas.summary.weighted[count, ] = c(c, 
                                         r,
                                         years[(moving.av.length + 1)],
                                         mean(d$delta),
                                         mean(d$pos),
                                         mean(d$weight)) #keep the weight for appropriate year
    count = count + 1
  }
}

##' remove data which is NA
j = which(deltas.summary.weighted$mean.delta=="NaN")
if(length(j) >0 ){
  deltas.summary.weighted = deltas.summary.weighted[-(j),]
}

##' change the data to be characters and numbers
deltas.summary.weighted$country = deltas.summary.weighted$country %>% as.character
deltas.summary.weighted$region = deltas.summary.weighted$region %>% as.character
deltas.summary.weighted$year = deltas.summary.weighted$year %>% as.character %>% as.numeric
deltas.summary.weighted$mean.delta = deltas.summary.weighted$mean.delta %>% as.character %>% as.numeric
deltas.summary.weighted$mean.pos = deltas.summary.weighted$mean.pos %>% as.character %>% as.numeric
deltas.summary.weighted$weight = deltas.summary.weighted$weight %>% as.character %>% as.numeric

dd <- deltas.summary.weighted

##' summarise with average position for each region, by year
dd2 = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.pos = mean(mean.pos))
dd3 = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.delta = mean(mean.delta))
```

We plot the position and speed of movement analysis with overlay of region averages,

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("log(inc) and sqrt(cv), both scaled 0 to 1 \nregion averages")

```

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("log(inc) and sqrt(cv), both scaled 0 to 1 \nregion averages")

```

and with overlap of population-weighted region averages.

```{r, echo = include.code, include = F}
##' summarise the population weighted average position for each region, by year
dd2b = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.pos = sum(mean.pos*weight))
dd3b = dd %>% 
  group_by(region, year) %>%
  dplyr::summarise(mean.delta = sum(mean.delta*weight))
```

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.pos*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd2b, lwd=1.2) + theme_minimal() + labs(y="position on path (%)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("log(inc) and sqrt(cv), both scaled 0 to 1 \npopulation-weighted region averages")

```

```{r, echo = include.code, fig.height = 6, fig.width = 6}

ggplot(dd, aes(x=year, y=mean.delta*(100/nrow(granular.canonical.path)), color=region)) + geom_line(aes(group=country), alpha=0.15) + geom_line(data = dd3b, lwd=1.2) + ylim(-10,10) + theme_minimal() + labs(y="speed of movement on path (% change)") + scale_colour_brewer(palette="Dark2", direction=1) + ggtitle("log(inc) and sqrt(cv), both scaled 0 to 1 \npopulation-weighted region averages")
```


# References










